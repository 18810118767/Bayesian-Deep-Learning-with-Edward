<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta content="text/html; charset=utf-8" http-equiv="Content-Type"/>
<meta content="text/css" http-equiv="Content-Style-Type"/>
<meta content="pandoc" name="generator"/>
<title>Edward – Classes of Inference</title>
<!-- Mobile Specific Metas -->
<meta content="width=device-width, initial-scale=1" name="viewport">
<!-- FONT -->
<link href="https://fonts.googleapis.com/css?family=Lora:400,400i,700" rel="stylesheet">
<!-- CSS -->
<link href="/css/normalize.css" rel="stylesheet">
<link href="/css/skeleton.css" rel="stylesheet">
<!-- Dynamically resize logo for mobile -->
<style type="text/css">
  .logo-width {
    width: 100%;
    box-sizing: border-box;
    margin-bottom: 15%;
  }
  /* Roughly the point when website is single column */
  @media (max-width: 850px) {
    .logo-width {
      width: 50%;
      box-sizing: border-box;
      margin-bottom: 5%;
    }
  }
  </style>
<!-- KaTeX -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.6.0/katex.min.js"></script>
<link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.6.0/katex.min.css" rel="stylesheet"/>
<script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.6.0/contrib/auto-render.min.js"></script>
<!-- highlight.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.4.0/highlight.min.js"></script>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.4.0/styles/github.min.css" rel="stylesheet">
<!-- Favicon -->
<link href="/icons/apple-touch-icon-57x57.png" rel="apple-touch-icon" sizes="57x57">
<link href="/icons/apple-touch-icon-60x60.png" rel="apple-touch-icon" sizes="60x60">
<link href="/icons/apple-touch-icon-72x72.png" rel="apple-touch-icon" sizes="72x72">
<link href="/icons/apple-touch-icon-76x76.png" rel="apple-touch-icon" sizes="76x76">
<link href="/icons/apple-touch-icon-114x114.png" rel="apple-touch-icon" sizes="114x114">
<link href="/icons/apple-touch-icon-120x120.png" rel="apple-touch-icon" sizes="120x120">
<link href="/icons/apple-touch-icon-144x144.png" rel="apple-touch-icon" sizes="144x144">
<link href="/icons/apple-touch-icon-152x152.png" rel="apple-touch-icon" sizes="152x152">
<link href="/icons/apple-touch-icon-180x180.png" rel="apple-touch-icon" sizes="180x180">
<link href="/icons/favicon-32x32.png" rel="icon" sizes="32x32" type="image/png">
<link href="/icons/android-chrome-192x192.png" rel="icon" sizes="192x192" type="image/png">
<link href="/icons/favicon-96x96.png" rel="icon" sizes="96x96" type="image/png">
<link href="/icons/favicon-16x16.png" rel="icon" sizes="16x16" type="image/png">
<link href="/icons/manifest.json" rel="manifest">
<link color="#5bbad5" href="/icons/safari-pinned-tab.svg" rel="mask-icon">
<link href="/icons/favicon.ico" rel="shortcut icon">
<meta content="#da532c" name="msapplication-TileColor">
<meta content="/icons/mstile-144x144.png" name="msapplication-TileImage">
<meta content="/icons/browserconfig.xml" name="msapplication-config">
<meta content="#ffffff" name="theme-color">
</meta></meta></meta></meta></link></link></link></link></link></link></link></link></link></link></link></link></link></link></link></link></link></link></link></link></meta></head>
<body>
<div class="container">
<div class="row" style="margin-top: 5%">
<div class="three columns">
<h1><a href="/">Edward</a></h1>
<a href="/">
<center>
<img alt="Edward" class="logo-width" src="/images/edward.png"/>
</center>
</a>
<a class="button u-full-width" href="/">Home</a>
<a class="button u-full-width" href="/getting-started">Getting Started</a>
<a class="button u-full-width" href="/tutorials/">Tutorials</a>
<a class="button u-full-width" href="/api/">API</a>
<a class="button u-full-width" href="#">Advanced</a>
<a class="button2 u-full-width" href="/design-philosophy">Design Philosophy</a>
<a class="button2 u-full-width" href="/contributing">Contributing</a>
<a class="button2 u-full-width" href="/troubleshooting">Troubleshooting</a>
<a class="button2 u-full-width" href="/license">License</a>
<div class="row" style="padding-bottom: 5%"> </div>
<a href="https://github.com/blei-lab/edward">
<!-- <object data="images/github-mark.svg" type="image/svg+xml"> -->
<img alt="Edward on Github" class="u-pull-right" src="/images/github-mark.svg" style="padding-right:10%"/>
<!-- </object> -->
</a>
<div class="row" style="padding-bottom: 5%"> </div>
</div>
<div class="nine columns">
<h2 id="api-and-documentation">API and Documentation</h2>
<div class="row" style="padding-bottom: 5%">
<div class="row" style="padding-bottom: 1%">
<a class="button3" href="/api/data">Data</a>
<a class="button3" href="/api/model">Model</a>
<a class="button3 button-primary" href="/api/inference">Inference</a>
<a class="button3" href="/api/criticism">Criticism</a>
</div>
<div class="row">
<a class="button4 button-primary" href="/api/inference-classes">Classes</a>
<a class="button4" href="/api/inference-composing">Composability</a>
<a class="button4" href="/api/inference-data-subsampling">Data Subsampling</a>
<a class="button4" href="/api/inference-development">Development</a>
</div>
</div>
<h3 id="classes-of-inference">Classes of Inference</h3>
<p>Edward uses class inheritance to provide a hierarchy of inference methods. Inference is broadly classified under three components: variational inference, Monte Carlo, and exact inference.</p>
<p><img alt="image" src="/images/inference_structure.png" width="700"/> <span><em>Dependency graph of inference methods. Nodes are classes in Edward and arrows represent class inheritance.</em></span></p>
<p>Below we highlight how to use inference algorithms from each class.</p>
<h3 id="variational-inference">Variational Inference</h3>
<p>Variational inference approximates the posterior by solving an optimization problem. We define the variational family and match its factors to latent variables in the model according to this optimization.</p>
<pre class="python" language="Python"><code>qbeta = Normal(mu=tf.Variable(tf.zeros([d])),
               sigma=tf.nn.softplus(tf.Variable(tf.ones[d])))
qz = Normal(mu=tf.Variable(tf.zeros([d])),
            sigma=tf.nn.softplus(tf.Variable(tf.ones[d])))

inference = ed.VariationalInference({beta: qbeta, z: qz}, data={x: x_train})</code></pre>
<p>Given an objective function, variational inference optimizes the factors with respect to <code>tf.Variable</code>s.</p>
<p>Maximum a posteriori (MAP) approximates the posterior using the mode. In Edward, we view MAP as a form of variational inference where the approximating family is a point mass distribution, i.e., a distribution with all probability mass concentrated at a point.</p>
<pre class="python" language="Python"><code>qbeta = PointMass(params=tf.Variable(tf.zeros([d])))
qz = PointMass(params=tf.Variable(tf.zeros([d])))

inference = ed.MAP({beta: qbeta, z: qz}, data={x: x_train})</code></pre>
<h3 id="monte-carlo">Monte Carlo</h3>
<p>Monte Carlo approximates the posterior using samples. In Edward, we view Monte Carlo as a form of inference where the approximating family is an empirical distribution.</p>
<pre class="python" language="Python"><code>T = int(1e4)  # number of samples
qbeta = Empirical(params=tf.Variable(tf.zeros([T, d]))
qz = Empirical(params=tf.variable(tf.zeros([T, d]))

inference = ed.MonteCarlo({beta: qbeta, z: qz}, data={x: x_train})</code></pre>
<p>Monte Carlo proceeds to update the <code>tf.Variable</code>s one sample at a time. Markov chain Monte Carlo does this sequentially to update the current sample (index <span class="math inline">\(t\)</span> of <code>tf.Variable</code>s) conditional on the last sample (index <span class="math inline">\(t-1\)</span> of the <code>tf.Variable</code>s).</p>
<h3 id="exact-inference">Exact Inference</h3>
<p>Edward also supports exact inference.</p>
<p>Collapsing discrete random variables. TODO has to explicitly define distribution form TODO this is a special case of the marginal below; maybe then we can organize these two as tractable marginals and tractable posteriors? (depends on if conjugacy also means tractable marginals)</p>
<pre class="python" language="Python"><code>z = Categorical(logits=tf.random_normal([K]))
x = Normal(mu=tf.gather(mus, z), sigma=tf.gather(sigmas, z))

cat = Categorical(logits=tf.Variable(tf.random_normal([K])))
components = [Normal(mu=tf.Variable(tf.random_normal([D])),
                     sigma=tf.Variable(tf.random_normal([D])))
              for _ in K]
qx = Mixture(cat=cat, components=components)

inference = CollapsedInference({x: qx})
inference.run()</code></pre>
<p>Conjugate inference. It can be used for calculating both tractable posteriors and tractable marginal densities. TODO has to explicitly define distribution form</p>
<pre class="python" language="Python"><code>z = Gamma(alpha=tf.constant([1]), beta=tf.constant([1./2]))
x = Exponential(lam=z)

qx = Gamma(alpha=tf.Variable(tf.random_normal([1])),
           beta=tf.Variable(tf.random_normal([1])))

inference = ConjugateInference({x: qx})
inference.run()</code></pre>
<p>Symbolic inference. TODO has to explicitly define distribution form of posterior functions of rvs</p>
<pre class="python" language="Python"><code>eps = Normal(mu=tf.constant([0.0]), sigma=tf.constant([1.0]))
x = mu + sigma * eps

qx = Normal(mu=tf.Variable(tf.random_normal([1])),
            sigma=tf.Variable(tf.random_normal([1])))

# using, e.g., Maple
inference = SymbolicInference({x: qx})
inference.run()</code></pre>
<p>(we can also do deterministic approximations; not sure what’s a better subsection to this)</p>
<p>Numerical integration. This includes for example Riemannian sums, Gaussian quadrature, adaptive quadrature, and quasi-Monte Carlo.</p>
<pre class="python" language="Python"><code>x = Normal(0, 1)
fx = f(x)
# TODO how to represent E_{p(x)} [ f(x) ]?

output = tf.Variable(tf.random_normal(1))

# We want E_{p(x)} [ f(x) ].
inference = GaussianQuadrature({ : output}))
inference.run()</code></pre>
<p><span><span>autogenerated</span></span></p>
</div>
</div>
<div class="row" style="padding-bottom: 25%"> </div>
</div>
<script>
  hljs.initHighlightingOnLoad();
  renderMathInElement(document.body);
</script>
</body>
</html>
