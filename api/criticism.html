<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta content="text/html; charset=utf-8" http-equiv="Content-Type"/>
<meta content="text/css" http-equiv="Content-Style-Type"/>
<meta content="pandoc" name="generator"/>
<title>Edward – Criticism</title>
<!-- Mobile Specific Metas -->
<meta content="width=device-width, initial-scale=1" name="viewport">
<!-- FONT -->
<link href="https://fonts.googleapis.com/css?family=Lora:400,400i,700" rel="stylesheet">
<!-- CSS -->
<link href="/css/normalize.css" rel="stylesheet">
<link href="/css/skeleton.css" rel="stylesheet">
<!-- Dynamically resize logo for mobile -->
<style type="text/css">
  .logo-width {
    width: 100%;
    box-sizing: border-box;
    margin-bottom: 15%;
  }
  /* Roughly the point when website is single column */
  @media (max-width: 850px) {
    .logo-width {
      width: 50%;
      box-sizing: border-box;
      margin-bottom: 5%;
    }
  }
  </style>
<!-- KaTeX -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.6.0/katex.min.js"></script>
<link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.6.0/katex.min.css" rel="stylesheet"/>
<script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.6.0/contrib/auto-render.min.js"></script>
<!-- highlight.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.4.0/highlight.min.js"></script>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.4.0/styles/github.min.css" rel="stylesheet">
<!-- Favicon -->
<link href="/icons/apple-touch-icon-57x57.png" rel="apple-touch-icon" sizes="57x57">
<link href="/icons/apple-touch-icon-60x60.png" rel="apple-touch-icon" sizes="60x60">
<link href="/icons/apple-touch-icon-72x72.png" rel="apple-touch-icon" sizes="72x72">
<link href="/icons/apple-touch-icon-76x76.png" rel="apple-touch-icon" sizes="76x76">
<link href="/icons/apple-touch-icon-114x114.png" rel="apple-touch-icon" sizes="114x114">
<link href="/icons/apple-touch-icon-120x120.png" rel="apple-touch-icon" sizes="120x120">
<link href="/icons/apple-touch-icon-144x144.png" rel="apple-touch-icon" sizes="144x144">
<link href="/icons/apple-touch-icon-152x152.png" rel="apple-touch-icon" sizes="152x152">
<link href="/icons/apple-touch-icon-180x180.png" rel="apple-touch-icon" sizes="180x180">
<link href="/icons/favicon-32x32.png" rel="icon" sizes="32x32" type="image/png">
<link href="/icons/android-chrome-192x192.png" rel="icon" sizes="192x192" type="image/png">
<link href="/icons/favicon-96x96.png" rel="icon" sizes="96x96" type="image/png">
<link href="/icons/favicon-16x16.png" rel="icon" sizes="16x16" type="image/png">
<link href="/icons/manifest.json" rel="manifest">
<link color="#5bbad5" href="/icons/safari-pinned-tab.svg" rel="mask-icon">
<link href="/icons/favicon.ico" rel="shortcut icon">
<meta content="#da532c" name="msapplication-TileColor">
<meta content="/icons/mstile-144x144.png" name="msapplication-TileImage">
<meta content="/icons/browserconfig.xml" name="msapplication-config">
<meta content="#ffffff" name="theme-color">
</meta></meta></meta></meta></link></link></link></link></link></link></link></link></link></link></link></link></link></link></link></link></link></link></link></link></meta></head>
<body>
<div class="container">
<div class="row" style="margin-top: 5%">
<div class="three columns">
<h1><a href="/">Edward</a></h1>
<a href="/">
<center>
<img alt="Edward" class="logo-width" src="/images/edward.png"/>
</center>
</a>
<a class="button u-full-width" href="/">Home</a>
<a class="button u-full-width" href="/getting-started">Getting Started</a>
<a class="button u-full-width" href="/tutorials/">Tutorials</a>
<a class="button u-full-width" href="/api/">API</a>
<a class="button u-full-width" href="#">Advanced</a>
<a class="button2 u-full-width" href="/design-philosophy">Design Philosophy</a>
<a class="button2 u-full-width" href="/contributing">Contributing</a>
<a class="button2 u-full-width" href="/troubleshooting">Troubleshooting</a>
<a class="button2 u-full-width" href="/license">License</a>
<div class="row" style="padding-bottom: 5%"> </div>
<a href="https://github.com/blei-lab/edward">
<!-- <object data="images/github-mark.svg" type="image/svg+xml"> -->
<img alt="Edward on Github" class="u-pull-right" src="/images/github-mark.svg" style="padding-right:10%"/>
<!-- </object> -->
</a>
<div class="row" style="padding-bottom: 5%"> </div>
</div>
<div class="nine columns">
<h2 id="api-and-documentation">API and Documentation</h2>
<div class="row" style="padding-bottom: 5%">
<div class="row" style="padding-bottom: 1%">
<a class="button3" href="/api/data">Data</a>
<a class="button3" href="/api/model">Model</a>
<a class="button3" href="/api/inference">Inference</a>
<a class="button3 button-primary" href="/api/criticism">Criticism</a>
</div>
</div>
<h3 id="criticism">Criticism</h3>
<p>We can never validate whether a model is true. In practice, “all models are wrong” <span class="citation">(Box, 1976)</span>. However, we can try to uncover where the model goes wrong. Model criticism helps justify the model as an approximation or point to good directions for revising the model. For background, see the criticism <a href="/tutorials/">tutorials</a>.</p>
<p>Edward explores model criticism using</p>
<ul>
<li>point-based evaluations, such as mean squared error or classification accuracy</li>
<li>posterior predictive checks, for making probabilistic assessments of the model fit using discrepancy functions</li>
</ul>
<hr/>
<span class="target" id="module-edward.criticisms"></span><dl class="function">
<dt id="edward.criticisms.evaluate">
<code class="descclassname">edward.criticisms.</code><code class="descname">evaluate</code><span class="sig-paren">(</span><em>metrics</em>, <em>data</em>, <em>latent_vars=None</em>, <em>model_wrapper=None</em>, <em>n_samples=100</em>, <em>output_key='y'</em><span class="sig-paren">)</span><a class="u-pull-right" href="https://github.com/blei-lab/edward/blob/master/edward/criticisms/evaluate.py#L13" title="Link to definition on GitHub.">[source]</a></dt>
<dd><p>Evaluate fitted model using a set of metrics.</p>
<p>A metric, or scoring rule (Winkler, 1994), is a function of observed
data under the posterior predictive distribution. For example in
supervised metrics such as classification accuracy, the observed
data (true output) is compared to the posterior predictive’s mean
(predicted output). In unsupervised metrics such as log-likelihood,
the probability of observing the data is calculated under the
posterior predictive’s log-density.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name"></col>
<col class="field-body"></col>
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>metrics</strong> : list of str or str</p>
<blockquote>
<div><p>List of metrics or a single metric:
<code class="docutils literal"><span class="pre">'binary_accuracy'</span></code>,
<code class="docutils literal"><span class="pre">'categorical_accuracy'</span></code>,
<code class="docutils literal"><span class="pre">'sparse_categorical_accuracy'</span></code>,
<code class="docutils literal"><span class="pre">'log_loss'</span></code> or <code class="docutils literal"><span class="pre">'binary_crossentropy'</span></code>,
<code class="docutils literal"><span class="pre">'categorical_crossentropy'</span></code>,
<code class="docutils literal"><span class="pre">'sparse_categorical_crossentropy'</span></code>,
<code class="docutils literal"><span class="pre">'hinge'</span></code>,
<code class="docutils literal"><span class="pre">'squared_hinge'</span></code>,
<code class="docutils literal"><span class="pre">'mse'</span></code> or <code class="docutils literal"><span class="pre">'MSE'</span></code> or <code class="docutils literal"><span class="pre">'mean_squared_error'</span></code>,
<code class="docutils literal"><span class="pre">'mae'</span></code> or <code class="docutils literal"><span class="pre">'MAE'</span></code> or <code class="docutils literal"><span class="pre">'mean_absolute_error'</span></code>,
<code class="docutils literal"><span class="pre">'mape'</span></code> or <code class="docutils literal"><span class="pre">'MAPE'</span></code> or <code class="docutils literal"><span class="pre">'mean_absolute_percentage_error'</span></code>,
<code class="docutils literal"><span class="pre">'msle'</span></code> or <code class="docutils literal"><span class="pre">'MSLE'</span></code> or <code class="docutils literal"><span class="pre">'mean_squared_logarithmic_error'</span></code>,
<code class="docutils literal"><span class="pre">'poisson'</span></code>,
<code class="docutils literal"><span class="pre">'cosine'</span></code> or <code class="docutils literal"><span class="pre">'cosine_proximity'</span></code>,
<code class="docutils literal"><span class="pre">'log_lik'</span></code> or <code class="docutils literal"><span class="pre">'log_likelihood'</span></code>.</p>
</div></blockquote>
<p><strong>data</strong> : dict</p>
<blockquote>
<div><p>Data to evaluate model with. It binds observed variables (of type
<code class="docutils literal"><span class="pre">RandomVariable</span></code>) to their realizations (of type <code class="docutils literal"><span class="pre">tf.Tensor</span></code>). It
can also bind placeholders (of type <code class="docutils literal"><span class="pre">tf.Tensor</span></code>) used in the model
to their realizations.</p>
</div></blockquote>
<p><strong>latent_vars</strong> : dict of str to RandomVariable, optional</p>
<blockquote>
<div><p>Collection of random variables binded to their inferred posterior.
It is only used (and in fact required) if the model wrapper is
specified.</p>
</div></blockquote>
<p><strong>model_wrapper</strong> : ed.Model, optional</p>
<blockquote>
<div><p>An optional wrapper for the probability model. It must have a
<code class="docutils literal"><span class="pre">predict</span></code> method, and <code class="docutils literal"><span class="pre">latent_vars</span></code> must be specified. <code class="docutils literal"><span class="pre">data</span></code> is
also changed. For TensorFlow, Python, and Stan models, the key
type is a string; for PyMC3, the key type is a Theano shared
variable. For TensorFlow, Python, and PyMC3 models, the value type
is a NumPy array or TensorFlow placeholder; for Stan, the value
type is the type according to the Stan program’s data block.</p>
</div></blockquote>
<p><strong>n_samples</strong> : int, optional</p>
<blockquote>
<div><p>Number of posterior samples for making predictions,
using the posterior predictive distribution. It is only used if
the model wrapper is specified.</p>
</div></blockquote>
<p><strong>output_key</strong> : RandomVariable or str, optional</p>
<blockquote>
<div><p>It is the key in <code class="docutils literal"><span class="pre">data</span></code> which corresponds to the model’s output.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">list of float or float</p>
<blockquote>
<div><p>A list of evaluations or a single evaluation.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Raises:</th><td class="field-body"><p class="first"><strong>NotImplementedError</strong></p>
<blockquote class="last">
<div><p>If an input metric does not match an implemented metric in Edward.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Examples</p>
<pre class="python" language="Python"><code>&gt;&gt;&gt; # build posterior predictive after inference: it is
&gt;&gt;&gt; # parameterized by posterior means
&gt;&gt;&gt; x_post = copy(x, {z: qz.mean(), beta: qbeta.mean()})
&gt;&gt;&gt;
&gt;&gt;&gt; # log-likelihood performance
&gt;&gt;&gt; evaluate('log_likelihood', data={x_post: x_train})
&gt;&gt;&gt;
&gt;&gt;&gt; # classification accuracy
&gt;&gt;&gt; # here, ``x_ph`` is any features the model is defined with respect to,
&gt;&gt;&gt; # and ``y_post`` is the posterior predictive distribution
&gt;&gt;&gt; evaluate('binary_accuracy', data={y_post: y_train, x_ph: x_train})
&gt;&gt;&gt;
&gt;&gt;&gt; # mean squared error
&gt;&gt;&gt; ed.evaluate('mean_squared_error', data={y: y_data, x: x_data})

</code>
</pre>
</dd></dl>
<dl class="function">
<dt id="edward.criticisms.ppc">
<code class="descclassname">edward.criticisms.</code><code class="descname">ppc</code><span class="sig-paren">(</span><em>T</em>, <em>data</em>, <em>latent_vars=None</em>, <em>model_wrapper=None</em>, <em>n_samples=100</em><span class="sig-paren">)</span><a class="u-pull-right" href="https://github.com/blei-lab/edward/blob/master/edward/criticisms/ppc.py#L12" title="Link to definition on GitHub.">[source]</a></dt>
<dd><p>Posterior predictive check
(Rubin, 1984; Meng, 1994; Gelman, Meng, and Stern, 1996).</p>
<p>If <code class="docutils literal"><span class="pre">latent_vars</span></code> is inputted as <code class="docutils literal"><span class="pre">None</span></code>, then it is a prior
predictive check (Box, 1980).</p>
<p>PPC’s form an empirical distribution for the predictive discrepancy,</p>
<div class="math">
\[p(T) = \int p(T(x^{rep}) | z) p(z | x) dz\]</div>
<p>by drawing replicated data sets xrep and calculating
<span class="math">\(T(x^{rep})\)</span> for each data set. Then it compares it to
<span class="math">\(T(x)\)</span>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name"></col>
<col class="field-body"></col>
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>T</strong> : function</p>
<blockquote>
<div><p>Discrepancy function, which takes a dictionary of data and
dictionary of latent variables as input and outputs a <code class="docutils literal"><span class="pre">tf.Tensor</span></code>.</p>
</div></blockquote>
<p><strong>data</strong> : dict</p>
<blockquote>
<div><p>Data to compare to. It binds observed variables (of type
<code class="docutils literal"><span class="pre">RandomVariable</span></code>) to their realizations (of type <code class="docutils literal"><span class="pre">tf.Tensor</span></code>). It
can also bind placeholders (of type <code class="docutils literal"><span class="pre">tf.Tensor</span></code>) used in the model
to their realizations.</p>
</div></blockquote>
<p><strong>latent_vars</strong> : dict of str to RandomVariable, optional</p>
<blockquote>
<div><p>Collection of random variables binded to their inferred posterior.
It is an optional argument, necessary for when the discrepancy is
a function of latent variables.</p>
</div></blockquote>
<p><strong>model_wrapper</strong> : ed.Model, optional</p>
<blockquote>
<div><p>An optional wrapper for the probability model. It must have a
<code class="docutils literal"><span class="pre">sample_likelihood</span></code> method. If <code class="docutils literal"><span class="pre">latent_vars</span></code> is not specified,
it must also have a <code class="docutils literal"><span class="pre">sample_prior</span></code> method, as <code class="docutils literal"><span class="pre">ppc</span></code> will
default to a prior predictive check. <code class="docutils literal"><span class="pre">data</span></code> is also changed. For
TensorFlow, Python, and Stan models, the key type is a string; for
PyMC3, the key type is a Theano shared variable. For TensorFlow,
Python, and PyMC3 models, the value type is a NumPy array or
TensorFlow placeholder; for Stan, the value type is the type
according to the Stan program’s data block.</p>
</div></blockquote>
<p><strong>n_samples</strong> : int, optional</p>
<blockquote>
<div><p>Number of replicated data sets.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">list of np.ndarray</p>
<blockquote class="last">
<div><p>List containing the reference distribution, which is a NumPy
array of size elements,</p>
<div class="math">
\[(T(x^{rep,1}, z^{1}), ..., T(x^{rep,size}, z^{size}))\]</div>
<p>and the realized discrepancy, which is a NumPy array of size
elements,</p>
<div class="math">
\[(T(x, z^{1}), ..., T(x, z^{size})).\]</div>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Examples</p>
<pre class="python" language="Python"><code>&gt;&gt;&gt; # build posterior predictive after inference: it is
&gt;&gt;&gt; # parameterized by posterior means
&gt;&gt;&gt; x_post = copy(x, {z: qz.mean(), beta: qbeta.mean()})
&gt;&gt;&gt;
&gt;&gt;&gt; # posterior predictive check
&gt;&gt;&gt; # T is a user-defined function of data, T(data)
&gt;&gt;&gt; T = lambda xs, zs: tf.reduce_mean(xs[x_post])
&gt;&gt;&gt; ppc(T, data={x_post: x_train})
&gt;&gt;&gt;
&gt;&gt;&gt; # in general T is a discrepancy function of the data (both response and
&gt;&gt;&gt; # covariates) and latent variables, T(data, latent_vars)
&gt;&gt;&gt; T = lambda xs, zs: tf.reduce_mean(zs['z'])
&gt;&gt;&gt; ppc(T, data={y_post: y_train, x_ph: x_train},
...     latent_vars={'z': qz, 'beta': qbeta})
&gt;&gt;&gt;
&gt;&gt;&gt; # prior predictive check
&gt;&gt;&gt; # running ppc on original x
&gt;&gt;&gt; ppc(T, data={x: x_train})

</code>
</pre>
</dd></dl>
<h3 class="unnumbered" id="references">References</h3>
<div class="references" id="refs">
<div id="ref-box1976science">
<p>Box, G. E. (1976). Science and statistics. <em>Journal of the American Statistical Association</em>, <em>71</em>(356), 791–799.</p>
</div>
</div>
</div>
</div>
<div class="row" style="padding-bottom: 25%"> </div>
</div>
<script>
  hljs.initHighlightingOnLoad();
  renderMathInElement(document.body);
</script>
</body>
</html>
