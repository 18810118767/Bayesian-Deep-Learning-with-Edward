<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta content="text/html; charset=utf-8" http-equiv="Content-Type"/>
<meta content="text/css" http-equiv="Content-Style-Type"/>
<meta content="pandoc" name="generator"/>
<title>Edward – Data</title>
<!-- Mobile Specific Metas -->
<meta content="width=device-width, initial-scale=1" name="viewport">
<!-- FONT -->
<link href="https://fonts.googleapis.com/css?family=Lora:400,400i,700" rel="stylesheet">
<!-- CSS -->
<link href="/css/normalize.css" rel="stylesheet">
<link href="/css/skeleton.css" rel="stylesheet">
<!-- Dynamically resize logo for mobile -->
<style type="text/css">
  .logo-width {
    width: 100%;
    box-sizing: border-box;
    margin-bottom: 15%;
  }
  /* Roughly the point when website is single column */
  @media (max-width: 850px) {
    .logo-width {
      width: 50%;
      box-sizing: border-box;
      margin-bottom: 5%;
    }
  }
  </style>
<!-- KaTeX -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.6.0/katex.min.js"></script>
<link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.6.0/katex.min.css" rel="stylesheet"/>
<script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.6.0/contrib/auto-render.min.js"></script>
<!-- highlight.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.4.0/highlight.min.js"></script>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.4.0/styles/github.min.css" rel="stylesheet">
<!-- Favicon -->
<link href="/icons/apple-touch-icon-57x57.png" rel="apple-touch-icon" sizes="57x57">
<link href="/icons/apple-touch-icon-60x60.png" rel="apple-touch-icon" sizes="60x60">
<link href="/icons/apple-touch-icon-72x72.png" rel="apple-touch-icon" sizes="72x72">
<link href="/icons/apple-touch-icon-76x76.png" rel="apple-touch-icon" sizes="76x76">
<link href="/icons/apple-touch-icon-114x114.png" rel="apple-touch-icon" sizes="114x114">
<link href="/icons/apple-touch-icon-120x120.png" rel="apple-touch-icon" sizes="120x120">
<link href="/icons/apple-touch-icon-144x144.png" rel="apple-touch-icon" sizes="144x144">
<link href="/icons/apple-touch-icon-152x152.png" rel="apple-touch-icon" sizes="152x152">
<link href="/icons/apple-touch-icon-180x180.png" rel="apple-touch-icon" sizes="180x180">
<link href="/icons/favicon-32x32.png" rel="icon" sizes="32x32" type="image/png">
<link href="/icons/android-chrome-192x192.png" rel="icon" sizes="192x192" type="image/png">
<link href="/icons/favicon-96x96.png" rel="icon" sizes="96x96" type="image/png">
<link href="/icons/favicon-16x16.png" rel="icon" sizes="16x16" type="image/png">
<link href="/icons/manifest.json" rel="manifest">
<link color="#5bbad5" href="/icons/safari-pinned-tab.svg" rel="mask-icon">
<link href="/icons/favicon.ico" rel="shortcut icon">
<meta content="#da532c" name="msapplication-TileColor">
<meta content="/icons/mstile-144x144.png" name="msapplication-TileImage">
<meta content="/icons/browserconfig.xml" name="msapplication-config">
<meta content="#ffffff" name="theme-color">
</meta></meta></meta></meta></link></link></link></link></link></link></link></link></link></link></link></link></link></link></link></link></link></link></link></link></meta></head>
<body>
<div class="container">
<div class="row" style="margin-top: 5%">
<div class="three columns">
<h1><a href="/">Edward</a></h1>
<a href="/">
<center>
<img alt="Edward" class="logo-width" src="/images/edward.png"/>
</center>
</a>
<a class="button u-full-width" href="/">Home</a>
<a class="button u-full-width" href="/getting-started">Getting Started</a>
<a class="button u-full-width" href="/tutorials/">Tutorials</a>
<a class="button u-full-width" href="/api/">API</a>
<a class="button u-full-width" href="#">Advanced</a>
<a class="button2 u-full-width" href="/design-philosophy">Design Philosophy</a>
<a class="button2 u-full-width" href="/contributing">Contributing</a>
<a class="button2 u-full-width" href="/troubleshooting">Troubleshooting</a>
<a class="button2 u-full-width" href="/license">License</a>
<div class="row" style="padding-bottom: 5%"> </div>
<a href="https://github.com/blei-lab/edward">
<!-- <object data="images/github-mark.svg" type="image/svg+xml"> -->
<img alt="Edward on Github" class="u-pull-right" src="/images/github-mark.svg" style="padding-right:10%"/>
<!-- </object> -->
</a>
<div class="row" style="padding-bottom: 5%"> </div>
</div>
<div class="nine columns">
<h2 id="api-and-documentation">API and Documentation</h2>
<div class="row" style="padding-bottom: 5%">
<div class="row" style="padding-bottom: 1%">
<a class="button3 button-primary" href="/api/data">Data</a>
<a class="button3" href="/api/model">Model</a>
<a class="button3" href="/api/inference">Inference</a>
<a class="button3" href="/api/criticism">Criticism</a>
<a class="button3" href="/api/stats">Statistics</a>
</div>
</div>
<h3 id="data">Data</h3>
<p>Data defines a set of observations. In Edward, data is represented as TensorFlow tensors or NumPy arrays.</p>
<pre class="python" language="Python"><code>x_data = np.array([0, 1, 0, 0, 0, 0, 0, 0, 0, 1])
x_data = tf.constant([0, 1, 0, 0, 0, 0, 0, 0, 0, 1])</code></pre>
<p>Edward can also work with batch tensors for settings when the full data does not fit in memory.</p>
<p>In general, there are three ways to read data in Edward. (They follow the <a href="https://www.tensorflow.org/versions/master/how_tos/reading_data/index.html">three ways to read data in TensorFlow</a>.)</p>
<ol>
<li><strong>Preloaded data.</strong> A constant or variable in the TensorFlow graph holds all the data.
<p>This setting is the fastest to work with and is recommended if the data fits in memory.</p>
<p>Represent the data as NumPy arrays. Internally, during inference, we will store them in TensorFlow variables to prevent copying data more than once in memory. (As an example, see the <a href="https://github.com/blei-lab/edward/blob/master/examples/tf_mixture_gaussian.py">mixture of Gaussians</a>.)</p></li>
<li><strong>Feeding.</strong> Manual code provides the data when running each step of inference.
<p>This setting provides the most fine-grained control which is useful for experimentation.</p>
<p>Represent the data as TensorFlow placeholders. During inference, the user must manually feed the placeholders at each step by first initializing via <code>inference.initialize()</code>; then in a loop call <code>inference.update(feed_dict=...)</code> where <code>feed_dict</code> carries the values for the <code>tf.placeholder</code>’s. (As an example, see the <a href="https://github.com/blei-lab/edward/blob/master/examples/bayesian_linear_regression.py">Bayesian linear regression</a>.)</p></li>
<li><strong>Reading from files.</strong> An input pipeline reads the data from files at the beginning of a TensorFlow graph.
<p>This setting is recommended if the data does not fit in memory.</p>
<p>Represent the data as TensorFlow tensors, where the tensors are the output of data readers. During inference, each update will be automatically evaluated over new batch tensors represented through the data readers. (As an example, see the <a href="https://github.com/blei-lab/edward/blob/master/tests/test_inference_data.py">data unit test</a>.)</p></li>
</ol>
<h3 id="training-models-with-data">Training Models with Data</h3>
<p>To pass in data during inference, we form a Python dictionary. Each item in the dictionary has a random variable binded to the data values.</p>
<pre class="python" language="Python"><code># assuming `x` and `y` form observed variables in the model
data = {x: x_data, y: y_data}</code></pre>
<p>How do we use the data during training? In general there are three use cases:</p>
<ol>
<li><strong>Train over the full data per step.</strong>
<p>Follow the setting of preloaded data.</p></li>
<li><strong>Train over a batch per step when the full data fits in memory.</strong> This scales inference in terms of computational complexity.
<p>Follow the setting of preloaded data. Specify the batch size with <code>n_minibatch</code> in <code>Inference</code>. By default, we will subsample by slicing along the first dimension of every data structure in the data dictionary. Alternatively, follow the setting of feeding. Manually deal with the batch behavior at each training step.</p></li>
<li><strong>Train over batches per step when the full data does not fit in memory.</strong> This scales inference in terms of computational complexity and memory complexity.
<p>Follow the setting of reading from files. Alternatively, follow the setting of feeding, and use a generator to create and destroy NumPy arrays on the fly for feeding the placeholders.</p></li>
</ol>
<h3 id="training-model-wrappers-with-data">Training Model Wrappers with Data</h3>
<p>During inference, data is passed in differently for external languages which use a model wrapper. Instead of binding observed variables, it is usually comprised of strings binded to the values, such as a key <code>’x’</code> with value <code>np.array([0.23512, 13.2])</code>. We detail specifics for each wrapper below.</p>
<ul>
<li><strong>TensorFlow.</strong> The data carries whatever keys and values the user accesses in the user-defined model. Key is a string. Value is a NumPy array or TensorFlow tensor.
<pre class="python" language="Python"><code>class BetaBernoulli:
  def log_prob(self, xs, zs):
    log_prior = beta.logpdf(zs['p'], a=1.0, b=1.0)
    log_lik = tf.reduce_sum(bernoulli.logpmf(xs['x'], p=zs['p']))
    return log_lik + log_prior</code></pre>
<p>model = BetaBernoulli() data = <span>’x’: np.array([0, 1, 0, 0, 0, 0, 0, 0, 0, 1])</span></p></li>
<li><strong>Python.</strong> The data carries whatever keys and values the user accesses in the user-defined model. Key is a string. Value is a NumPy array or TensorFlow tensor.
<pre class="python" language="Python"><code>class BetaBernoulli(PythonModel):
  def _py_log_prob(self, xs, zs):
    log_prior = beta.logpdf(zs['p'], a=1.0, b=1.0)
    log_lik = np.sum(bernoulli.logpmf(xs['x'], p=zs['p']))
    return log_lik + log_prior

model = BetaBernoulli()
data = {'x': np.array([0, 1, 0, 0, 0, 0, 0, 0, 0, 1])}</code></pre></li>
<li><strong>PyMC3.</strong> The data binds Theano shared variables, which are used to mark the observed PyMC3 random variables, to their realizations. Key is a Theano shared variable. Value is a NumPy array or TensorFlow tensor.
<pre class="python" language="Python"><code>x_obs = theano.shared(np.zeros(1))
with pm.Model() as pm_model:
  p = pm.Beta('p', 1, 1, transform=None)
  x = pm.Bernoulli('x', p, observed=x_obs)

model = PyMC3Model(pm_model)
data = {x_obs: np.array([0, 1, 0, 0, 0, 0, 0, 0, 0, 1])}</code></pre></li>
<li><strong>Stan.</strong> The data is according to the Stan program’s data block. Key is a string. Value is whatever type is used for the data block.
<pre class="python" language="Python"><code>model_code = """
  data {
    int&lt;lower=0&gt; N;
    int&lt;lower=0,upper=1&gt; x[N];
  }
  parameters {
    real&lt;lower=0,upper=1&gt; p;
  }
  model {
    p ~ beta(1.0, 1.0);
    for (n in 1:N)
    x[n] ~ bernoulli(p);
  }
"""
model = ed.StanModel(model_code=model_code)
data = {'N': 10, 'x': [0, 1, 0, 0, 0, 0, 0, 0, 0, 1]}</code></pre></li>
</ul>
<p>Note that for these model wrappers, all 3 use cases for training models with data are supported. However, Stan is limited to training over the full data per step. (This because Stan’s data structure requires data subsampling on arbitrary data types, which we don’t know how to automate.)</p>
</div>
</div>
<div class="row" style="padding-bottom: 25%"> </div>
</div>
<script>
  hljs.initHighlightingOnLoad();
  renderMathInElement(document.body);
</script>
</body>
</html>
