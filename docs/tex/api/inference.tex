\title{Inference}

{{navbar}}

\subsubsection{Inference}

Given a model $p(x, z)$ and data set $x$,
an inference algorithm infers the posterior distribution $p(z\mid x)$
of the latent variables given data. For more details, see the
\href{/tutorials/inference}
{Inference of Probability Models tutorial}.

Here are a few example use cases.
%
\begin{lstlisting}[language=Python]
z = RandomVariable()
x = RandomVariable(par=z)

qz = RandomVariable(par=tf.Variable())

# infer q(z) \approx p(z | x = x_data)
inference = Inference({z: qz}, {x: x_data})
\end{lstlisting}
\begin{lstlisting}[language=Python]
x = RandomVariable()

qx = RandomVariable(par=tf.Variable())

# infer q(x; lambda) \approx p(x)
inference = Inference({x: qx})
\end{lstlisting}
%
Running inference is as simple as the following:
\begin{lstlisting}[language=Python]
inference = Inference({z: qz}, data={x: np.array()})
inference.run()
\end{lstlisting}
%
Inference also supports fine-grained control of the training procedure.
%
\begin{lstlisting}[language=Python]
inference = ed.Inference({z: qz}, data={x: np.array()})
inference.initialize()

init = tf.initialize_all_variables()
init.run()

for _ in range(inference.n_iter):
  info_dict = inference.update()
  inference.print_progress(info_dict)

inference.finalize()
\end{lstlisting}

{{autogenerated}}
