<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta content="text/html; charset=utf-8" http-equiv="Content-Type"/>
<meta content="text/css" http-equiv="Content-Style-Type"/>
<meta content="pandoc" name="generator"/>
<title>Edward – Delving In</title>
<!-- Mobile Specific Metas -->
<meta content="width=device-width, initial-scale=1" name="viewport">
<!-- FONT -->
<link href="https://fonts.googleapis.com/css?family=Lora:400,400i,700" rel="stylesheet">
<!-- CSS -->
<link href="css/normalize.css" rel="stylesheet">
<link href="css/skeleton.css" rel="stylesheet">
<!-- Dynamically resize logo for mobile -->
<style type="text/css">
  .logo-width {
    width: 100%;
    box-sizing: border-box;
    margin-bottom: 15%;
  }
  /* Roughly the point when website is single column */
  @media (max-width: 850px) {
    .logo-width {
      width: 50%;
      box-sizing: border-box;
      margin-bottom: 5%;
    }
  }
  </style>
<!-- KaTeX -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.6.0/katex.min.js"></script>
<link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.6.0/katex.min.css" rel="stylesheet"/>
<script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.6.0/contrib/auto-render.min.js"></script>
<!-- highlight.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.4.0/highlight.min.js"></script>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.4.0/styles/github.min.css" rel="stylesheet">
<!-- Favicon -->
<link href="icons/apple-touch-icon-57x57.png" rel="apple-touch-icon" sizes="57x57">
<link href="icons/apple-touch-icon-60x60.png" rel="apple-touch-icon" sizes="60x60">
<link href="icons/apple-touch-icon-72x72.png" rel="apple-touch-icon" sizes="72x72">
<link href="icons/apple-touch-icon-76x76.png" rel="apple-touch-icon" sizes="76x76">
<link href="icons/apple-touch-icon-114x114.png" rel="apple-touch-icon" sizes="114x114">
<link href="icons/apple-touch-icon-120x120.png" rel="apple-touch-icon" sizes="120x120">
<link href="icons/apple-touch-icon-144x144.png" rel="apple-touch-icon" sizes="144x144">
<link href="icons/apple-touch-icon-152x152.png" rel="apple-touch-icon" sizes="152x152">
<link href="icons/apple-touch-icon-180x180.png" rel="apple-touch-icon" sizes="180x180">
<link href="icons/favicon-32x32.png" rel="icon" sizes="32x32" type="image/png">
<link href="icons/android-chrome-192x192.png" rel="icon" sizes="192x192" type="image/png">
<link href="icons/favicon-96x96.png" rel="icon" sizes="96x96" type="image/png">
<link href="icons/favicon-16x16.png" rel="icon" sizes="16x16" type="image/png">
<link href="icons/manifest.json" rel="manifest">
<link color="#5bbad5" href="icons/safari-pinned-tab.svg" rel="mask-icon">
<link href="icons/favicon.ico" rel="shortcut icon">
<meta content="#da532c" name="msapplication-TileColor">
<meta content="icons/mstile-144x144.png" name="msapplication-TileImage">
<meta content="icons/browserconfig.xml" name="msapplication-config">
<meta content="#ffffff" name="theme-color">
</meta></meta></meta></meta></link></link></link></link></link></link></link></link></link></link></link></link></link></link></link></link></link></link></link></link></meta></head>
<body>
<div class="container">
<div class="row" style="margin-top: 5%">
<div class="three columns">
<h1><a href="/">Edward</a></h1>
<a href="/">
<center>
<img alt="Edward" class="logo-width" src="images/edward.png"/>
</center>
</a>
<a class="button u-full-width" href="/">Home</a>
<a class="button u-full-width" href="getting-started">Getting Started</a>
<a class="button u-full-width" href="delving-in">Delving In</a>
<a class="button u-full-width" href="tutorials">Tutorials</a>
<a class="button u-full-width" href="api/">API</a>
<a class="button u-full-width" href="#">Advanced</a>
<a class="button2 u-full-width" href="design-philosophy">Design Philosophy</a>
<a class="button2 u-full-width" href="contributing">Contributing</a>
<a class="button2 u-full-width" href="troubleshooting">Troubleshooting</a>
<a class="button2 u-full-width" href="license">License</a>
<div class="row" style="padding-bottom: 5%"> </div>
<a href="https://github.com/blei-lab/edward">
<!-- <object data="images/github-mark.svg" type="image/svg+xml"> -->
<img alt="Edward on Github" class="u-pull-right" src="images/github-mark.svg" style="padding-right:10%"/>
<!-- </object> -->
</a>
<div class="row" style="padding-bottom: 5%"> </div>
</div>
<div class="nine columns">
<h2 id="delving-in">Delving In</h2>
<p>Edward’s design reflects the building blocks for probabilistic modeling. It defines interchangeable components, enabling rapid experimentation and research with probabilistic models. Here we provide an overview of the design.</p>
<p>Edward is named after the innovative statistician <a href="https://en.wikipedia.org/wiki/George_E._P._Box">George Edward Pelham Box</a>. Edward follows Box’s philosophy of statistics and machine learning <span class="citation">(Box, 1976)</span>.</p>
<p>First gather data from some real-world phenomena. Then cycle through <a href="http://www.annualreviews.org/eprint/7xbyci3nwAg5kEttvvjk/full/10.1146/annurev-statistics-022513-115657">Box’s loop</a> <span class="citation">(Blei, 2014)</span>.</p>
<ol>
<li>Build a probabilistic model of the phenomena.</li>
<li>Reason about the phenomena given model and data.</li>
<li>Criticize the model, revise and repeat.</li>
</ol>
<p><img alt="image" src="images/model_infer_criticize.png"/></p>
<p>Here’s a toy example. A child flips a coin ten times, with the set of outcomes being <code>[0, 1, 0, 0, 0, 0, 0, 0, 0, 1]</code>, where <code>0</code> denotes tails and <code>1</code> denotes heads. She is interested in the probability that the coin lands heads. First, build a model: assume the coin flips are independent and land heads with the same probability. Second, reason about the phenomenon: use an algorithm to infer the model given data. Third, criticize the model: analyze whether the model captures the real-world phenomenon of coin flips. If it doesn’t, then revise the model and repeat.</p>
<p>This process defines the design of Edward. Four objects enable this analysis.</p>
<h3 id="data">Data</h3>
<p>Data defines a set of observations. In Edward, data is represented as TensorFlow tensors or NumPy arrays.</p>
<pre class="python" language="Python"><code>x_data = np.array([0, 1, 0, 0, 0, 0, 0, 0, 0, 1])</code></pre>
<p>Edward can also work with batch tensors for settings when the full data does not fit in memory.</p>
<h3 id="models">Models</h3>
<p>A probabilistic model is a joint distribution <span class="math inline">\(p(x, z)\)</span> of data <span class="math inline">\(x\)</span> and latent variables <span class="math inline">\(z\)</span>. In Edward, we specify it using a simple language of random variables.</p>
<pre class="python" language="Python"><code>p = Beta(a=1.0, b=1.0)
x = Bernoulli(p=tf.ones(10) * p)</code></pre>
<p>Here, we define <code>p</code> as a scalar random variable. It is a latent probability to a Bernoulli likelihood, and this probability is shared across data points.</p>
<p>Edward also supports other languages for specifying probability models: TensorFlow, Python, PyMC3, and Stan. More details are available in the <a href="api/models">model API</a>.</p>
<h3 id="inference">Inference</h3>
<p>Given a model and data, we aim to reason about <span class="math inline">\(z\)</span>: the model’s hidden structure. The posterior distribution <span class="math inline">\(p(z \mid x)\)</span> captures our reasoning: its mean describes our best guess of the hidden structure, and its variance describes the uncertainty around our best guess.</p>
<p>Edward has many inference algorithms and makes it easy to develop new ones.</p>
<p><img alt="image" src="images/inference_structure.png"/> <span><em>Dependency graph of inference methods. Nodes are classes in Edward and arrows represent class inheritance.</em></span></p>
<p>Edward focuses on variational inference. It views posterior inference as positing a model of the latent variables <span class="math inline">\(q(z \;;\; \lambda)\)</span> and optimizing it to approximate the posterior <span class="math inline">\(p(z \mid x)\)</span>.</p>
<p>Variational models are defined using the same language of random variables. For example, to specify a variational model (e.g. for a Gaussian mixture) <span class="math display">\[\begin{aligned}
  q(z \;;\; \lambda)
  &amp;=
  \text{Dirichlet}(z_\pi)
  \times
  \mathcal{N}(z_\mu)
  \times
  \text{InverseGamma}(z_\sigma)\end{aligned}\]</span> we would write</p>
<pre class="python" language="Python"><code>from edward.models import Dirichlet, Normal, InverseGamma

qpi_alpha = tf.nn.softplus(tf.Variable(tf.random_normal([K])))
qmu_mu = tf.Variable(tf.random_normal([K * D]))
qmu_sigma = tf.nn.softplus(tf.Variable(tf.random_normal([K * D])))
qsigma_alpha = tf.nn.softplus(tf.Variable(tf.random_normal([K * D])))
qsigma_beta = tf.nn.softplus(tf.Variable(tf.random_normal([K * D])))

qpi = Dirichlet(alpha=qpi_alpha)
qmu = Normal(mu=qmu_mu, sigma=qmu_sigma)
qsigma = InverseGamma(alpha=qsigma_alpha, beta=qsigma_beta)</code></pre>
<p>Each algorithm derived from <code>VariationalInference</code> minimizes a different loss function between the variational model and the posterior. For example, suppose we aim to minimize the Kullback-Leibler divergence <span class="math display">\[\begin{aligned}
  \text{KL}(p(z \mid x) \;\|\; q(z \;;\; \lambda))\end{aligned}\]</span> Instantiate the inference class: bind each latent variable to its corresponding variational distribution; then pass in data, which binds each observed variable to data that we condition on. Then run the inference.</p>
<pre class="python" language="Python"><code>data = {x: x_data}
inference = ed.KLpq({pi: qpi, mu: qmu, sigma: qsigma}, data)
inference.run(n_iter=500, n_minibatch=5)</code></pre>
<p>This runs the <code>KLpq</code> minimization algorithm for <code>500</code> iterations, using a batch of <code>5</code> data points per iteration.</p>
<h3 id="criticism">Criticism</h3>
<p>Criticizing models and their inference is a crucial step in analysis. Following falsificationists such as Popper and Box, no model will exactly describe the natural phenomena we seek to analyze; in other words, “all models are wrong”. Thus we would like to uncover where and how the model goes wrong.</p>
<p>Edward explores model and inference criticism using</p>
<ul>
<li>point-based evaluations, such as mean squared error or classification accuracy</li>
</ul>
<pre class="python" language="Python"><code>ed.evaluate('mean_squared_error', data={y: y_data, x: x_data})</code></pre>
<ul>
<li>posterior predictive checks, for making probabilistic assessments of the model fit using discrepancy functions</li>
</ul>
<pre class="python" language="Python"><code>T = lambda xs, zs: tf.reduce_mean(xs[x])
ed.ppc(T, data={x: x_data})</code></pre>
<p>See the <a class="uri" href="tutorials">tutorials</a> for examples of models, inference, and criticism in Edward.</p>
<p>See the <a href="api/">API</a> for details of how Edward implements these objects.</p>
<h3 class="unnumbered" id="references">References</h3>
<div class="references" id="refs">
<div id="ref-blei2014build">
<p>Blei, D. M. (2014). Build, compute, critique, repeat: Data analysis with latent variable models. <em>Annual Review of Statistics and Its Application</em>, <em>1</em>, 203–232.</p>
</div>
<div id="ref-box1976science">
<p>Box, G. E. (1976). Science and statistics. <em>Journal of the American Statistical Association</em>, <em>71</em>(356), 791–799.</p>
</div>
</div>
</div>
</div>
<div class="row" style="padding-bottom: 25%"> </div>
</div>
<script>
  hljs.initHighlightingOnLoad();
  renderMathInElement(document.body);
</script>
</body>
</html>
