

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>edward.util &mdash; Edward 1.0.9 documentation</title>
  

  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  

  

  
    <link rel="top" title="Edward 1.0.9 documentation" href="../../index.html"/>
        <link rel="up" title="Module code" href="../index.html"/> 

  
  <script src="../../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../../index.html" class="icon icon-home"> Edward
          

          
          </a>

          
            
            
              <div class="version">
                1.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
                <ul>
<li class="toctree-l1"><a class="reference internal" href="../../data.html">Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../models.html">Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../inferences.html">Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../criticisms.html">Criticism</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../edward.html">edward package</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="../../index.html">Edward</a>
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          





<div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../../index.html">Docs</a> &raquo;</li>
      
          <li><a href="../index.html">Module code</a> &raquo;</li>
      
    <li>edward.util</li>
      <li class="wy-breadcrumbs-aside">
        
          
        
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for edward.util</h1><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">__future__</span> <span class="k">import</span> <span class="n">absolute_import</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="k">import</span> <span class="n">division</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="k">import</span> <span class="n">print_function</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">six</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="kn">from</span> <span class="nn">copy</span> <span class="k">import</span> <span class="n">deepcopy</span>
<span class="kn">from</span> <span class="nn">edward.models.random_variable</span> <span class="k">import</span> <span class="n">RandomVariable</span>
<span class="kn">from</span> <span class="nn">tensorflow.core.framework</span> <span class="k">import</span> <span class="n">attr_value_pb2</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.ops</span> <span class="k">import</span> <span class="n">control_flow_ops</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.framework.ops</span> <span class="k">import</span> <span class="n">set_shapes_for_outputs</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.util</span> <span class="k">import</span> <span class="n">compat</span>

<span class="n">distributions</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">distributions</span>


<div class="viewcode-block" id="copy"><a class="viewcode-back" href="../../edward.util.html#edward.util.copy">[docs]</a><span class="k">def</span> <span class="nf">copy</span><span class="p">(</span><span class="n">org_instance</span><span class="p">,</span> <span class="n">dict_swap</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">scope</span><span class="o">=</span><span class="s2">&quot;copied&quot;</span><span class="p">,</span>
         <span class="n">replace_itself</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">copy_q</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Build a new node in the TensorFlow graph from `org_instance`,</span>
<span class="sd">  where any of its ancestors existing in `dict_swap` are</span>
<span class="sd">  replaced with `dict_swap`&#39;s corresponding value.</span>

<span class="sd">  The copying is done recursively, so any `Operation` whose output</span>
<span class="sd">  is required to evaluate `org_instance` is also copied (if it isn&#39;t</span>
<span class="sd">  already copied within the new scope). This is with the exception of</span>
<span class="sd">  `tf.Variable`s and `tf.placeholder`s, which are reused and not newly copied.</span>

<span class="sd">  Parameters</span>
<span class="sd">  ----------</span>
<span class="sd">  org_instance : RandomVariable, tf.Variable, tf.Tensor, or tf.Operation</span>
<span class="sd">    Node to add in graph with replaced ancestors.</span>
<span class="sd">  dict_swap : dict, optional</span>
<span class="sd">    Random variables, variables, tensors, or operations to swap with.</span>
<span class="sd">    Its keys are what `org_instance` may depend on, and its values are</span>
<span class="sd">    the corresponding object (not necessarily of the same class</span>
<span class="sd">    instance, but must have the same type, e.g., float32) that is used</span>
<span class="sd">    in exchange.</span>
<span class="sd">  scope : str, optional</span>
<span class="sd">    A scope for the new node(s). This is used to avoid name</span>
<span class="sd">    conflicts with the original node(s).</span>
<span class="sd">  replace_itself : bool, optional</span>
<span class="sd">    Whether to replace `org_instance` itself if it exists in</span>
<span class="sd">    `dict_swap`. (This is used for the recursion.)</span>
<span class="sd">  copy_q : bool, optional</span>
<span class="sd">    Whether to copy the replaced tensors too (if not already</span>
<span class="sd">    copied within the new scope). Otherwise will reuse them.</span>

<span class="sd">  Returns</span>
<span class="sd">  -------</span>
<span class="sd">  RandomVariable, tf.Variable, tf.Tensor, or tf.Operation</span>
<span class="sd">    The copied node.</span>

<span class="sd">  Raises</span>
<span class="sd">  ------</span>
<span class="sd">  TypeError</span>
<span class="sd">    If `org_instance` is not one of the above types.</span>

<span class="sd">  Examples</span>
<span class="sd">  --------</span>
<span class="sd">  &gt;&gt;&gt; x = tf.constant(2.0)</span>
<span class="sd">  &gt;&gt;&gt; y = tf.constant(3.0)</span>
<span class="sd">  &gt;&gt;&gt; z = x * y</span>
<span class="sd">  &gt;&gt;&gt;</span>
<span class="sd">  &gt;&gt;&gt; qx = tf.constant(4.0)</span>
<span class="sd">  &gt;&gt;&gt; # The TensorFlow graph is currently</span>
<span class="sd">  &gt;&gt;&gt; # `x` -&gt; `z` &lt;- y`, `qx`</span>
<span class="sd">  &gt;&gt;&gt;</span>
<span class="sd">  &gt;&gt;&gt; # This adds a subgraph with newly copied nodes,</span>
<span class="sd">  &gt;&gt;&gt; # `copied/qx` -&gt; `copied/z` &lt;- `copied/y`</span>
<span class="sd">  &gt;&gt;&gt; z_new = copy(z, {x: qx})</span>
<span class="sd">  &gt;&gt;&gt;</span>
<span class="sd">  &gt;&gt;&gt; sess = tf.Session()</span>
<span class="sd">  &gt;&gt;&gt; sess.run(z)</span>
<span class="sd">  6.0</span>
<span class="sd">  &gt;&gt;&gt; sess.run(z_new)</span>
<span class="sd">  12.0</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">org_instance</span><span class="p">,</span> <span class="n">RandomVariable</span><span class="p">)</span> <span class="ow">and</span> \
     <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">org_instance</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">)</span> <span class="ow">and</span> \
     <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">org_instance</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="ow">and</span> \
     <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">org_instance</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Operation</span><span class="p">):</span>
    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;Could not copy instance: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">org_instance</span><span class="p">))</span>

  <span class="k">if</span> <span class="n">dict_swap</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">dict_swap</span> <span class="o">=</span> <span class="p">{}</span>

  <span class="c1"># Swap instance if in dictionary.</span>
  <span class="k">if</span> <span class="n">org_instance</span> <span class="ow">in</span> <span class="n">dict_swap</span> <span class="ow">and</span> <span class="n">replace_itself</span><span class="p">:</span>
    <span class="n">org_instance</span> <span class="o">=</span> <span class="n">dict_swap</span><span class="p">[</span><span class="n">org_instance</span><span class="p">]</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">copy_q</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">org_instance</span>
  <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">org_instance</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="ow">and</span> <span class="n">replace_itself</span><span class="p">:</span>
    <span class="c1"># Deal with case when `org_instance` is the associated tensor</span>
    <span class="c1"># from the RandomVariable, e.g., `z.value()`. If</span>
    <span class="c1"># `dict_swap={z: qz}`, we aim to swap it with `qz.value()`.</span>
    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">six</span><span class="o">.</span><span class="n">iteritems</span><span class="p">(</span><span class="n">dict_swap</span><span class="p">):</span>
      <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">RandomVariable</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">org_instance</span> <span class="o">==</span> <span class="n">key</span><span class="o">.</span><span class="n">value</span><span class="p">():</span>
          <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">RandomVariable</span><span class="p">):</span>
            <span class="n">org_instance</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">value</span><span class="p">()</span>
          <span class="k">else</span><span class="p">:</span>
            <span class="n">org_instance</span> <span class="o">=</span> <span class="n">value</span>

          <span class="k">if</span> <span class="ow">not</span> <span class="n">copy_q</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">org_instance</span>
          <span class="k">break</span>

  <span class="n">graph</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_default_graph</span><span class="p">()</span>
  <span class="n">new_name</span> <span class="o">=</span> <span class="n">scope</span> <span class="o">+</span> <span class="s1">&#39;/&#39;</span> <span class="o">+</span> <span class="n">org_instance</span><span class="o">.</span><span class="n">name</span>

  <span class="c1"># If an instance of the same name exists, return appropriately.</span>
  <span class="c1"># Do this for random variables.</span>
  <span class="n">random_variables</span> <span class="o">=</span> <span class="p">{</span><span class="n">x</span><span class="o">.</span><span class="n">name</span><span class="p">:</span> <span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span>
                      <span class="n">graph</span><span class="o">.</span><span class="n">get_collection</span><span class="p">(</span><span class="s1">&#39;_random_variable_collection_&#39;</span><span class="p">)}</span>
  <span class="k">if</span> <span class="n">new_name</span> <span class="ow">in</span> <span class="n">random_variables</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">random_variables</span><span class="p">[</span><span class="n">new_name</span><span class="p">]</span>

  <span class="c1"># Do this for tensors and operations.</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">already_present</span> <span class="o">=</span> <span class="n">graph</span><span class="o">.</span><span class="n">as_graph_element</span><span class="p">(</span><span class="n">new_name</span><span class="p">,</span>
                                             <span class="n">allow_tensor</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                             <span class="n">allow_operation</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">already_present</span>
  <span class="k">except</span><span class="p">:</span>
    <span class="k">pass</span>

  <span class="c1"># If instance is a variable, return it; do not re-copy any.</span>
  <span class="c1"># Note we check variables via their name and not their type. This</span>
  <span class="c1"># is because if we get variables through an op&#39;s inputs, it has</span>
  <span class="c1"># type tf.Tensor: we can only tell it is a variable via its name.</span>
  <span class="n">variables</span> <span class="o">=</span> <span class="p">{</span><span class="n">x</span><span class="o">.</span><span class="n">name</span><span class="p">:</span> <span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">graph</span><span class="o">.</span><span class="n">get_collection</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">GraphKeys</span><span class="o">.</span><span class="n">VARIABLES</span><span class="p">)}</span>
  <span class="k">if</span> <span class="n">org_instance</span><span class="o">.</span><span class="n">name</span> <span class="ow">in</span> <span class="n">variables</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="n">variables</span><span class="p">[</span><span class="n">org_instance</span><span class="o">.</span><span class="n">name</span><span class="p">]</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>

  <span class="c1"># Do the same for placeholders. Same logic holds.</span>
  <span class="c1"># Note this assumes that placeholders are all in this collection.</span>
  <span class="n">placeholders</span> <span class="o">=</span> <span class="p">{</span><span class="n">x</span><span class="o">.</span><span class="n">name</span><span class="p">:</span> <span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">graph</span><span class="o">.</span><span class="n">get_collection</span><span class="p">(</span><span class="s1">&#39;PLACEHOLDERS&#39;</span><span class="p">)}</span>
  <span class="k">if</span> <span class="n">org_instance</span><span class="o">.</span><span class="n">name</span> <span class="ow">in</span> <span class="n">placeholders</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="n">placeholders</span><span class="p">[</span><span class="n">org_instance</span><span class="o">.</span><span class="n">name</span><span class="p">]</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>

  <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">org_instance</span><span class="p">,</span> <span class="n">RandomVariable</span><span class="p">):</span>
    <span class="n">rv</span> <span class="o">=</span> <span class="n">org_instance</span>

    <span class="c1"># If it has copiable arguments, copy them.</span>
    <span class="n">dist_args</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">six</span><span class="o">.</span><span class="n">iteritems</span><span class="p">(</span><span class="n">rv</span><span class="o">.</span><span class="n">_dist_args</span><span class="p">):</span>
      <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">RandomVariable</span><span class="p">)</span> <span class="ow">or</span> \
         <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">)</span> <span class="ow">or</span> \
         <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="ow">or</span> \
         <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Operation</span><span class="p">):</span>
         <span class="n">value</span> <span class="o">=</span> <span class="n">copy</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">dict_swap</span><span class="p">,</span> <span class="n">scope</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="n">copy_q</span><span class="p">)</span>

      <span class="n">dist_args</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>

    <span class="n">dist_args</span><span class="p">[</span><span class="s1">&#39;name&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">new_name</span> <span class="o">+</span> <span class="n">rv</span><span class="o">.</span><span class="n">distribution</span><span class="o">.</span><span class="n">name</span>

    <span class="c1"># Copy a new `rv` with any newly copied arguments.</span>
    <span class="c1"># We do this by creating an empty class object and setting</span>
    <span class="c1"># its attributes. (This is to avoid a throwaway tensor in the</span>
    <span class="c1"># graph, during instantiation of DistributionTensor.)</span>
    <span class="n">new_rv</span> <span class="o">=</span> <span class="n">Empty</span><span class="p">()</span>
    <span class="n">new_rv</span><span class="o">.</span><span class="n">__class__</span> <span class="o">=</span> <span class="n">rv</span><span class="o">.</span><span class="n">__class__</span>
    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">six</span><span class="o">.</span><span class="n">iteritems</span><span class="p">(</span><span class="n">rv</span><span class="o">.</span><span class="n">__dict__</span><span class="p">):</span>
      <span class="k">if</span> <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;_name&#39;</span><span class="p">,</span> <span class="s1">&#39;_dist_args&#39;</span><span class="p">,</span> <span class="s1">&#39;_dist&#39;</span><span class="p">,</span> <span class="s1">&#39;_value&#39;</span><span class="p">]:</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="n">new_rv</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">value</span><span class="p">))</span>

    <span class="nb">setattr</span><span class="p">(</span><span class="n">new_rv</span><span class="p">,</span> <span class="s1">&#39;_name&#39;</span><span class="p">,</span> <span class="n">new_name</span><span class="p">)</span>
    <span class="nb">setattr</span><span class="p">(</span><span class="n">new_rv</span><span class="p">,</span> <span class="s1">&#39;_dist_args&#39;</span><span class="p">,</span> <span class="n">dist_args</span><span class="p">)</span>
    <span class="nb">setattr</span><span class="p">(</span><span class="n">new_rv</span><span class="p">,</span> <span class="s1">&#39;_dist&#39;</span><span class="p">,</span> <span class="n">new_rv</span><span class="o">.</span><span class="n">_dist_cls</span><span class="p">(</span><span class="o">**</span><span class="n">new_rv</span><span class="o">.</span><span class="n">_dist_args</span><span class="p">))</span>
    <span class="nb">setattr</span><span class="p">(</span><span class="n">new_rv</span><span class="p">,</span> <span class="s1">&#39;_value&#39;</span><span class="p">,</span> <span class="n">new_rv</span><span class="o">.</span><span class="n">_dist</span><span class="o">.</span><span class="n">sample</span><span class="p">())</span>
    <span class="k">return</span> <span class="n">new_rv</span>
  <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">org_instance</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
    <span class="n">tensor</span> <span class="o">=</span> <span class="n">org_instance</span>

    <span class="c1"># A tensor is one of the outputs of its underlying</span>
    <span class="c1"># op. Therefore copy the op itself.</span>
    <span class="n">op</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">op</span>
    <span class="n">new_op</span> <span class="o">=</span> <span class="n">copy</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="n">dict_swap</span><span class="p">,</span> <span class="n">scope</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="n">copy_q</span><span class="p">)</span>

    <span class="n">output_index</span> <span class="o">=</span> <span class="n">op</span><span class="o">.</span><span class="n">outputs</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span>
    <span class="n">new_tensor</span> <span class="o">=</span> <span class="n">new_op</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="n">output_index</span><span class="p">]</span>

    <span class="c1"># Add copied tensor to collections that the original one is in.</span>
    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">collection</span> <span class="ow">in</span> <span class="n">tensor</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">_collections</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
      <span class="k">if</span> <span class="n">tensor</span> <span class="ow">in</span> <span class="n">collection</span><span class="p">:</span>
        <span class="n">graph</span><span class="o">.</span><span class="n">add_to_collection</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">new_tensor</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">new_tensor</span>
  <span class="k">else</span><span class="p">:</span>  <span class="c1"># tf.Operation</span>
    <span class="n">op</span> <span class="o">=</span> <span class="n">org_instance</span>

    <span class="c1"># If it has an original op, copy it.</span>
    <span class="k">if</span> <span class="n">op</span><span class="o">.</span><span class="n">_original_op</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">new_original_op</span> <span class="o">=</span> <span class="n">copy</span><span class="p">(</span><span class="n">op</span><span class="o">.</span><span class="n">_original_op</span><span class="p">,</span> <span class="n">dict_swap</span><span class="p">,</span> <span class="n">scope</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="n">copy_q</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">new_original_op</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="c1"># If it has control inputs, copy them.</span>
    <span class="n">new_control_inputs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">op</span><span class="o">.</span><span class="n">control_inputs</span><span class="p">:</span>
      <span class="n">elem</span> <span class="o">=</span> <span class="n">copy</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dict_swap</span><span class="p">,</span> <span class="n">scope</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="n">copy_q</span><span class="p">)</span>
      <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">elem</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Operation</span><span class="p">):</span>
        <span class="n">elem</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">elem</span><span class="p">)</span>

      <span class="n">new_control_inputs</span> <span class="o">+=</span> <span class="p">[</span><span class="n">elem</span><span class="p">]</span>

    <span class="c1"># If it has inputs, copy them.</span>
    <span class="n">new_inputs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">op</span><span class="o">.</span><span class="n">inputs</span><span class="p">:</span>
      <span class="n">elem</span> <span class="o">=</span> <span class="n">copy</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dict_swap</span><span class="p">,</span> <span class="n">scope</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="n">copy_q</span><span class="p">)</span>
      <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">elem</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Operation</span><span class="p">):</span>
        <span class="n">elem</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">elem</span><span class="p">)</span>

      <span class="n">new_inputs</span> <span class="o">+=</span> <span class="p">[</span><span class="n">elem</span><span class="p">]</span>

    <span class="c1"># Make a copy of the node def.</span>
    <span class="c1"># As an instance of tensorflow.core.framework.graph_pb2.NodeDef, it</span>
    <span class="c1"># stores string-based info such as name, device, and type of the op.</span>
    <span class="c1"># It is unique to every Operation instance.</span>
    <span class="n">new_node_def</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">op</span><span class="o">.</span><span class="n">node_def</span><span class="p">)</span>
    <span class="n">new_node_def</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">new_name</span>

    <span class="c1"># Copy the other inputs needed for initialization.</span>
    <span class="n">output_types</span> <span class="o">=</span> <span class="n">op</span><span class="o">.</span><span class="n">_output_types</span><span class="p">[:]</span>
    <span class="n">input_types</span> <span class="o">=</span> <span class="n">op</span><span class="o">.</span><span class="n">_input_types</span><span class="p">[:]</span>

    <span class="c1"># Make a copy of the op def.</span>
    <span class="c1"># It is unique to every Operation type.</span>
    <span class="n">op_def</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">op</span><span class="o">.</span><span class="n">op_def</span><span class="p">)</span>

    <span class="n">ret</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Operation</span><span class="p">(</span><span class="n">new_node_def</span><span class="p">,</span>
                       <span class="n">graph</span><span class="p">,</span>
                       <span class="n">new_inputs</span><span class="p">,</span>
                       <span class="n">output_types</span><span class="p">,</span>
                       <span class="n">new_control_inputs</span><span class="p">,</span>
                       <span class="n">input_types</span><span class="p">,</span>
                       <span class="n">new_original_op</span><span class="p">,</span>
                       <span class="n">op_def</span><span class="p">)</span>

    <span class="c1"># Use Graph&#39;s private methods to add the op, following</span>
    <span class="c1"># implementation of `tf.Graph().create_op()`.</span>
    <span class="n">compute_shapes</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="n">compute_device</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="n">op_type</span> <span class="o">=</span> <span class="n">new_name</span>

    <span class="k">if</span> <span class="n">compute_shapes</span><span class="p">:</span>
      <span class="n">set_shapes_for_outputs</span><span class="p">(</span><span class="n">ret</span><span class="p">)</span>
    <span class="n">graph</span><span class="o">.</span><span class="n">_add_op</span><span class="p">(</span><span class="n">ret</span><span class="p">)</span>
    <span class="n">graph</span><span class="o">.</span><span class="n">_record_op_seen_by_control_dependencies</span><span class="p">(</span><span class="n">ret</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">compute_device</span><span class="p">:</span>
      <span class="n">graph</span><span class="o">.</span><span class="n">_apply_device_functions</span><span class="p">(</span><span class="n">ret</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">graph</span><span class="o">.</span><span class="n">_colocation_stack</span><span class="p">:</span>
      <span class="n">all_colocation_groups</span> <span class="o">=</span> <span class="p">[]</span>
      <span class="k">for</span> <span class="n">colocation_op</span> <span class="ow">in</span> <span class="n">graph</span><span class="o">.</span><span class="n">_colocation_stack</span><span class="p">:</span>
        <span class="n">all_colocation_groups</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">colocation_op</span><span class="o">.</span><span class="n">colocation_groups</span><span class="p">())</span>
        <span class="k">if</span> <span class="n">colocation_op</span><span class="o">.</span><span class="n">device</span><span class="p">:</span>
          <span class="c1"># Make this device match the device of the colocated op, to</span>
          <span class="c1"># provide consistency between the device and the colocation</span>
          <span class="c1"># property.</span>
          <span class="k">if</span> <span class="n">ret</span><span class="o">.</span><span class="n">device</span> <span class="ow">and</span> <span class="n">ret</span><span class="o">.</span><span class="n">device</span> <span class="o">!=</span> <span class="n">colocation_op</span><span class="o">.</span><span class="n">device</span><span class="p">:</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;Tried to colocate </span><span class="si">%s</span><span class="s2"> with an op </span><span class="si">%s</span><span class="s2"> that had &quot;</span>
                            <span class="s2">&quot;a different device: </span><span class="si">%s</span><span class="s2"> vs </span><span class="si">%s</span><span class="s2">. &quot;</span>
                            <span class="s2">&quot;Ignoring colocation property.&quot;</span><span class="p">,</span>
                            <span class="n">name</span><span class="p">,</span> <span class="n">colocation_op</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">ret</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
                            <span class="n">colocation_op</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
          <span class="k">else</span><span class="p">:</span>
            <span class="n">ret</span><span class="o">.</span><span class="n">_set_device</span><span class="p">(</span><span class="n">colocation_op</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

      <span class="n">all_colocation_groups</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">all_colocation_groups</span><span class="p">))</span>
      <span class="n">ret</span><span class="o">.</span><span class="n">node_def</span><span class="o">.</span><span class="n">attr</span><span class="p">[</span><span class="s2">&quot;_class&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">CopyFrom</span><span class="p">(</span><span class="n">attr_value_pb2</span><span class="o">.</span><span class="n">AttrValue</span><span class="p">(</span>
          <span class="nb">list</span><span class="o">=</span><span class="n">attr_value_pb2</span><span class="o">.</span><span class="n">AttrValue</span><span class="o">.</span><span class="n">ListValue</span><span class="p">(</span><span class="n">s</span><span class="o">=</span><span class="n">all_colocation_groups</span><span class="p">)))</span>

    <span class="c1"># Sets &quot;container&quot; attribute if</span>
    <span class="c1"># (1) graph._container is not None</span>
    <span class="c1"># (2) &quot;is_stateful&quot; is set in OpDef</span>
    <span class="c1"># (3) &quot;container&quot; attribute is in OpDef</span>
    <span class="c1"># (4) &quot;container&quot; attribute is None</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">graph</span><span class="o">.</span><span class="n">_container</span> <span class="ow">and</span>
        <span class="n">op_type</span> <span class="ow">in</span> <span class="n">graph</span><span class="o">.</span><span class="n">_registered_ops</span> <span class="ow">and</span>
        <span class="n">graph</span><span class="o">.</span><span class="n">_registered_ops</span><span class="p">[</span><span class="n">op_type</span><span class="p">]</span><span class="o">.</span><span class="n">is_stateful</span> <span class="ow">and</span>
        <span class="s2">&quot;container&quot;</span> <span class="ow">in</span> <span class="n">ret</span><span class="o">.</span><span class="n">node_def</span><span class="o">.</span><span class="n">attr</span> <span class="ow">and</span>
            <span class="ow">not</span> <span class="n">ret</span><span class="o">.</span><span class="n">node_def</span><span class="o">.</span><span class="n">attr</span><span class="p">[</span><span class="s2">&quot;container&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">s</span><span class="p">):</span>
      <span class="n">ret</span><span class="o">.</span><span class="n">node_def</span><span class="o">.</span><span class="n">attr</span><span class="p">[</span><span class="s2">&quot;container&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">CopyFrom</span><span class="p">(</span>
          <span class="n">attr_value_pb2</span><span class="o">.</span><span class="n">AttrValue</span><span class="p">(</span><span class="n">s</span><span class="o">=</span><span class="n">compat</span><span class="o">.</span><span class="n">as_bytes</span><span class="p">(</span><span class="n">graph</span><span class="o">.</span><span class="n">_container</span><span class="p">)))</span>

    <span class="k">return</span> <span class="n">ret</span></div>


<div class="viewcode-block" id="cumprod"><a class="viewcode-back" href="../../edward.util.html#edward.util.cumprod">[docs]</a><span class="k">def</span> <span class="nf">cumprod</span><span class="p">(</span><span class="n">xs</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Cumulative product of a tensor along its outer dimension.</span>

<span class="sd">  https://github.com/tensorflow/tensorflow/issues/813</span>

<span class="sd">  Parameters</span>
<span class="sd">  ----------</span>
<span class="sd">  xs : tf.Tensor</span>
<span class="sd">    A 1-D or higher tensor.</span>

<span class="sd">  Returns</span>
<span class="sd">  -------</span>
<span class="sd">  tf.Tensor</span>
<span class="sd">    A tensor with `cumprod` applied along its outer dimension.</span>

<span class="sd">  Raises</span>
<span class="sd">  ------</span>
<span class="sd">  InvalidArgumentError</span>
<span class="sd">    If the input has Inf or NaN values.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">xs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">xs</span><span class="p">)</span>
  <span class="n">dependencies</span> <span class="o">=</span> <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">verify_tensor_all_finite</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">msg</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)]</span>
  <span class="n">xs</span> <span class="o">=</span> <span class="n">control_flow_ops</span><span class="o">.</span><span class="n">with_dependencies</span><span class="p">(</span><span class="n">dependencies</span><span class="p">,</span> <span class="n">xs</span><span class="p">)</span>

  <span class="n">values</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">unpack</span><span class="p">(</span><span class="n">xs</span><span class="p">)</span>
  <span class="n">out</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="n">prev</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">values</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
  <span class="k">for</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">values</span><span class="p">:</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">prev</span> <span class="o">*</span> <span class="n">val</span>
    <span class="n">out</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
    <span class="n">prev</span> <span class="o">=</span> <span class="n">s</span>

  <span class="n">result</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">pack</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">result</span></div>


<div class="viewcode-block" id="dot"><a class="viewcode-back" href="../../edward.util.html#edward.util.dot">[docs]</a><span class="k">def</span> <span class="nf">dot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Compute dot product between a 2-D tensor and a 1-D tensor.</span>

<span class="sd">  If x is a ``[M x N]`` matrix, then y is a ``M``-vector.</span>

<span class="sd">  If x is a ``M``-vector, then y is a ``[M x N]`` matrix.</span>

<span class="sd">  Parameters</span>
<span class="sd">  ----------</span>
<span class="sd">  x : tf.Tensor</span>
<span class="sd">    A 1-D or 2-D tensor (see above).</span>
<span class="sd">  y : tf.Tensor</span>
<span class="sd">    A 1-D or 2-D tensor (see above).</span>

<span class="sd">  Returns</span>
<span class="sd">  -------</span>
<span class="sd">  tf.Tensor</span>
<span class="sd">    A 1-D tensor of length ``N``.</span>

<span class="sd">  Raises</span>
<span class="sd">  ------</span>
<span class="sd">  InvalidArgumentError</span>
<span class="sd">    If the inputs have Inf or NaN values.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
  <span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
  <span class="n">dependencies</span> <span class="o">=</span> <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">verify_tensor_all_finite</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">msg</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">),</span>
                  <span class="n">tf</span><span class="o">.</span><span class="n">verify_tensor_all_finite</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">msg</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)]</span>
  <span class="n">x</span> <span class="o">=</span> <span class="n">control_flow_ops</span><span class="o">.</span><span class="n">with_dependencies</span><span class="p">(</span><span class="n">dependencies</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
  <span class="n">y</span> <span class="o">=</span> <span class="n">control_flow_ops</span><span class="o">.</span><span class="n">with_dependencies</span><span class="p">(</span><span class="n">dependencies</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

  <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">get_shape</span><span class="p">())</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
    <span class="n">vec</span> <span class="o">=</span> <span class="n">x</span>
    <span class="n">mat</span> <span class="o">=</span> <span class="n">y</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">vec</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">mat</span><span class="p">),</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="n">mat</span> <span class="o">=</span> <span class="n">x</span>
    <span class="n">vec</span> <span class="o">=</span> <span class="n">y</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">mat</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">vec</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span></div>


<div class="viewcode-block" id="Empty"><a class="viewcode-back" href="../../edward.util.html#edward.util.Empty">[docs]</a><span class="k">class</span> <span class="nc">Empty</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Empty class.&quot;&quot;&quot;</span>
  <span class="k">pass</span></div>


<div class="viewcode-block" id="get_dims"><a class="viewcode-back" href="../../edward.util.html#edward.util.get_dims">[docs]</a><span class="k">def</span> <span class="nf">get_dims</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Get values of each dimension.</span>

<span class="sd">  Parameters</span>
<span class="sd">  ----------</span>
<span class="sd">  x : float, int, tf.Tensor, np.ndarray, or RandomVariable</span>
<span class="sd">    A n-D tensor.</span>

<span class="sd">  Returns</span>
<span class="sd">  -------</span>
<span class="sd">  list of int</span>
<span class="sd">    Python list containing dimensions of ``x``.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="nb">float</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">[]</span>
  <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()</span><span class="o">.</span><span class="n">as_list</span><span class="p">()</span>
  <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
    <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
  <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">RandomVariable</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span><span class="o">.</span><span class="n">get_batch_shape</span><span class="p">()</span><span class="o">.</span><span class="n">as_list</span><span class="p">()</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span></div>


<div class="viewcode-block" id="get_session"><a class="viewcode-back" href="../../edward.util.html#edward.util.get_session">[docs]</a><span class="k">def</span> <span class="nf">get_session</span><span class="p">():</span>
  <span class="sd">&quot;&quot;&quot;Get the globally defined TensorFlow session.</span>

<span class="sd">  If the session is not already defined, then the function will create</span>
<span class="sd">  a global session.</span>

<span class="sd">  Returns</span>
<span class="sd">  -------</span>
<span class="sd">  _ED_SESSION : tf.InteractiveSession</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">global</span> <span class="n">_ED_SESSION</span>
  <span class="k">if</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_default_session</span><span class="p">()</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">_ED_SESSION</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">InteractiveSession</span><span class="p">()</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="n">_ED_SESSION</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_default_session</span><span class="p">()</span>

  <span class="k">return</span> <span class="n">_ED_SESSION</span></div>


<div class="viewcode-block" id="hessian"><a class="viewcode-back" href="../../edward.util.html#edward.util.hessian">[docs]</a><span class="k">def</span> <span class="nf">hessian</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">xs</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Calculate Hessian of y with respect to each x in xs.</span>

<span class="sd">  Parameters</span>
<span class="sd">  ----------</span>
<span class="sd">  y : tf.Tensor</span>
<span class="sd">    Tensor to calculate Hessian of.</span>
<span class="sd">  xs : list of tf.Variable</span>
<span class="sd">    List of TensorFlow variables to calculate with respect to.</span>
<span class="sd">    The variables can have different shapes.</span>

<span class="sd">  Returns</span>
<span class="sd">  -------</span>
<span class="sd">  tf.Tensor</span>
<span class="sd">    A 2-D tensor where each row is</span>
<span class="sd">    .. math:: \partial_{xs} ( [ \partial_{xs} y ]_j ).</span>

<span class="sd">  Raises</span>
<span class="sd">  ------</span>
<span class="sd">  InvalidArgumentError</span>
<span class="sd">    If the inputs have Inf or NaN values.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
  <span class="n">dependencies</span> <span class="o">=</span> <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">verify_tensor_all_finite</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">msg</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)]</span>
  <span class="n">dependencies</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="n">tf</span><span class="o">.</span><span class="n">verify_tensor_all_finite</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">msg</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">xs</span><span class="p">])</span>

  <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">control_dependencies</span><span class="p">(</span><span class="n">dependencies</span><span class="p">):</span>
    <span class="c1"># Calculate flattened vector grad_{xs} y.</span>
    <span class="n">grads</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">gradients</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">xs</span><span class="p">)</span>
    <span class="n">grads</span> <span class="o">=</span> <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="k">for</span> <span class="n">grad</span> <span class="ow">in</span> <span class="n">grads</span><span class="p">]</span>
    <span class="n">grads</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">grads</span><span class="p">)</span>
    <span class="c1"># Loop over each element in the vector.</span>
    <span class="n">mat</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">d</span> <span class="o">=</span> <span class="n">grads</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
      <span class="n">d</span> <span class="o">=</span> <span class="n">grads</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">d</span><span class="p">):</span>
      <span class="c1"># Calculate grad_{xs} ( [ grad_{xs} y ]_j ).</span>
      <span class="n">gradjgrads</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">gradients</span><span class="p">(</span><span class="n">grads</span><span class="p">[</span><span class="n">j</span><span class="p">],</span> <span class="n">xs</span><span class="p">)</span>
      <span class="c1"># Flatten into vector.</span>
      <span class="n">hi</span> <span class="o">=</span> <span class="p">[]</span>
      <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">xs</span><span class="p">)):</span>
        <span class="n">hij</span> <span class="o">=</span> <span class="n">gradjgrads</span><span class="p">[</span><span class="n">l</span><span class="p">]</span>
        <span class="c1"># return 0 if gradient doesn&#39;t exist; TensorFlow returns None</span>
        <span class="k">if</span> <span class="n">hij</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
          <span class="n">hij</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">xs</span><span class="p">[</span><span class="n">l</span><span class="p">]</span><span class="o">.</span><span class="n">get_shape</span><span class="p">(),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

        <span class="n">hij</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">hij</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">hi</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">hij</span><span class="p">)</span>

      <span class="n">hi</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">hi</span><span class="p">)</span>
      <span class="n">mat</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">hi</span><span class="p">)</span>

    <span class="c1"># Form matrix where each row is grad_{xs} ( [ grad_{xs} y ]_j ).</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">pack</span><span class="p">(</span><span class="n">mat</span><span class="p">)</span></div>


<div class="viewcode-block" id="kl_multivariate_normal"><a class="viewcode-back" href="../../edward.util.html#edward.util.kl_multivariate_normal">[docs]</a><span class="k">def</span> <span class="nf">kl_multivariate_normal</span><span class="p">(</span><span class="n">loc_one</span><span class="p">,</span> <span class="n">scale_one</span><span class="p">,</span> <span class="n">loc_two</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">scale_two</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Calculate the KL of multivariate normal distributions with</span>
<span class="sd">  diagonal covariances.</span>

<span class="sd">  Parameters</span>
<span class="sd">  ----------</span>
<span class="sd">  loc_one : tf.Tensor</span>
<span class="sd">    A 0-D tensor, 1-D tensor of length n, or 2-D tensor of shape M</span>
<span class="sd">    x n where each row represents the mean of a n-dimensional</span>
<span class="sd">    Gaussian.</span>
<span class="sd">  scale_one : tf.Tensor</span>
<span class="sd">    A tensor of same shape as ``loc_one``, representing the</span>
<span class="sd">    standard deviation.</span>
<span class="sd">  loc_two : tf.Tensor, optional</span>
<span class="sd">    A tensor of same shape as ``loc_one``, representing the</span>
<span class="sd">    mean of another Gaussian.</span>
<span class="sd">  scale_two : tf.Tensor, optional</span>
<span class="sd">    A tensor of same shape as ``loc_one``, representing the</span>
<span class="sd">    standard deviation of another Gaussian.</span>

<span class="sd">  Returns</span>
<span class="sd">  -------</span>
<span class="sd">  tf.Tensor</span>
<span class="sd">    For 0-D or 1-D tensor inputs, outputs the 0-D tensor</span>
<span class="sd">    ``KL( N(z; loc_one, scale_one) || N(z; loc_two, scale_two) )``</span>
<span class="sd">    For 2-D tensor inputs, outputs the 1-D tensor</span>
<span class="sd">    ``[KL( N(z; loc_one[m,:], scale_one[m,:]) || ``</span>
<span class="sd">    ``N(z; loc_two[m,:], scale_two[m,:]) )]_{m=1}^M``</span>

<span class="sd">  Raises</span>
<span class="sd">  ------</span>
<span class="sd">  InvalidArgumentError</span>
<span class="sd">    If the location variables have Inf or NaN values, or if the scale</span>
<span class="sd">    variables are not positive.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">loc_one</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">loc_one</span><span class="p">)</span>
  <span class="n">scale_one</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">scale_one</span><span class="p">)</span>
  <span class="n">loc_two</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">loc_two</span><span class="p">)</span>
  <span class="n">scale_two</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">scale_two</span><span class="p">)</span>
  <span class="n">dependencies</span> <span class="o">=</span> <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">verify_tensor_all_finite</span><span class="p">(</span><span class="n">loc_one</span><span class="p">,</span> <span class="n">msg</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">),</span>
                  <span class="n">tf</span><span class="o">.</span><span class="n">verify_tensor_all_finite</span><span class="p">(</span><span class="n">loc_two</span><span class="p">,</span> <span class="n">msg</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">),</span>
                  <span class="n">tf</span><span class="o">.</span><span class="n">assert_positive</span><span class="p">(</span><span class="n">scale_one</span><span class="p">),</span>
                  <span class="n">tf</span><span class="o">.</span><span class="n">assert_positive</span><span class="p">(</span><span class="n">scale_two</span><span class="p">)]</span>
  <span class="n">loc_one</span> <span class="o">=</span> <span class="n">control_flow_ops</span><span class="o">.</span><span class="n">with_dependencies</span><span class="p">(</span><span class="n">dependencies</span><span class="p">,</span> <span class="n">loc_one</span><span class="p">)</span>
  <span class="n">scale_one</span> <span class="o">=</span> <span class="n">control_flow_ops</span><span class="o">.</span><span class="n">with_dependencies</span><span class="p">(</span><span class="n">dependencies</span><span class="p">,</span> <span class="n">scale_one</span><span class="p">)</span>

  <span class="k">if</span> <span class="n">loc_two</span> <span class="o">==</span> <span class="mf">0.0</span> <span class="ow">and</span> <span class="n">scale_two</span> <span class="o">==</span> <span class="mf">1.0</span><span class="p">:</span>
    <span class="c1"># With default arguments, we can avoid some intermediate computation.</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">scale_one</span><span class="p">)</span> <span class="o">+</span> <span class="n">tf</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">loc_one</span><span class="p">)</span> <span class="o">-</span> \
        <span class="mf">1.0</span> <span class="o">-</span> <span class="mf">2.0</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">scale_one</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="n">loc_two</span> <span class="o">=</span> <span class="n">control_flow_ops</span><span class="o">.</span><span class="n">with_dependencies</span><span class="p">(</span><span class="n">dependencies</span><span class="p">,</span> <span class="n">loc_two</span><span class="p">)</span>
    <span class="n">scale_two</span> <span class="o">=</span> <span class="n">control_flow_ops</span><span class="o">.</span><span class="n">with_dependencies</span><span class="p">(</span><span class="n">dependencies</span><span class="p">,</span> <span class="n">scale_two</span><span class="p">)</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">scale_one</span> <span class="o">/</span> <span class="n">scale_two</span><span class="p">)</span> <span class="o">+</span> \
        <span class="n">tf</span><span class="o">.</span><span class="n">square</span><span class="p">((</span><span class="n">loc_two</span> <span class="o">-</span> <span class="n">loc_one</span><span class="p">)</span> <span class="o">/</span> <span class="n">scale_two</span><span class="p">)</span> <span class="o">-</span> \
        <span class="mf">1.0</span> <span class="o">+</span> <span class="mf">2.0</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">scale_two</span><span class="p">)</span> <span class="o">-</span> <span class="mf">2.0</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">scale_one</span><span class="p">)</span>

  <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">get_shape</span><span class="p">())</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">:</span>  <span class="c1"># scalar or vector</span>
    <span class="k">return</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>  <span class="c1"># matrix</span>
    <span class="k">return</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span></div>


<div class="viewcode-block" id="log_mean_exp"><a class="viewcode-back" href="../../edward.util.html#edward.util.log_mean_exp">[docs]</a><span class="k">def</span> <span class="nf">log_mean_exp</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">,</span> <span class="n">reduction_indices</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">keep_dims</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Compute the ``log_mean_exp`` of elements in a tensor, taking</span>
<span class="sd">  the mean across axes given by ``reduction_indices``.</span>

<span class="sd">  Parameters</span>
<span class="sd">  ----------</span>
<span class="sd">  input_tensor : tf.Tensor</span>
<span class="sd">    The tensor to reduce. Should have numeric type.</span>
<span class="sd">  reduction_indices : int or list of int, optional</span>
<span class="sd">    The dimensions to reduce. If `None` (the default), reduces all</span>
<span class="sd">    dimensions.</span>
<span class="sd">  keep_dims : bool, optional</span>
<span class="sd">    If true, retains reduced dimensions with length 1.</span>

<span class="sd">  Returns</span>
<span class="sd">  -------</span>
<span class="sd">  tf.Tensor</span>
<span class="sd">    The reduced tensor.</span>

<span class="sd">  Raises</span>
<span class="sd">  ------</span>
<span class="sd">  InvalidArgumentError</span>
<span class="sd">    If the input has Inf or NaN values.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">input_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">)</span>
  <span class="n">dependencies</span> <span class="o">=</span> <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">verify_tensor_all_finite</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">,</span> <span class="n">msg</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)]</span>
  <span class="n">input_tensor</span> <span class="o">=</span> <span class="n">control_flow_ops</span><span class="o">.</span><span class="n">with_dependencies</span><span class="p">(</span><span class="n">dependencies</span><span class="p">,</span> <span class="n">input_tensor</span><span class="p">)</span>

  <span class="n">x_max</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_max</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">,</span> <span class="n">reduction_indices</span><span class="p">,</span> <span class="n">keep_dims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">x_max</span><span class="p">)</span> <span class="o">+</span> <span class="n">tf</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">input_tensor</span> <span class="o">-</span> <span class="n">x_max</span><span class="p">),</span> <span class="n">reduction_indices</span><span class="p">,</span> <span class="n">keep_dims</span><span class="p">))</span></div>


<div class="viewcode-block" id="log_sum_exp"><a class="viewcode-back" href="../../edward.util.html#edward.util.log_sum_exp">[docs]</a><span class="k">def</span> <span class="nf">log_sum_exp</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">,</span> <span class="n">reduction_indices</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">keep_dims</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Compute the ``log_sum_exp`` of elements in a tensor, taking</span>
<span class="sd">  the sum across axes given by ``reduction_indices``.</span>

<span class="sd">  Parameters</span>
<span class="sd">  ----------</span>
<span class="sd">  input_tensor : tf.Tensor</span>
<span class="sd">    The tensor to reduce. Should have numeric type.</span>
<span class="sd">  reduction_indices : int or list of int, optional</span>
<span class="sd">    The dimensions to reduce. If `None` (the default), reduces all</span>
<span class="sd">    dimensions.</span>
<span class="sd">  keep_dims : bool, optional</span>
<span class="sd">    If true, retains reduced dimensions with length 1.</span>

<span class="sd">  Returns</span>
<span class="sd">  -------</span>
<span class="sd">  tf.Tensor</span>
<span class="sd">    The reduced tensor.</span>

<span class="sd">  Raises</span>
<span class="sd">  ------</span>
<span class="sd">  InvalidArgumentError</span>
<span class="sd">    If the input has Inf or NaN values.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">input_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">)</span>
  <span class="n">dependencies</span> <span class="o">=</span> <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">verify_tensor_all_finite</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">,</span> <span class="n">msg</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)]</span>
  <span class="n">input_tensor</span> <span class="o">=</span> <span class="n">control_flow_ops</span><span class="o">.</span><span class="n">with_dependencies</span><span class="p">(</span><span class="n">dependencies</span><span class="p">,</span> <span class="n">input_tensor</span><span class="p">)</span>

  <span class="n">x_max</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_max</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">,</span> <span class="n">reduction_indices</span><span class="p">,</span> <span class="n">keep_dims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">x_max</span><span class="p">)</span> <span class="o">+</span> <span class="n">tf</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">input_tensor</span> <span class="o">-</span> <span class="n">x_max</span><span class="p">),</span> <span class="n">reduction_indices</span><span class="p">,</span> <span class="n">keep_dims</span><span class="p">))</span></div>


<div class="viewcode-block" id="logit"><a class="viewcode-back" href="../../edward.util.html#edward.util.logit">[docs]</a><span class="k">def</span> <span class="nf">logit</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Evaluate :math:`\log(x / (1 - x))` elementwise.</span>

<span class="sd">  Parameters</span>
<span class="sd">  ----------</span>
<span class="sd">  x : tf.Tensor</span>
<span class="sd">    A n-D tensor.</span>

<span class="sd">  Returns</span>
<span class="sd">  -------</span>
<span class="sd">  tf.Tensor</span>
<span class="sd">    A tensor of same shape as input.</span>

<span class="sd">  Raises</span>
<span class="sd">  ------</span>
<span class="sd">  InvalidArgumentError</span>
<span class="sd">    If the input is not between :math:`(0,1)` elementwise.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
  <span class="n">dependencies</span> <span class="o">=</span> <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">assert_positive</span><span class="p">(</span><span class="n">x</span><span class="p">),</span>
                  <span class="n">tf</span><span class="o">.</span><span class="n">assert_less</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)]</span>
  <span class="n">x</span> <span class="o">=</span> <span class="n">control_flow_ops</span><span class="o">.</span><span class="n">with_dependencies</span><span class="p">(</span><span class="n">dependencies</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">-</span> <span class="n">tf</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">x</span><span class="p">)</span></div>


<div class="viewcode-block" id="multivariate_rbf"><a class="viewcode-back" href="../../edward.util.html#edward.util.multivariate_rbf">[docs]</a><span class="k">def</span> <span class="nf">multivariate_rbf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">l</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Squared-exponential kernel</span>

<span class="sd">  .. math:: k(x, y) = \sigma^2 \exp{ -1/(2l^2) \sum_i (x_i - y_i)^2 }</span>

<span class="sd">  Parameters</span>
<span class="sd">  ----------</span>
<span class="sd">  x : tf.Tensor</span>
<span class="sd">    A n-D tensor.</span>
<span class="sd">  y : tf.Tensor, optional</span>
<span class="sd">    A tensor of same shape as ``x``.</span>
<span class="sd">  sigma : tf.Tensor, optional</span>
<span class="sd">    A 0-D tensor, representing the standard deviation of radial</span>
<span class="sd">    basis function.</span>
<span class="sd">  l : tf.Tensor, optional</span>
<span class="sd">    A 0-D tensor, representing the lengthscale of radial basis</span>
<span class="sd">    function.</span>

<span class="sd">  Returns</span>
<span class="sd">  -------</span>
<span class="sd">  tf.Tensor</span>
<span class="sd">    A tensor of one less dimension than the input.</span>

<span class="sd">  Raises</span>
<span class="sd">  ------</span>
<span class="sd">  InvalidArgumentError</span>
<span class="sd">    If the mean variables have Inf or NaN values, or if the scale</span>
<span class="sd">    and length variables are not positive.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
  <span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
  <span class="n">sigma</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">sigma</span><span class="p">)</span>
  <span class="n">l</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">l</span><span class="p">)</span>
  <span class="n">dependencies</span> <span class="o">=</span> <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">verify_tensor_all_finite</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">msg</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">),</span>
                  <span class="n">tf</span><span class="o">.</span><span class="n">verify_tensor_all_finite</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">msg</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">),</span>
                  <span class="n">tf</span><span class="o">.</span><span class="n">assert_positive</span><span class="p">(</span><span class="n">sigma</span><span class="p">),</span>
                  <span class="n">tf</span><span class="o">.</span><span class="n">assert_positive</span><span class="p">(</span><span class="n">l</span><span class="p">)]</span>
  <span class="n">x</span> <span class="o">=</span> <span class="n">control_flow_ops</span><span class="o">.</span><span class="n">with_dependencies</span><span class="p">(</span><span class="n">dependencies</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
  <span class="n">y</span> <span class="o">=</span> <span class="n">control_flow_ops</span><span class="o">.</span><span class="n">with_dependencies</span><span class="p">(</span><span class="n">dependencies</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
  <span class="n">sigma</span> <span class="o">=</span> <span class="n">control_flow_ops</span><span class="o">.</span><span class="n">with_dependencies</span><span class="p">(</span><span class="n">dependencies</span><span class="p">,</span> <span class="n">sigma</span><span class="p">)</span>
  <span class="n">l</span> <span class="o">=</span> <span class="n">control_flow_ops</span><span class="o">.</span><span class="n">with_dependencies</span><span class="p">(</span><span class="n">dependencies</span><span class="p">,</span> <span class="n">l</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">sigma</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">)</span> <span class="o">*</span> \
      <span class="n">tf</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="mf">1.0</span> <span class="o">/</span> <span class="p">(</span><span class="mf">2.0</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">))</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">y</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">)))</span></div>


<div class="viewcode-block" id="placeholder"><a class="viewcode-back" href="../../edward.util.html#edward.util.placeholder">[docs]</a><span class="k">def</span> <span class="nf">placeholder</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;A wrapper around ``tf.placeholder``. It adds the tensor to the</span>
<span class="sd">  ``PLACEHOLDERS`` collection.&quot;&quot;&quot;</span>
  <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
  <span class="n">tf</span><span class="o">.</span><span class="n">add_to_collection</span><span class="p">(</span><span class="s2">&quot;PLACEHOLDERS&quot;</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">x</span></div>


<div class="viewcode-block" id="rbf"><a class="viewcode-back" href="../../edward.util.html#edward.util.rbf">[docs]</a><span class="k">def</span> <span class="nf">rbf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">l</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Squared-exponential kernel element-wise</span>

<span class="sd">  .. math:: k(x, y) = \sigma^2 \exp{ -1/(2l^2) (x - y)^2 }</span>

<span class="sd">  Parameters</span>
<span class="sd">  ----------</span>
<span class="sd">  x : tf.Tensor</span>
<span class="sd">    A n-D tensor.</span>
<span class="sd">  y : tf.Tensor, optional</span>
<span class="sd">    A tensor of same shape as ``x``.</span>
<span class="sd">  sigma : tf.Tensor, optional</span>
<span class="sd">    A 0-D tensor, representing the standard deviation of radial</span>
<span class="sd">    basis function.</span>
<span class="sd">  l : tf.Tensor, optional</span>
<span class="sd">    A 0-D tensor, representing the lengthscale of radial basis</span>
<span class="sd">    function.</span>

<span class="sd">  Returns</span>
<span class="sd">  -------</span>
<span class="sd">  tf.Tensor</span>
<span class="sd">    A tensor of one less dimension than the input.</span>

<span class="sd">  Raises</span>
<span class="sd">  ------</span>
<span class="sd">  InvalidArgumentError</span>
<span class="sd">    If the mean variables have Inf or NaN values, or if the scale</span>
<span class="sd">    and length variables are not positive.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
  <span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
  <span class="n">sigma</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">sigma</span><span class="p">)</span>
  <span class="n">l</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">l</span><span class="p">)</span>
  <span class="n">dependencies</span> <span class="o">=</span> <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">verify_tensor_all_finite</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">msg</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">),</span>
                  <span class="n">tf</span><span class="o">.</span><span class="n">verify_tensor_all_finite</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">msg</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">),</span>
                  <span class="n">tf</span><span class="o">.</span><span class="n">assert_positive</span><span class="p">(</span><span class="n">sigma</span><span class="p">),</span>
                  <span class="n">tf</span><span class="o">.</span><span class="n">assert_positive</span><span class="p">(</span><span class="n">l</span><span class="p">)]</span>
  <span class="n">x</span> <span class="o">=</span> <span class="n">control_flow_ops</span><span class="o">.</span><span class="n">with_dependencies</span><span class="p">(</span><span class="n">dependencies</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
  <span class="n">y</span> <span class="o">=</span> <span class="n">control_flow_ops</span><span class="o">.</span><span class="n">with_dependencies</span><span class="p">(</span><span class="n">dependencies</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
  <span class="n">sigma</span> <span class="o">=</span> <span class="n">control_flow_ops</span><span class="o">.</span><span class="n">with_dependencies</span><span class="p">(</span><span class="n">dependencies</span><span class="p">,</span> <span class="n">sigma</span><span class="p">)</span>
  <span class="n">l</span> <span class="o">=</span> <span class="n">control_flow_ops</span><span class="o">.</span><span class="n">with_dependencies</span><span class="p">(</span><span class="n">dependencies</span><span class="p">,</span> <span class="n">l</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">sigma</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">)</span> <span class="o">*</span> \
      <span class="n">tf</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="mf">1.0</span> <span class="o">/</span> <span class="p">(</span><span class="mf">2.0</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">))</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">y</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">))</span></div>


<div class="viewcode-block" id="set_seed"><a class="viewcode-back" href="../../edward.util.html#edward.util.set_seed">[docs]</a><span class="k">def</span> <span class="nf">set_seed</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Set seed for both NumPy and TensorFlow.</span>

<span class="sd">  Parameters</span>
<span class="sd">  ----------</span>
<span class="sd">  x : int, float</span>
<span class="sd">    seed</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">node_names</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">six</span><span class="o">.</span><span class="n">iterkeys</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">get_default_graph</span><span class="p">()</span><span class="o">.</span><span class="n">_nodes_by_name</span><span class="p">))</span>
  <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">node_names</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">node_names</span> <span class="o">!=</span> <span class="p">[</span><span class="s1">&#39;keras_learning_phase&#39;</span><span class="p">]:</span>
    <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Seeding is not supported after initializing &quot;</span>
                       <span class="s2">&quot;part of the graph. &quot;</span>
                       <span class="s2">&quot;Please move set_seed to the beginning of your code.&quot;</span><span class="p">)</span>

  <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
  <span class="n">tf</span><span class="o">.</span><span class="n">set_random_seed</span><span class="p">(</span><span class="n">x</span><span class="p">)</span></div>


<div class="viewcode-block" id="tile"><a class="viewcode-back" href="../../edward.util.html#edward.util.tile">[docs]</a><span class="k">def</span> <span class="nf">tile</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">multiples</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Constructs a tensor by tiling a given tensor.</span>

<span class="sd">  This extends ``tf.tile`` to features available in ``np.tile``.</span>
<span class="sd">  Namely, ``inputs`` and ``multiples`` can be a 0-D tensor.  Further,</span>
<span class="sd">  if 1-D, ``multiples`` can be of any length according to broadcasting</span>
<span class="sd">  rules (see documentation of ``np.tile`` or examples below).</span>

<span class="sd">  Parameters</span>
<span class="sd">  ----------</span>
<span class="sd">  input : tf.Tensor</span>
<span class="sd">    The input tensor.</span>
<span class="sd">  multiples : tf.Tensor</span>
<span class="sd">    The number of repetitions of ``input`` along each axis. Has type</span>
<span class="sd">    ``tf.int32``. 0-D or 1-D.</span>
<span class="sd">  *args :</span>
<span class="sd">    Passed into ``tf.tile``.</span>
<span class="sd">  **kwargs :</span>
<span class="sd">    Passed into ``tf.tile``.</span>

<span class="sd">  Returns</span>
<span class="sd">  -------</span>
<span class="sd">  tf.Tensor</span>
<span class="sd">      Has the same type as ``input``.</span>

<span class="sd">  Examples</span>
<span class="sd">  --------</span>
<span class="sd">  &gt;&gt;&gt; a = tf.constant([0, 1, 2])</span>
<span class="sd">  &gt;&gt;&gt; sess.run(ed.tile(a, 2))</span>
<span class="sd">  array([0, 1, 2, 0, 1, 2], dtype=int32)</span>
<span class="sd">  &gt;&gt;&gt; sess.run(ed.tile(a, (2, 2)))</span>
<span class="sd">  array([[0, 1, 2, 0, 1, 2],</span>
<span class="sd">         [0, 1, 2, 0, 1, 2]], dtype=int32)</span>
<span class="sd">  &gt;&gt;&gt; sess.run(ed.tile(a, (2, 1, 2)))</span>
<span class="sd">  array([[[0, 1, 2, 0, 1, 2]],</span>
<span class="sd">         [[0, 1, 2, 0, 1, 2]]], dtype=int32)</span>
<span class="sd">  &gt;&gt;&gt;</span>
<span class="sd">  &gt;&gt;&gt; b = tf.constant([[1, 2], [3, 4]])</span>
<span class="sd">  &gt;&gt;&gt; sess.run(ed.tile(b, 2))</span>
<span class="sd">  array([[1, 2, 1, 2],</span>
<span class="sd">         [3, 4, 3, 4]], dtype=int32)</span>
<span class="sd">  &gt;&gt;&gt; sess.run(ed.tile(b, (2, 1)))</span>
<span class="sd">  array([[1, 2],</span>
<span class="sd">         [3, 4],</span>
<span class="sd">         [1, 2],</span>
<span class="sd">         [3, 4]], dtype=int32)</span>
<span class="sd">  &gt;&gt;&gt;</span>
<span class="sd">  &gt;&gt;&gt; c = tf.constant([1, 2, 3, 4])</span>
<span class="sd">  &gt;&gt;&gt; sess.run(ed.tile(c, (4, 1)))</span>
<span class="sd">  array([[1, 2, 3, 4],</span>
<span class="sd">         [1, 2, 3, 4],</span>
<span class="sd">         [1, 2, 3, 4],</span>
<span class="sd">         [1, 2, 3, 4]], dtype=int32)</span>

<span class="sd">  Notes</span>
<span class="sd">  -----</span>
<span class="sd">  Sometimes this can result in an unknown shape. The core reason for</span>
<span class="sd">  this is the following behavior:</span>

<span class="sd">  &gt;&gt;&gt; n = tf.constant([1])</span>
<span class="sd">  &gt;&gt;&gt; tf.tile(tf.constant([[1.0]]),</span>
<span class="sd">  ...         tf.concat(0, [n, tf.constant([1.0]).get_shape()]))</span>
<span class="sd">  &lt;tf.Tensor &#39;Tile:0&#39; shape=(1, 1) dtype=float32&gt;</span>
<span class="sd">  &gt;&gt;&gt; n = tf.reshape(tf.constant(1), [1])</span>
<span class="sd">  &gt;&gt;&gt; tf.tile(tf.constant([[1.0]]),</span>
<span class="sd">  ...         tf.concat(0, [n, tf.constant([1.0]).get_shape()]))</span>
<span class="sd">  &lt;tf.Tensor &#39;Tile_1:0&#39; shape=(?, ?) dtype=float32&gt;</span>

<span class="sd">  For this reason, we try to fetch ``multiples`` out of session if</span>
<span class="sd">  possible. This can be slow if ``multiples`` has computationally</span>
<span class="sd">  intensive dependencies in order to perform this fetch.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="nb">input</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
  <span class="n">multiples</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">multiples</span><span class="p">)</span>

  <span class="c1"># 0-d tensor</span>
  <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="nb">input</span><span class="o">.</span><span class="n">get_shape</span><span class="p">())</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="nb">input</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

  <span class="c1"># 0-d tensor</span>
  <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">multiples</span><span class="o">.</span><span class="n">get_shape</span><span class="p">())</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">multiples</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">multiples</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

  <span class="k">try</span><span class="p">:</span>
    <span class="n">get_session</span><span class="p">()</span>
    <span class="n">multiples</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">multiples</span><span class="o">.</span><span class="n">eval</span><span class="p">())</span>
  <span class="k">except</span><span class="p">:</span>
    <span class="k">pass</span>

  <span class="c1"># broadcasting</span>
  <span class="n">diff</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="nb">input</span><span class="o">.</span><span class="n">get_shape</span><span class="p">())</span> <span class="o">-</span> <span class="n">get_dims</span><span class="p">(</span><span class="n">multiples</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
  <span class="k">if</span> <span class="n">diff</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
    <span class="nb">input</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">diff</span><span class="p">)</span> <span class="o">+</span> <span class="n">get_dims</span><span class="p">(</span><span class="nb">input</span><span class="p">))</span>
  <span class="k">elif</span> <span class="n">diff</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">multiples</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">diff</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">),</span> <span class="n">multiples</span><span class="p">])</span>

  <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">multiples</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>


<div class="viewcode-block" id="to_simplex"><a class="viewcode-back" href="../../edward.util.html#edward.util.to_simplex">[docs]</a><span class="k">def</span> <span class="nf">to_simplex</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Transform real vector of length ``(K-1)`` to a simplex of dimension ``K``</span>
<span class="sd">  using a backward stick breaking construction.</span>

<span class="sd">  Parameters</span>
<span class="sd">  ----------</span>
<span class="sd">  x : tf.Tensor</span>
<span class="sd">    A 1-D or 2-D tensor.</span>

<span class="sd">  Returns</span>
<span class="sd">  -------</span>
<span class="sd">  tf.Tensor</span>
<span class="sd">    A tensor of same shape as input but with last dimension of</span>
<span class="sd">    size ``K``.</span>

<span class="sd">  Raises</span>
<span class="sd">  ------</span>
<span class="sd">  InvalidArgumentError</span>
<span class="sd">    If the input has Inf or NaN values.</span>

<span class="sd">  Notes</span>
<span class="sd">  -----</span>
<span class="sd">  x as a 3-D or higher tensor is not guaranteed to be supported.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
  <span class="n">dependencies</span> <span class="o">=</span> <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">verify_tensor_all_finite</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">msg</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)]</span>
  <span class="n">x</span> <span class="o">=</span> <span class="n">control_flow_ops</span><span class="o">.</span><span class="n">with_dependencies</span><span class="p">(</span><span class="n">dependencies</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>

  <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">):</span>
    <span class="n">shape</span> <span class="o">=</span> <span class="n">get_dims</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="n">shape</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span>

  <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
    <span class="n">n_rows</span> <span class="o">=</span> <span class="p">()</span>
    <span class="n">K_minus_one</span> <span class="o">=</span> <span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">eq</span> <span class="o">=</span> <span class="o">-</span><span class="n">tf</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">K_minus_one</span> <span class="o">-</span> <span class="n">tf</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="n">K_minus_one</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">eq</span> <span class="o">+</span> <span class="n">x</span><span class="p">)</span>
    <span class="n">pil</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="p">[</span><span class="n">z</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mf">1.0</span><span class="p">])])</span>
    <span class="n">piu</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mf">1.0</span><span class="p">]),</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">z</span><span class="p">])</span>
    <span class="n">S</span> <span class="o">=</span> <span class="n">cumprod</span><span class="p">(</span><span class="n">piu</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">S</span> <span class="o">*</span> <span class="n">pil</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="n">n_rows</span> <span class="o">=</span> <span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">K_minus_one</span> <span class="o">=</span> <span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">eq</span> <span class="o">=</span> <span class="o">-</span><span class="n">tf</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">K_minus_one</span> <span class="o">-</span> <span class="n">tf</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="n">K_minus_one</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">eq</span> <span class="o">+</span> <span class="n">x</span><span class="p">)</span>
    <span class="n">pil</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="p">[</span><span class="n">z</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="n">n_rows</span><span class="p">,</span> <span class="mi">1</span><span class="p">])])</span>
    <span class="n">piu</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="n">n_rows</span><span class="p">,</span> <span class="mi">1</span><span class="p">]),</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">z</span><span class="p">])</span>
    <span class="c1"># cumulative product along 1st axis</span>
    <span class="n">S</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">pack</span><span class="p">([</span><span class="n">cumprod</span><span class="p">(</span><span class="n">piu_x</span><span class="p">)</span> <span class="k">for</span> <span class="n">piu_x</span> <span class="ow">in</span> <span class="n">tf</span><span class="o">.</span><span class="n">unpack</span><span class="p">(</span><span class="n">piu</span><span class="p">)])</span>
    <span class="k">return</span> <span class="n">S</span> <span class="o">*</span> <span class="n">pil</span></div>
</pre></div>

           </div>
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2016, Edward Development Team.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../../',
            VERSION:'1.0.9',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true
        };
    </script>
      <script type="text/javascript" src="../../_static/jquery.js"></script>
      <script type="text/javascript" src="../../_static/underscore.js"></script>
      <script type="text/javascript" src="../../_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="../../_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>