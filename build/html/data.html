

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Data &mdash; Edward 1.0.9 documentation</title>
  

  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  

  

  
    <link rel="top" title="Edward 1.0.9 documentation" href="index.html"/>
        <link rel="next" title="Models" href="models.html"/>
        <link rel="prev" title="Edward" href="index.html"/> 

  
  <script src="_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="index.html" class="icon icon-home"> Edward
          

          
          </a>

          
            
            
              <div class="version">
                1.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
                <ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Data</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#reading-data-in-edward">Reading Data in Edward</a></li>
<li class="toctree-l2"><a class="reference internal" href="#training-models-with-data">Training Models with Data</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="models.html">Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="inferences.html">Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="criticisms.html">Criticism</a></li>
<li class="toctree-l1"><a class="reference internal" href="edward.html">edward package</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="index.html">Edward</a>
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          

 



<div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="index.html">Docs</a> &raquo;</li>
      
    <li>Data</li>
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="_sources/data.txt" rel="nofollow"> View page source</a>
          
        
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="data">
<h1>Data<a class="headerlink" href="#data" title="Permalink to this headline">Â¶</a></h1>
<p>Data in Edward is stored as a Python dictionary. It is usually comprised
of strings binded to NumPy arrays such as a key <code class="docutils literal"><span class="pre">'x'</span></code> with value
<code class="docutils literal"><span class="pre">np.array([0.23512,</span> <span class="pre">13.2])</span></code>.
We detail specifics for each modeling language below.</p>
<ul class="simple">
<li><strong>TensorFlow.</strong> The data carries whatever keys and values the user
accesses in the user-defined model. Key is a string. Value is a NumPy
array or TensorFlow tensor.</li>
</ul>
<div class="code python highlight-default"><div class="highlight"><pre><span class="k">class</span> <span class="nc">BetaBernoulli</span><span class="p">:</span>
  <span class="k">def</span> <span class="nf">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xs</span><span class="p">,</span> <span class="n">zs</span><span class="p">):</span>
    <span class="n">log_prior</span> <span class="o">=</span> <span class="n">beta</span><span class="o">.</span><span class="n">logpdf</span><span class="p">(</span><span class="n">zs</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
    <span class="n">log_lik</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">pack</span><span class="p">([</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">bernoulli</span><span class="o">.</span><span class="n">logpmf</span><span class="p">(</span><span class="n">xs</span><span class="p">[</span><span class="s">&#39;x&#39;</span><span class="p">],</span> <span class="n">z</span><span class="p">))</span>
                       <span class="k">for</span> <span class="n">z</span> <span class="ow">in</span> <span class="n">tf</span><span class="o">.</span><span class="n">unpack</span><span class="p">(</span><span class="n">zs</span><span class="p">)])</span>
    <span class="k">return</span> <span class="n">log_lik</span> <span class="o">+</span> <span class="n">log_prior</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">BetaBernoulli</span><span class="p">()</span>
<span class="n">data</span> <span class="o">=</span> <span class="p">{</span><span class="s">&#39;x&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])}</span>
</pre></div>
</div>
<ul class="simple">
<li><strong>Python.</strong> The data carries whatever keys and values the user
accesses in the user-defined model. Key is a string. Value is a NumPy
array or TensorFlow tensor.</li>
</ul>
<div class="code python highlight-default"><div class="highlight"><pre><span class="k">class</span> <span class="nc">BetaBernoulli</span><span class="p">(</span><span class="n">PythonModel</span><span class="p">):</span>
  <span class="k">def</span> <span class="nf">_py_log_prob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xs</span><span class="p">,</span> <span class="n">zs</span><span class="p">):</span>
      <span class="n">n_minibatch</span> <span class="o">=</span> <span class="n">zs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
      <span class="n">lp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_minibatch</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
      <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_minibatch</span><span class="p">):</span>
        <span class="n">lp</span><span class="p">[</span><span class="n">b</span><span class="p">]</span> <span class="o">=</span> <span class="n">beta</span><span class="o">.</span><span class="n">logpdf</span><span class="p">(</span><span class="n">zs</span><span class="p">[</span><span class="n">b</span><span class="p">,</span> <span class="p">:],</span> <span class="n">a</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">xs</span><span class="p">[</span><span class="s">&#39;x&#39;</span><span class="p">])):</span>
          <span class="n">lp</span><span class="p">[</span><span class="n">b</span><span class="p">]</span> <span class="o">+=</span> <span class="n">bernoulli</span><span class="o">.</span><span class="n">logpmf</span><span class="p">(</span><span class="n">xs</span><span class="p">[</span><span class="s">&#39;x&#39;</span><span class="p">][</span><span class="n">n</span><span class="p">],</span> <span class="n">p</span><span class="o">=</span><span class="n">zs</span><span class="p">[</span><span class="n">b</span><span class="p">,</span> <span class="p">:])</span>

      <span class="k">return</span> <span class="n">lp</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">BetaBernoulli</span><span class="p">()</span>
<span class="n">data</span> <span class="o">=</span> <span class="p">{</span><span class="s">&#39;x&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])}</span>
</pre></div>
</div>
<ul class="simple">
<li><strong>PyMC3.</strong> The data binds Theano shared variables, which are used to
mark the observed PyMC3 random variables, to their realizations. Key
is a Theano shared variable. Value is a NumPy array or TensorFlow
tensor.</li>
</ul>
<div class="code python highlight-default"><div class="highlight"><pre><span class="n">x_obs</span> <span class="o">=</span> <span class="n">theano</span><span class="o">.</span><span class="n">shared</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
<span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">pm_model</span><span class="p">:</span>
  <span class="n">beta</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Beta</span><span class="p">(</span><span class="s">&#39;beta&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="k">None</span><span class="p">)</span>
  <span class="n">x</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Bernoulli</span><span class="p">(</span><span class="s">&#39;x&#39;</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">x_obs</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">PyMC3Model</span><span class="p">(</span><span class="n">pm_model</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="p">{</span><span class="n">x_obs</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])}</span>
</pre></div>
</div>
<ul class="simple">
<li><strong>Stan.</strong> The data is according to the Stan program&#8217;s data block. Key
is a string. Value is whatever type is used for the data block.</li>
</ul>
<div class="code python highlight-default"><div class="highlight"><pre><span class="n">model_code</span> <span class="o">=</span> <span class="s">&quot;&quot;&quot;</span>
<span class="s">  data {</span>
<span class="s">    int&lt;lower=0&gt; N;</span>
<span class="s">    int&lt;lower=0,upper=1&gt; y[N];</span>
<span class="s">  }</span>
<span class="s">  parameters {</span>
<span class="s">    real&lt;lower=0,upper=1&gt; theta;</span>
<span class="s">  }</span>
<span class="s">  model {</span>
<span class="s">    theta ~ beta(1.0, 1.0);</span>
<span class="s">    for (n in 1:N)</span>
<span class="s">      y[n] ~ bernoulli(theta);</span>
<span class="s">  }</span>
<span class="s">&quot;&quot;&quot;</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">ed</span><span class="o">.</span><span class="n">StanModel</span><span class="p">(</span><span class="n">model_code</span><span class="o">=</span><span class="n">model_code</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="p">{</span><span class="s">&#39;N&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span> <span class="s">&#39;y&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]}</span>
</pre></div>
</div>
<div class="section" id="reading-data-in-edward">
<h2>Reading Data in Edward<a class="headerlink" href="#reading-data-in-edward" title="Permalink to this headline">Â¶</a></h2>
<p>There are three ways to read data in Edward. They follow the <a class="reference external" href="https://www.tensorflow.org/versions/r0.9/how_tos/reading_data/index.html">three ways
to read data in TensorFlow</a>.</p>
<ol class="arabic">
<li><p class="first"><strong>Preloaded data.</strong> A constant or variable in the TensorFlow graph
holds all the data.</p>
<p>This setting is the fastest to work with and is recommended if the
data fits in memory.</p>
<p>For inference, pass in the data as a dictionary of NumPy arrays.
Internally, we will store them in TensorFlow variables to prevent
copying data more than once in memory. Batch training is available
by passing in the <code class="docutils literal"><span class="pre">n_minibatch</span></code> argument to inference. (As an example, see
the <a class="reference external" href="https://github.com/blei-lab/edward/blob/master/examples/mixture_gaussian.py">mixture of Gaussians</a>.)</p>
</li>
<li><p class="first"><strong>Feeding.</strong> Manual code provides the data when running each step of
inference.</p>
<p>This setting provides the most fine-grained control which is useful for experimentation.</p>
<p>For inference, pass in the data as a dictionary of TensorFlow
placeholders. The user must manually feed the placeholders at each
step of inference: initialize via <code class="docutils literal"><span class="pre">inference.initialize()</span></code>; then
in a loop call <code class="docutils literal"><span class="pre">sess.run(inference.train,</span> <span class="pre">feed_dict={...})</span></code> where
in <code class="docutils literal"><span class="pre">feed_dict</span></code> you pass in the values for the
<code class="docutils literal"><span class="pre">tf.placeholder</span></code>&#8216;s.
(As an example, see
the <a class="reference external" href="https://github.com/blei-lab/edward/blob/master/examples/mixture_density_network.py">mixture density network</a>
or <a class="reference external" href="https://github.com/blei-lab/edward/blob/master/examples/convolutional_vae.py">variational auto-encoder</a>.)</p>
</li>
<li><p class="first"><strong>Reading from files.</strong> An input pipeline reads the data from files
at the beginning of a TensorFlow graph.</p>
<p>This setting is recommended if the data does not fit in memory.</p>
<p>For inference, pass in the data as a dictionary of TensorFlow
tensors, where the tensors are the output of data readers. (As an
example, see
the <a class="reference external" href="https://github.com/blei-lab/edward/blob/master/tests/test_inference_data.py">data unit test</a>.)</p>
</li>
</ol>
</div>
<div class="section" id="training-models-with-data">
<h2>Training Models with Data<a class="headerlink" href="#training-models-with-data" title="Permalink to this headline">Â¶</a></h2>
<p>How do we use the data during training? In general there are three use
cases:</p>
<ol class="arabic">
<li><p class="first">Train over the full data per step.</p>
<p>Follow the setting of preloaded data.</p>
</li>
<li><p class="first">Train over a batch per step when the full data fits in memory. This
scale inference in terms of computational complexity.</p>
<p>Follow the setting of preloaded data. Specify the batch size with
<code class="docutils literal"><span class="pre">n_minibatch</span></code> in <code class="docutils literal"><span class="pre">Inference</span></code>. By default, we will subsample by
slicing along the first dimension of every data structure in the
data dictionary. Alternatively, follow the setting of feeding.
Manually deal with the batch behavior at each training step.</p>
</li>
<li><p class="first">Train over batches per step when the full data does not fit in
memory. This scales inference in terms of computational complexity and
memory complexity.</p>
<p>Follow the setting of reading from files. Alternatively, follow the
setting of feeding, and use a generator to create and destroy NumPy
arrays on the fly for feeding the placeholders.</p>
</li>
</ol>
<p>The three use cases are supported for all modeling languages except
Stan, which is limited to training over the full data per step. (This
because Stan&#8217;s data structure requires data subsampling on arbitrary
data types, which we don&#8217;t know how to automate.)</p>
</div>
</div>


           </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="models.html" class="btn btn-neutral float-right" title="Models" accesskey="n">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="index.html" class="btn btn-neutral" title="Edward" accesskey="p"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2016, Edward Development Team.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'./',
            VERSION:'1.0.9',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true
        };
    </script>
      <script type="text/javascript" src="_static/jquery.js"></script>
      <script type="text/javascript" src="_static/underscore.js"></script>
      <script type="text/javascript" src="_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>