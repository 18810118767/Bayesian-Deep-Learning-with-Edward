<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta content="text/html; charset=utf-8" http-equiv="Content-Type"/>
<meta content="text/css" http-equiv="Content-Style-Type"/>
<meta content="pandoc" name="generator"/>
<title>Edward – Latent space models for neural data</title>
<!-- Mobile Specific Metas -->
<meta content="width=device-width, initial-scale=1" name="viewport">
<!-- FONT -->
<link href="https://fonts.googleapis.com/css?family=Lora:400,400i,700" rel="stylesheet">
<!-- CSS -->
<link href="css/normalize.css" rel="stylesheet">
<link href="css/skeleton.css" rel="stylesheet">
<!-- Dynamically resize logo for mobile -->
<style type="text/css">
  .logo-width {
    width: 100%;
    box-sizing: border-box;
    margin-bottom: 15%;
  }
  /* Roughly the point when website is single column */
  @media (max-width: 850px) {
    .logo-width {
      width: 50%;
      box-sizing: border-box;
      margin-bottom: 5%;
    }
  }
  </style>
<!-- KaTeX -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.6.0/katex.min.js"></script>
<link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.6.0/katex.min.css" rel="stylesheet"/>
<script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.6.0/contrib/auto-render.min.js"></script>
<!-- highlight.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.4.0/highlight.min.js"></script>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.4.0/styles/github.min.css" rel="stylesheet">
<!-- Favicon -->
<link href="icons/apple-touch-icon-57x57.png" rel="apple-touch-icon" sizes="57x57">
<link href="icons/apple-touch-icon-60x60.png" rel="apple-touch-icon" sizes="60x60">
<link href="icons/apple-touch-icon-72x72.png" rel="apple-touch-icon" sizes="72x72">
<link href="icons/apple-touch-icon-76x76.png" rel="apple-touch-icon" sizes="76x76">
<link href="icons/apple-touch-icon-114x114.png" rel="apple-touch-icon" sizes="114x114">
<link href="icons/apple-touch-icon-120x120.png" rel="apple-touch-icon" sizes="120x120">
<link href="icons/apple-touch-icon-144x144.png" rel="apple-touch-icon" sizes="144x144">
<link href="icons/apple-touch-icon-152x152.png" rel="apple-touch-icon" sizes="152x152">
<link href="icons/apple-touch-icon-180x180.png" rel="apple-touch-icon" sizes="180x180">
<link href="icons/favicon-32x32.png" rel="icon" sizes="32x32" type="image/png">
<link href="icons/android-chrome-192x192.png" rel="icon" sizes="192x192" type="image/png">
<link href="icons/favicon-96x96.png" rel="icon" sizes="96x96" type="image/png">
<link href="icons/favicon-16x16.png" rel="icon" sizes="16x16" type="image/png">
<link href="icons/manifest.json" rel="manifest">
<link color="#5bbad5" href="icons/safari-pinned-tab.svg" rel="mask-icon">
<link href="icons/favicon.ico" rel="shortcut icon">
<meta content="#da532c" name="msapplication-TileColor">
<meta content="icons/mstile-144x144.png" name="msapplication-TileImage">
<meta content="icons/browserconfig.xml" name="msapplication-config">
<meta content="#ffffff" name="theme-color">
</meta></meta></meta></meta></link></link></link></link></link></link></link></link></link></link></link></link></link></link></link></link></link></link></link></link></meta></head>
<body>
<div class="container">
<div class="row" style="margin-top: 5%">
<div class="three columns">
<h1><a href="/">Edward</a></h1>
<a href="/">
<center>
<img alt="Edward" class="logo-width" src="images/edward.png"/>
</center>
</a>
<a class="button u-full-width" href="/">Home</a>
<a class="button u-full-width" href="getting-started">Getting Started</a>
<a class="button u-full-width" href="delving-in">Delving In</a>
<a class="button u-full-width" href="tutorials">Tutorials</a>
<a class="button u-full-width" href="api/">API</a>
<a class="button u-full-width" href="#">Advanced</a>
<a class="button2 u-full-width" href="design-philosophy">Design Philosophy</a>
<a class="button2 u-full-width" href="contributing">Contributing</a>
<a class="button2 u-full-width" href="troubleshooting">Troubleshooting</a>
<a class="button2 u-full-width" href="license">License</a>
<div class="row" style="padding-bottom: 5%"> </div>
<a href="https://github.com/blei-lab/edward">
<!-- <object data="images/github-mark.svg" type="image/svg+xml"> -->
<img alt="Edward on Github" class="u-pull-right" src="images/github-mark.svg" style="padding-right:10%"/>
<!-- </object> -->
</a>
<div class="row" style="padding-bottom: 5%"> </div>
</div>
<div class="nine columns">
<h2 id="latent-space-models-for-neural-data">Latent space models for neural data</h2>
<p>Many interesting data sets exhibit a network structure. For example, social networks or biological neural networks.</p>
<p>What we can learn about the nodes of the network from its connectivity patterns? We can begin to study this using a latent space model. Latent space models embed the nodes of the network in a latent space which captures attributes of the nodes. The likelihood to form an edge between two nodes depends on their distance in the latent space.</p>
<p>Let us study an dataset from from neuroscience. The script can be found <a href="https://github.com/blei-lab/edward/blob/master/examples/latent_space_model.py">here</a>.</p>
<h3 id="data">Data</h3>
<p>The data comes from <a href="http://www-personal.umich.edu/~mejn/netdata/">Mark Newman’s repository</a>. It is a weighted, directed network representing the neural network of the nematode <a href="https://en.wikipedia.org/wiki/Caenorhabditis_elegans">C. Elegans</a> compiled by Watts and Strogatz from original experimental data by White and co-authors.</p>
<p>The neural network consists of around <span class="math inline">\(300\)</span> neurons. Each connection is associated with a weight (positive integer) capturing the strength of the connection.</p>
<p>In the example we load the data with</p>
<pre class="python" language="Python"><code>def load_celegans_brain():
  x = np.load('data/celegans_brain.npy')
  N = x.shape[0]
  return {'x': x}, N

data, N = load_celegans_brain()</code></pre>
<h3 id="model">Model</h3>
<p>Here we will fit a latent space model to the C. Elegans neural network. What can we learn about the neurons from how they are connected? We will learn a latent embedding for each neuron to capture the similarities between them.</p>
<p>Each neuron <span class="math inline">\(n\)</span> is a node in the network and is associated with a latent <span class="math inline">\(K\)</span>-dimensional vector <span class="math inline">\(z_n\)</span>.</p>
<p>We place a Gaussian prior on each of the latent vectors. The log-odds of an edge between node <span class="math inline">\(i\)</span> and <span class="math inline">\(j\)</span> is proportional to the Euclidean distance between the latent representations of the nodes <span class="math inline">\(|z_i- z_j|\)</span>. Here, we model the weights (<span class="math inline">\(Y_{ij}\)</span>) of the edges with a Poisson likelihood. The rate is the reciprocal of the distance in latent space. This is the generative process:</p>
<p>For each node <span class="math inline">\(n\)</span>: <span class="math display">\[\begin{aligned}
z_n \sim N(0,I).\end{aligned}\]</span> For each edge <span class="math inline">\((i,j)\)</span>: <span class="math display">\[\begin{aligned}
Y_{ij} \sim \text{Poisson}\Bigg(\frac{1}{|z_i - z_j|}\Bigg).\end{aligned}\]</span></p>
<p>Here we build the model in Edward using TensorFlow.</p>
<pre class="python" language="Python"><code>class LatentSpaceModel:
  """
  p(x, z) = [ prod_{i=1}^N prod_{j=1}^N Poi(Y_{ij}; 1/||z_i - z_j|| ) ]
        [ prod_{i=1}^N N(z_i; 0, I)) ]
  """
  def __init__(self, N, K, var=1.0,
               like='Poisson',
               prior='Lognormal',
               dist='euclidean'):
    self.n_vars = N * K
    self.N = N
    self.K = K
    self.prior_variance = var
    self.like = like
    self.prior = prior
    self.dist = dist

  def log_prob(self, xs, zs):
    """Return a vector [log p(xs, zs[1,:]), ..., log p(xs, zs[S,:])]."""
    zs = zs['z']
    if self.prior == 'Lognormal':
      zs = tf.exp(zs)
    elif self.prior != 'Gaussian':
      raise NotImplementedError("prior not available.")

    log_prior = -self.prior_variance * tf.reduce_sum(zs * zs)

    z = tf.reshape(zs, [self.N, self.K])
    if self.dist == 'euclidean':
      xp = tf.matmul(tf.ones([1, self.N]),
                     tf.reduce_sum(z * z, 1, keep_dims=True))
      xp = xp + tf.transpose(xp) - 2 * tf.matmul(z, z, transpose_b=True)
      xp = 1.0 / xp
    elif self.dist == 'cosine':
      xp = tf.matmul(z, z, transpose_b=True)

    if self.like == 'Gaussian':
      log_lik = tf.reduce_sum(norm.logpdf(xs['x'], xp, 1.0))
    elif self.like == 'Poisson':
      if not (self.dist == 'euclidean' or self.prior == "Lognormal"):
        raise NotImplementedError("Rate of Poisson has to be nonnegatve.")

      log_lik = tf.reduce_sum(poisson.logpmf(xs['x'], xp))
    else:
      raise NotImplementedError("likelihood not available.")

    return log_lik + log_prior


K = 3
model = LatentSpaceModel(N, K=3, like='Poisson', prior='Gaussian')</code></pre>
<h3 id="inference">Inference</h3>
<p>Maximum a posteriori (MAP) estimation is simple in Edward. Two lines are required: Instantiating inference and running it.</p>
<pre class="python" language="Python"><code>inference = ed.MAP(['z'], data, model)</code></pre>
<p>See this extended tutorial about <a href="tut_MAP">MAP estimation in Edward</a>.</p>
<p>One could instead run variational inference. This requires specifying a variational model and instantiating <code>MFVI</code>.</p>
<pre class="python" language="Python"><code>qz = Normal(model.n_vars)
inference = ed.MFVI({'z': qz}, data, model)</code></pre>
<p>Finally, the following line runs the inference procedure for 5000 iterations and prints progress every 500 iteration.</p>
<pre class="python" language="Python"><code>inference.run(n_iter=5000, n_print=500)</code></pre>
<p>See this extended tutorial about <a href="tut_variational_inference">variational inference in Edward</a>.</p>
<h3 id="references">References</h3>
<ul>
<li>White, J. G., Southgate, E., Thomson, J. N., and Brenner, S. (1986). The structure of the nervous system of the nematode caenorhabditis elegans. <em>Philos Trans R Soc Lond B Biol Sci</em>, 314(1165):1–340.</li>
<li>Watts, D. J. and Strogatz, S. H. (1998). Collective dynamics of ‘small-world’ networks. <em>Nature</em>, 393(6684):440–442.</li>
<li>Hoff, P. D., Raftery, A. E., and Handcock, M. S. (2002). Latent space approaches to social network analysis. <em>Journal of the american Statistical association</em>, 97(460):1090–1098.</li>
</ul>
</div>
</div>
<div class="row" style="padding-bottom: 25%"> </div>
</div>
<script>
  hljs.initHighlightingOnLoad();
  renderMathInElement(document.body);
</script>
</body>
</html>
