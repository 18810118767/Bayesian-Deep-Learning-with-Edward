{
    "docs": [
        {
            "location": "/", 
            "text": "Welcome to Edward\n\n\nEdward\n is a Python library for probabilistic modeling, inference,\nand criticism. It enables black box inference for models with discrete\nand continuous latent variables, neural network parameterizations, and\ninfinite dimensional parameter spaces. Edward serves as a fusion of\nthree fields: Bayesian statistics and machine learning, deep learning,\nand probabilistic programming.\n\n\nIt supports \nmodeling languages\n including\n\n\n\n\nTensorFlow\n (with neural network compositionality via \nKeras\n, \nPretty Tensor\n, or \nTensorFlow-Slim\n)\n\n\nStan\n\n\nPyMC3\n\n\noriginal Python using \nNumPy/SciPy\n\n\n\n\nIt supports \ninference\n via\n\n\n\n\nVariational inference\n\n\nBlack box variational inference\n\n\nStochastic variational inference\n\n\nVariational auto-encoders\n\n\nInclusive KL divergence (KL(p || q))\n\n\nLaplace approximation\n\n\n\n\n\n\nMarginal posterior optimization (empirical Bayes, marginal maximum likelihood)\n\n\nMaximum a posteriori (penalized maximum likelihood, maximum likelihood)\n\n\n\n\nIt supports \ncriticism\n of the model and inference via\n\n\n\n\nEvaluations on both supervised and unsupervised tasks\n\n\nPosterior predictive checks\n\n\n\n\nIt also has \nfeatures\n including\n\n\n\n\nTensorFlow\n for backend computation, which includes automatic differentiation, GPU support, computational graphs, optimization, and TensorBoard\n\n\nA library for probability distributions in TensorFlow\n\n\nDocumentation and tutorials\n\n\nExamples demonstrating state-of-the-art generative models and inference\n\n\n\n\nGetting Started\n\n\nYou can find a tutorial here\n\nfor getting started with Edward. We highlight a few examples, more of\nwhich can be found in \nexamples/\n:\n\n\n\n\nBayesian linear regression\n\n\nHierarchical logistic regression\n\n\nMixture model of Gaussians\n\n\nGaussian process classification\n\n\nBayesian neural network\n\n\nMixture density network\n\n\nVariational auto-encoder\n\n\n\n\nInstallation\n\n\nTo install the latest stable version, run\n\n\npip install edward\n\n\n\n\nTo install the latest development version, run\n\n\npip install -e \ngit+https://github.com/blei-lab/edward.git#egg=edward\n\n\n\n\n\nAuthors\n\n\nEdward is led by \nDustin Tran\n with guidance by \nDavid Blei\n. It is under active development (by order of joining) by \nDustin Tran\n, \nDavid Blei\n, \nAlp Kucukelbir\n, \nAdji Dieng\n, \nMaja Rudolph\n, and \nDawen Liang\n. We welcome contributions by submitting issues, feature requests, or by solving any current issues!\n\n\nWe thank Rajesh Ranganath, Allison Chaney, Jaan Altosaar, and other members of the Blei Lab for their helpful feedback and advice.\n\n\nCitation\n\n\nWe appreciate citations for Edward because it lets us find out how\npeople have been using the library and it motivates further work.\n\n\nDustin Tran, David M. Blei, Alp Kucukelbir, Adji Dieng, Maja Rudolph, and Dawen Liang. 2016. Edward: A library for probabilistic modeling, inference, and criticism. http://edwardlib.org\n\n\n@misc{tran2016edward,\n  author = {Dustin Tran and David M. Blei and Alp Kucukelbir and Adji Dieng and Maja Rudolph and Dawen Liang},\n  title = {{Edward: A library for probabilistic modeling, inference, and criticism}},\n  year = {2016},\n  url = {http://edwardlib.org}\n}", 
            "title": "Home"
        }, 
        {
            "location": "/#welcome-to-edward", 
            "text": "Edward  is a Python library for probabilistic modeling, inference,\nand criticism. It enables black box inference for models with discrete\nand continuous latent variables, neural network parameterizations, and\ninfinite dimensional parameter spaces. Edward serves as a fusion of\nthree fields: Bayesian statistics and machine learning, deep learning,\nand probabilistic programming.  It supports  modeling languages  including   TensorFlow  (with neural network compositionality via  Keras ,  Pretty Tensor , or  TensorFlow-Slim )  Stan  PyMC3  original Python using  NumPy/SciPy   It supports  inference  via   Variational inference  Black box variational inference  Stochastic variational inference  Variational auto-encoders  Inclusive KL divergence (KL(p || q))  Laplace approximation    Marginal posterior optimization (empirical Bayes, marginal maximum likelihood)  Maximum a posteriori (penalized maximum likelihood, maximum likelihood)   It supports  criticism  of the model and inference via   Evaluations on both supervised and unsupervised tasks  Posterior predictive checks   It also has  features  including   TensorFlow  for backend computation, which includes automatic differentiation, GPU support, computational graphs, optimization, and TensorBoard  A library for probability distributions in TensorFlow  Documentation and tutorials  Examples demonstrating state-of-the-art generative models and inference", 
            "title": "Welcome to Edward"
        }, 
        {
            "location": "/#getting-started", 
            "text": "You can find a tutorial here \nfor getting started with Edward. We highlight a few examples, more of\nwhich can be found in  examples/ :   Bayesian linear regression  Hierarchical logistic regression  Mixture model of Gaussians  Gaussian process classification  Bayesian neural network  Mixture density network  Variational auto-encoder", 
            "title": "Getting Started"
        }, 
        {
            "location": "/#installation", 
            "text": "To install the latest stable version, run  pip install edward  To install the latest development version, run  pip install -e  git+https://github.com/blei-lab/edward.git#egg=edward", 
            "title": "Installation"
        }, 
        {
            "location": "/#authors", 
            "text": "Edward is led by  Dustin Tran  with guidance by  David Blei . It is under active development (by order of joining) by  Dustin Tran ,  David Blei ,  Alp Kucukelbir ,  Adji Dieng ,  Maja Rudolph , and  Dawen Liang . We welcome contributions by submitting issues, feature requests, or by solving any current issues!  We thank Rajesh Ranganath, Allison Chaney, Jaan Altosaar, and other members of the Blei Lab for their helpful feedback and advice.", 
            "title": "Authors"
        }, 
        {
            "location": "/#citation", 
            "text": "We appreciate citations for Edward because it lets us find out how\npeople have been using the library and it motivates further work.  Dustin Tran, David M. Blei, Alp Kucukelbir, Adji Dieng, Maja Rudolph, and Dawen Liang. 2016. Edward: A library for probabilistic modeling, inference, and criticism. http://edwardlib.org  @misc{tran2016edward,\n  author = {Dustin Tran and David M. Blei and Alp Kucukelbir and Adji Dieng and Maja Rudolph and Dawen Liang},\n  title = {{Edward: A library for probabilistic modeling, inference, and criticism}},\n  year = {2016},\n  url = {http://edwardlib.org}\n}", 
            "title": "Citation"
        }, 
        {
            "location": "/getting-started/", 
            "text": "Getting Started\n\n\nEdward\n is named after the innovative statistician\n\nGeorge Edward Pelham Box\n.\nEdward follows Box's philosophy of statistics and machine learning.\n\n\nFirst gather data from a real-world process. Then cycle through Box's loop:\n\n\n\n\nBuild a probabilistic model of the process\n\n\nReason about the process given model and data\n\n\nCriticize the model, revise and repeat\n\n\n\n\nHere's a toy example. A child flips a coin ten times, with the data of outcomes being \n[0, 1, 0, 0, 0, 0, 0, 0, 0, 1]\n. We are interested in the probability that the coin lands heads. First, build a model: assume the coin flips are independent and land heads with the same probability. Second, reason about the process: use an algorithm to infer the model given data. Third, criticize the model: analyze whether the model captures the real-world process of coin flips. If it doesn't, then revise the model and repeat.\n\n\nThis process defines the design of \nEdward\n. Here are the four primary objects that enable the above analysis. (More \nedward\n syntax follows in a complete example.)\n\n\nData\n\n\nData\n objects are containers that contain measurements. The structure of these objects must match the inputs of the probabilistic model.\n\n\ndata = ed.Data(np.array([0, 1, 0, 0, 0, 0, 0, 0, 0, 1]))\n\n\n\n\nModels\n\n\nThere are two types of model objects in Edward:\n\n\n\n\nProbability models of data\n\n\nVariational models of latent variables\n\n\n\n\nWe can specify probability models of data using NumPy/SciPy, TensorFlow, PyMC3, or Stan. Here is a model of coin flips using a \nBeta-Bernoulli distribution\n in NumPy/Scipy.\n\n\nclass BetaBernoulli(PythonModel):\n    \np(x, z) = Bernoulli(x | z) * Beta(z | 1, 1)\n    \n\n    def _py_log_prob(self, xs, zs):\n        n_samples = zs.shape[0]\n        lp = np.zeros(n_samples, dtype=np.float32)\n        for s in range(n_samples):\n            lp[s] = beta.logpdf(zs[s, :], a=1.0, b=1.0)\n            for n in range(len(xs)):\n                lp[s] += bernoulli.logpmf(xs[n], p=zs[s, :])\n        return lp\n\n\n\n\nThis describes a Bayesian model, which is a joint distribution of data and latent variables \nz\n. With this model and data of coin flips, we aim to reason about \nz\n, the probability that the coin lands heads. The posterior distribution of \nz\n captures our reasoning: its mean describes our best guess of the probability, and its variance describes our uncertainty around our best guess. In this toy model, we know that the posterior is a Beta distribution. Let us assume we do not know its parameters in closed form.\n\n\nEdward can employ variational inference to infer this posterior, which finds the closest distribution within a specified family. Initialize an empty  \nVariational()\n model. Then add a Beta distribution to the variational model.\n\n\nvariational = Variational()\nvariational.add(Beta())\n\n\n\n\nWith this syntax, we can build rich variational models to describe the latent variables in our data models. (More documentation on this coming soon.)\n\n\nInference\n\n\nInference\n objects infer latent variables of models given data. Edward currently supports a variety of variational inference algorithms. These take as input a probability model, a variational model, and data.\n\n\nHere we use mean-field variational inference.\n\n\ninference = ed.MFVI(model, variational, data)\n\n\n\n\n(For the technical audience, the mean-field assumption of a fully factorized approximation is moot here. We're dealing with a one-dimensional latent variable.)\n\n\nCalling \ninference.run\n runs the inference algorithm until convergence. It recovers a Beta distribution with mean 0.25 and variance 0.12. 0.25 is our best guess of the probability that the coin lands heads.\n\n\nCriticism\n\n\n[In Progress]\n\n\nA complete example: the Beta-Bernoulli model\n\n\nHere is a complete script, defining the data, model, and the variational model. We run mean-field variational inference for \n10000\n iterations at the end. The same example is also available in cases where the model is written in \nStan\n, \nPyMC3\n and \nTensorFlow\n respectively.\n\n\nA simple coin flipping example. The model is written in NumPy/SciPy.\n\nProbability model\n    Prior: Beta\n    Likelihood: Bernoulli\nVariational model\n    Likelihood: Mean-field Beta\n\n\nimport edward as ed\nimport numpy as np\n\nfrom edward.models import PythonModel, Variational, Beta\nfrom scipy.stats import beta, bernoulli\n\nclass BetaBernoulli(PythonModel):\n    \np(x, z) = Bernoulli(x | z) * Beta(z | 1, 1)\n    \n\n    def _py_log_prob(self, xs, zs):\n        # This example is pedagogical.\n        # We recommend vectorizing operations in practice.\n        n_minibatch = zs.shape[0]\n        lp = np.zeros(n_minibatch, dtype=np.float32)\n        for s in range(n_minibatch):\n            lp[s] = beta.logpdf(zs[s, :], a=1.0, b=1.0)\n            for n in range(len(xs)):\n                lp[s] += bernoulli.logpmf(xs[n], p=zs[s, :])\n        return lp\n\ndata = ed.Data(np.array([0, 1, 0, 0, 0, 0, 0, 0, 0, 1]))\nmodel = BetaBernoulli()\nvariational = Variational()\nvariational.add(Beta())\ninference = ed.MFVI(model, variational, data)\n\ninference.run(n_iter=10000)\n\n\n\n\nMore Links\n\n\nYou can find more complicated examples in the \nexamples/\n directory. We highlight several here:\n\n\n\n\nBayesian linear regression\n\n\nHierarchical logistic regression\n\n\nMixture model of Gaussians\n\n\nGaussian process classification\n\n\nBayesian neural network\n\n\nMixture density network\n\n\nVariational auto-encoder\n\n\n\n\nWe think the library will make it significantly easier to do research in machine learning and statistics. You can find more about this \nhere\n.\n\n\nYou can find more about Edward's design and philosophy, and how it relates to other software \nhere\n.\n\n\nReferences\n\n\n\n\nDavid M Blei. Build, compute, critique, repeat: data analysis with latent variable models. Annual Review of Statistics and Its Application, 1:203-232, 2014.", 
            "title": "Getting Started"
        }, 
        {
            "location": "/getting-started/#getting-started", 
            "text": "Edward  is named after the innovative statistician George Edward Pelham Box .\nEdward follows Box's philosophy of statistics and machine learning.  First gather data from a real-world process. Then cycle through Box's loop:   Build a probabilistic model of the process  Reason about the process given model and data  Criticize the model, revise and repeat   Here's a toy example. A child flips a coin ten times, with the data of outcomes being  [0, 1, 0, 0, 0, 0, 0, 0, 0, 1] . We are interested in the probability that the coin lands heads. First, build a model: assume the coin flips are independent and land heads with the same probability. Second, reason about the process: use an algorithm to infer the model given data. Third, criticize the model: analyze whether the model captures the real-world process of coin flips. If it doesn't, then revise the model and repeat.  This process defines the design of  Edward . Here are the four primary objects that enable the above analysis. (More  edward  syntax follows in a complete example.)", 
            "title": "Getting Started"
        }, 
        {
            "location": "/getting-started/#data", 
            "text": "Data  objects are containers that contain measurements. The structure of these objects must match the inputs of the probabilistic model.  data = ed.Data(np.array([0, 1, 0, 0, 0, 0, 0, 0, 0, 1]))", 
            "title": "Data"
        }, 
        {
            "location": "/getting-started/#models", 
            "text": "There are two types of model objects in Edward:   Probability models of data  Variational models of latent variables   We can specify probability models of data using NumPy/SciPy, TensorFlow, PyMC3, or Stan. Here is a model of coin flips using a  Beta-Bernoulli distribution  in NumPy/Scipy.  class BetaBernoulli(PythonModel):\n     p(x, z) = Bernoulli(x | z) * Beta(z | 1, 1)\n     \n    def _py_log_prob(self, xs, zs):\n        n_samples = zs.shape[0]\n        lp = np.zeros(n_samples, dtype=np.float32)\n        for s in range(n_samples):\n            lp[s] = beta.logpdf(zs[s, :], a=1.0, b=1.0)\n            for n in range(len(xs)):\n                lp[s] += bernoulli.logpmf(xs[n], p=zs[s, :])\n        return lp  This describes a Bayesian model, which is a joint distribution of data and latent variables  z . With this model and data of coin flips, we aim to reason about  z , the probability that the coin lands heads. The posterior distribution of  z  captures our reasoning: its mean describes our best guess of the probability, and its variance describes our uncertainty around our best guess. In this toy model, we know that the posterior is a Beta distribution. Let us assume we do not know its parameters in closed form.  Edward can employ variational inference to infer this posterior, which finds the closest distribution within a specified family. Initialize an empty   Variational()  model. Then add a Beta distribution to the variational model.  variational = Variational()\nvariational.add(Beta())  With this syntax, we can build rich variational models to describe the latent variables in our data models. (More documentation on this coming soon.)", 
            "title": "Models"
        }, 
        {
            "location": "/getting-started/#inference", 
            "text": "Inference  objects infer latent variables of models given data. Edward currently supports a variety of variational inference algorithms. These take as input a probability model, a variational model, and data.  Here we use mean-field variational inference.  inference = ed.MFVI(model, variational, data)  (For the technical audience, the mean-field assumption of a fully factorized approximation is moot here. We're dealing with a one-dimensional latent variable.)  Calling  inference.run  runs the inference algorithm until convergence. It recovers a Beta distribution with mean 0.25 and variance 0.12. 0.25 is our best guess of the probability that the coin lands heads.", 
            "title": "Inference"
        }, 
        {
            "location": "/getting-started/#criticism", 
            "text": "[In Progress]", 
            "title": "Criticism"
        }, 
        {
            "location": "/getting-started/#a-complete-example-the-beta-bernoulli-model", 
            "text": "Here is a complete script, defining the data, model, and the variational model. We run mean-field variational inference for  10000  iterations at the end. The same example is also available in cases where the model is written in  Stan ,  PyMC3  and  TensorFlow  respectively.  A simple coin flipping example. The model is written in NumPy/SciPy.\n\nProbability model\n    Prior: Beta\n    Likelihood: Bernoulli\nVariational model\n    Likelihood: Mean-field Beta \nimport edward as ed\nimport numpy as np\n\nfrom edward.models import PythonModel, Variational, Beta\nfrom scipy.stats import beta, bernoulli\n\nclass BetaBernoulli(PythonModel):\n     p(x, z) = Bernoulli(x | z) * Beta(z | 1, 1)\n     \n    def _py_log_prob(self, xs, zs):\n        # This example is pedagogical.\n        # We recommend vectorizing operations in practice.\n        n_minibatch = zs.shape[0]\n        lp = np.zeros(n_minibatch, dtype=np.float32)\n        for s in range(n_minibatch):\n            lp[s] = beta.logpdf(zs[s, :], a=1.0, b=1.0)\n            for n in range(len(xs)):\n                lp[s] += bernoulli.logpmf(xs[n], p=zs[s, :])\n        return lp\n\ndata = ed.Data(np.array([0, 1, 0, 0, 0, 0, 0, 0, 0, 1]))\nmodel = BetaBernoulli()\nvariational = Variational()\nvariational.add(Beta())\ninference = ed.MFVI(model, variational, data)\n\ninference.run(n_iter=10000)", 
            "title": "A complete example: the Beta-Bernoulli model"
        }, 
        {
            "location": "/getting-started/#more-links", 
            "text": "You can find more complicated examples in the  examples/  directory. We highlight several here:   Bayesian linear regression  Hierarchical logistic regression  Mixture model of Gaussians  Gaussian process classification  Bayesian neural network  Mixture density network  Variational auto-encoder   We think the library will make it significantly easier to do research in machine learning and statistics. You can find more about this  here .  You can find more about Edward's design and philosophy, and how it relates to other software  here .", 
            "title": "More Links"
        }, 
        {
            "location": "/getting-started/#references", 
            "text": "David M Blei. Build, compute, critique, repeat: data analysis with latent variable models. Annual Review of Statistics and Its Application, 1:203-232, 2014.", 
            "title": "References"
        }, 
        {
            "location": "/guide-research/", 
            "text": "Getting Started for Research\n\n\nThis is a guide to how to use Edward for research. Following Box's loop, we divide research into three components: model, inference, and criticism.\n\n\nAs the library uses TensorFlow as a backend, here is a quick guide on \nhow to get started with it\n. You will most likely need to work directly in TensorFlow as you manipulate different objects and understand how certain behaviors of the new research works. Here is an \nexample\n with access to the TensorFlow session rather than hiding the TensorFlow internals with \ninference.run\n.\n\n\nDeveloping new probabilistic models\n\n\nA probabilistic model is specified by a joint distribution \np(x,z)\n of data \nx\n and latent variables \nz\n. All models in Edward are written as a class; to implement a new model, it can be written in any of the currently supported modeling languages: Stan, TensorFlow, and NumPy/SciPy.\n\n\nTo use Stan, simply write a Stan program in the form of a file or string. Then call it with \nStanModel(file)\n or \nStanModel(model_code)\n. Here is an example:\n\n\nmodel_code = \n\n    data {\n      int\nlower=0\n N;\n      int\nlower=0,upper=1\n y[N];\n    }\n    parameters {\n      real\nlower=0,upper=1\n theta;\n    }\n    model {\n      theta ~ beta(1.0, 1.0);\n      for (n in 1:N)\n        y[n] ~ bernoulli(theta);\n    }\n\n\nmodel = ed.StanModel(model_code=model_code)\n\n\n\n\nHere is a \ntoy script\n that uses this model. Stan programs are convenient as \nthere are many online examples\n, although they are limited to probability models with differentiable latent variables and they can be quite slow to call in practice over TensorFlow.\n\n\nTo use TensorFlow, PyMC3, or NumPy/SciPy, write a class with the method \nlog_prob(xs, zs)\n. This method takes as input a mini-batch of data \nxs\n and a mini-batch of the latent variables \nzs\n; the method outputs a vector of the joint density evaluations \n[log p(xs, zs[0,:]), log p(xs, zs[1,:]), ...]\n with size being the size of the latent variables' mini-batch. Here is an example:\n\n\nclass BetaBernoulli:\n    \n\n    p(x, z) = Bernoulli(x | z) * Beta(z | 1, 1)\n    \n\n    def __init__(self):\n        self.num_vars = 1\n\n    def log_prob(self, xs, zs):\n        log_prior = beta.logpdf(zs, a=1.0, b=1.0)\n        log_lik = tf.pack([tf.reduce_sum(bernoulli.logpmf(xs, z))\n                           for z in tf.unpack(zs)])\n        return log_lik + log_prior\n\nmodel = BetaBernoulli()\n\n\n\n\nHere is a \ntoy script\n that uses this model which is written in TensorFlow. Here is another \ntoy script\n that uses the same model written in NumPy/SciPy and \nanother\n written in PyMC3.\n\n\nFor efficiency during future inferences or criticisms, we recommend using the modeling language which contains the most structure about the model; this enables the inference algorithms to automatically take advantage of any available structure if they are implemented to do so. TensorFlow will be most efficient as Edward uses it as the backend for computation.\n\n\nDeveloping new inference algorithms\n\n\nAn inference algorithm calculates the posterior for a particular model and data set; it is the distribution of the latent variables given data, \np(z | x)\n, and is used in all downstream analyses such as prediction. With Edward, you can develop new black box inference algorithms and also develop custom inference algorithms which are tailored to a particular model or restricted class of models.\n\n\nThere is a base \nInference\n class, from which all inference methods are based on. We categorize inference under two paradigms:\n\n\n\n\nVariationalInference\n\n\nMonteCarlo\n\n\n\n\n(or more plainly, optimization and sampling). These inherit from \nInference\n and each have their own default methods. See the file \ninferences.py\n.\n\n\nConsider developing a variational inference algorithm.\nThe main method in \nVariationalInference\n is \nrun()\n, which is a simple wrapper that first runs \ninitialize()\n and then in a loop runs \nupdate()\n and \nprint_progress()\n. To develop a new variational inference algorithm, inherit from \nVariationalInference\n and write a new method for \nbuild_loss()\n: this returns an object that TensorFlow will automatically differentiate during optimization. The other methods have defaults which you can update as necessary. The \ninclusive KL divergence algorithm in \ninferences.py\n is a useful example. It writes \nbuild_loss()\n so that automatic diferentiation of its return object is a tractable gradient that minimizes KL(p||q). It also modifies \ninitialize()\n and \nupdate()\n.\n\n\nConsider developing a Monte Carlo algorithm. Inherit from \nMonteCarlo\n.[Documentation is in progress.]\n\n\nNote that you can build model-specific inference algorithms and inference algorithms that are tailored to a smaller class than the general class available here. There's nothing preventing you to do so, and the general organizational paradigm and low-level functions are still useful in such a case. You can write a class that for example inherits from \nInference\n directly or inherits to carry both optimization and sampling methods.\n\n\nDeveloping new criticism techniques\n\n\n[Documentation is in progress.]", 
            "title": "Guide for Research"
        }, 
        {
            "location": "/guide-research/#getting-started-for-research", 
            "text": "This is a guide to how to use Edward for research. Following Box's loop, we divide research into three components: model, inference, and criticism.  As the library uses TensorFlow as a backend, here is a quick guide on  how to get started with it . You will most likely need to work directly in TensorFlow as you manipulate different objects and understand how certain behaviors of the new research works. Here is an  example  with access to the TensorFlow session rather than hiding the TensorFlow internals with  inference.run .", 
            "title": "Getting Started for Research"
        }, 
        {
            "location": "/guide-research/#developing-new-probabilistic-models", 
            "text": "A probabilistic model is specified by a joint distribution  p(x,z)  of data  x  and latent variables  z . All models in Edward are written as a class; to implement a new model, it can be written in any of the currently supported modeling languages: Stan, TensorFlow, and NumPy/SciPy.  To use Stan, simply write a Stan program in the form of a file or string. Then call it with  StanModel(file)  or  StanModel(model_code) . Here is an example:  model_code =  \n    data {\n      int lower=0  N;\n      int lower=0,upper=1  y[N];\n    }\n    parameters {\n      real lower=0,upper=1  theta;\n    }\n    model {\n      theta ~ beta(1.0, 1.0);\n      for (n in 1:N)\n        y[n] ~ bernoulli(theta);\n    } \nmodel = ed.StanModel(model_code=model_code)  Here is a  toy script  that uses this model. Stan programs are convenient as  there are many online examples , although they are limited to probability models with differentiable latent variables and they can be quite slow to call in practice over TensorFlow.  To use TensorFlow, PyMC3, or NumPy/SciPy, write a class with the method  log_prob(xs, zs) . This method takes as input a mini-batch of data  xs  and a mini-batch of the latent variables  zs ; the method outputs a vector of the joint density evaluations  [log p(xs, zs[0,:]), log p(xs, zs[1,:]), ...]  with size being the size of the latent variables' mini-batch. Here is an example:  class BetaBernoulli:\n     \n    p(x, z) = Bernoulli(x | z) * Beta(z | 1, 1)\n     \n    def __init__(self):\n        self.num_vars = 1\n\n    def log_prob(self, xs, zs):\n        log_prior = beta.logpdf(zs, a=1.0, b=1.0)\n        log_lik = tf.pack([tf.reduce_sum(bernoulli.logpmf(xs, z))\n                           for z in tf.unpack(zs)])\n        return log_lik + log_prior\n\nmodel = BetaBernoulli()  Here is a  toy script  that uses this model which is written in TensorFlow. Here is another  toy script  that uses the same model written in NumPy/SciPy and  another  written in PyMC3.  For efficiency during future inferences or criticisms, we recommend using the modeling language which contains the most structure about the model; this enables the inference algorithms to automatically take advantage of any available structure if they are implemented to do so. TensorFlow will be most efficient as Edward uses it as the backend for computation.", 
            "title": "Developing new probabilistic models"
        }, 
        {
            "location": "/guide-research/#developing-new-inference-algorithms", 
            "text": "An inference algorithm calculates the posterior for a particular model and data set; it is the distribution of the latent variables given data,  p(z | x) , and is used in all downstream analyses such as prediction. With Edward, you can develop new black box inference algorithms and also develop custom inference algorithms which are tailored to a particular model or restricted class of models.  There is a base  Inference  class, from which all inference methods are based on. We categorize inference under two paradigms:   VariationalInference  MonteCarlo   (or more plainly, optimization and sampling). These inherit from  Inference  and each have their own default methods. See the file  inferences.py .  Consider developing a variational inference algorithm.\nThe main method in  VariationalInference  is  run() , which is a simple wrapper that first runs  initialize()  and then in a loop runs  update()  and  print_progress() . To develop a new variational inference algorithm, inherit from  VariationalInference  and write a new method for  build_loss() : this returns an object that TensorFlow will automatically differentiate during optimization. The other methods have defaults which you can update as necessary. The  inclusive KL divergence algorithm in  inferences.py  is a useful example. It writes  build_loss()  so that automatic diferentiation of its return object is a tractable gradient that minimizes KL(p||q). It also modifies  initialize()  and  update() .  Consider developing a Monte Carlo algorithm. Inherit from  MonteCarlo .[Documentation is in progress.]  Note that you can build model-specific inference algorithms and inference algorithms that are tailored to a smaller class than the general class available here. There's nothing preventing you to do so, and the general organizational paradigm and low-level functions are still useful in such a case. You can write a class that for example inherits from  Inference  directly or inherits to carry both optimization and sampling methods.", 
            "title": "Developing new inference algorithms"
        }, 
        {
            "location": "/guide-research/#developing-new-criticism-techniques", 
            "text": "[Documentation is in progress.]", 
            "title": "Developing new criticism techniques"
        }, 
        {
            "location": "/design/", 
            "text": "Design and Philosophy\n\n\nEdward\n serves two purposes:\n\n\n\n\n\n\nto serve as a foundation for research;\n\n\n\n\n\n\nto provide a unified library for inference and criticism, with modeling tools at our disposal.\n\n\n\n\n\n\nAs a research tool, the code base serves as a testbed for fast experimentation, so that we can easily play with extensions of current paradigms. For example, to evaluate new inference algorithms, the experiments only need to be written once and we can simply swap the inference with the newly proposed algorithm. For certain inference algorithms, this corresponds to inheriting from a current inference class and simply writing one function. This idea applies to all components of probabilistic modeling: we can leverage the built-in inference algorithms to develop new complex models, or use the built-in models and inference to develop new criticism techniques.\n\n\nAs an applied tool, Edward supports a wide variety of settings, ranging from classical hierarchical models on small data sets to complex deep probabilistic models on large data sets. With \nTensorFlow\n as a backend, Edward can leverage features such as computational graphs, distributed training, and CPU/GPU integration to deploy probabilistic modeling at scale. It also has the fundamentals: for example, linear model examples, mixture model examples, probabilistic neural networks, and stochastic and black box variational inference.\n\n\nRelated Software\n\n\nThere are several notable themes in Edward.\n\n\nProbabilistic programming.\n\nThere has been incredible progress recently on developing generic languages for specifying probabilistic models, or probabilistic programs. Among these include \nVenture\n, \nAnglican\n, \nFigaro\n, \nStan\n, and \nWebPPL\n. Edward focuses less on the language and more on easily enabling probabilistic modeling across all components of data analysis. For example, we use Stan's modeling language as an easy way to specify models in Edward, and our library enables fast experimentation on their inference and criticism.\n\n\nBlack box inference.\n\nImplementations of inference algorithms are usually tied to a specific probabilistic programming language, and the majority of these are black box algorithms, using sequential Monte Carlo and making very few assumptions about the model. There are three important distinctions. First, we focus primarily on variational inference. Second, we are agnostic to the modeling language. Third, we believe inference algorithms should take advantage of as much structure as possible from the model. Thus Edward supports all types of inference algorithms, whether they be black box or model-specific, being tailored to a single model or restricted class of models. This makes Edward's probabilistic modeling a rich and practical tool for real-world applications. It also makes Edward suitable for experimenting with all types of inference.\n\n\nComputational frameworks.\n\nThere are many computational frameworks, primarily built for deep learning: as of this date, this includes \nTensorFlow\n,\nTheano\n, \nTorch\n, \nComputational Graph Toolkit\n, \nneon\n, and \nStan Math Library\n. These are incredible tools which Edward employs as a backend. In terms of abstraction, Edward sits at one level higher. For example, we chose to use TensorFlow among the bunch due to Python as our language of choice for machine learning research and as an investment in Google's massive engineering.\n\n\nHigh-level deep learning libraries.\n\nNeural network libraries such as \nKeras\n and \nLasagne\n are at a similar abstraction level as us, but they are primarily interested in parameterizing complicated functions for supervised learning on large datasets. We are more interested in probabilistic models which apply to a wide amount of learning tasks, and which can have both complicated likelihood and complicated priors (neural networks are an option but not a necessity). Therefore our goals are orthogonal and in fact mutually benefit each other. For example, we use Keras' abstraction as a way to easily specify models parameterized by deep neural networks.", 
            "title": "Design and Philosophy"
        }, 
        {
            "location": "/design/#design-and-philosophy", 
            "text": "Edward  serves two purposes:    to serve as a foundation for research;    to provide a unified library for inference and criticism, with modeling tools at our disposal.    As a research tool, the code base serves as a testbed for fast experimentation, so that we can easily play with extensions of current paradigms. For example, to evaluate new inference algorithms, the experiments only need to be written once and we can simply swap the inference with the newly proposed algorithm. For certain inference algorithms, this corresponds to inheriting from a current inference class and simply writing one function. This idea applies to all components of probabilistic modeling: we can leverage the built-in inference algorithms to develop new complex models, or use the built-in models and inference to develop new criticism techniques.  As an applied tool, Edward supports a wide variety of settings, ranging from classical hierarchical models on small data sets to complex deep probabilistic models on large data sets. With  TensorFlow  as a backend, Edward can leverage features such as computational graphs, distributed training, and CPU/GPU integration to deploy probabilistic modeling at scale. It also has the fundamentals: for example, linear model examples, mixture model examples, probabilistic neural networks, and stochastic and black box variational inference.", 
            "title": "Design and Philosophy"
        }, 
        {
            "location": "/design/#related-software", 
            "text": "There are several notable themes in Edward.  Probabilistic programming. \nThere has been incredible progress recently on developing generic languages for specifying probabilistic models, or probabilistic programs. Among these include  Venture ,  Anglican ,  Figaro ,  Stan , and  WebPPL . Edward focuses less on the language and more on easily enabling probabilistic modeling across all components of data analysis. For example, we use Stan's modeling language as an easy way to specify models in Edward, and our library enables fast experimentation on their inference and criticism.  Black box inference. \nImplementations of inference algorithms are usually tied to a specific probabilistic programming language, and the majority of these are black box algorithms, using sequential Monte Carlo and making very few assumptions about the model. There are three important distinctions. First, we focus primarily on variational inference. Second, we are agnostic to the modeling language. Third, we believe inference algorithms should take advantage of as much structure as possible from the model. Thus Edward supports all types of inference algorithms, whether they be black box or model-specific, being tailored to a single model or restricted class of models. This makes Edward's probabilistic modeling a rich and practical tool for real-world applications. It also makes Edward suitable for experimenting with all types of inference.  Computational frameworks. \nThere are many computational frameworks, primarily built for deep learning: as of this date, this includes  TensorFlow , Theano ,  Torch ,  Computational Graph Toolkit ,  neon , and  Stan Math Library . These are incredible tools which Edward employs as a backend. In terms of abstraction, Edward sits at one level higher. For example, we chose to use TensorFlow among the bunch due to Python as our language of choice for machine learning research and as an investment in Google's massive engineering.  High-level deep learning libraries. \nNeural network libraries such as  Keras  and  Lasagne  are at a similar abstraction level as us, but they are primarily interested in parameterizing complicated functions for supervised learning on large datasets. We are more interested in probabilistic models which apply to a wide amount of learning tasks, and which can have both complicated likelihood and complicated priors (neural networks are an option but not a necessity). Therefore our goals are orthogonal and in fact mutually benefit each other. For example, we use Keras' abstraction as a way to easily specify models parameterized by deep neural networks.", 
            "title": "Related Software"
        }, 
        {
            "location": "/developer/", 
            "text": "Developer Process\n\n\nStandards\n\n\n\n\nPull request and branches.\n Contribute by developing on a clone of the repo and writing the code in a branch. Submit a pull request when ready.\n\n\n\n\nFor developers with push permission to the repo, see \nStan's process\n for how to name branches.  Do not merge your own pull requests or ever push to master. Someone should always review your code.  After merging (or deciding to close the request without merging), always delete the branch from the repo.\n\n\n\n\nUnit testing.\n Unit testing is awesome. It's useful not only for checking code after having written it, but also in checking code as you are developing it. If you're informally writing short scripts that output various things anyways, I suggest saving the file in the \ntests/\n directory. This gets the momentum going as the test becomes formalized. For testing, simply run \nnose2\n in the repo; it will automatically find and run all tests in \ntests/\n. Most if not all pull requests should have unit tests.\n\n\nIssue labeling system.\n We use \nStan's labeling system\n. While several labels obviously don't apply to us, it's better than the default labels and it's not worth the effort to reinvent the wheel and maintain a custom system.\n\n\n\n\nCoding\n\n\n\n\nStyle guidelines.\n Follow \nTensorFlow\n, including its \ndocumentation guidelines\n.  The only exceptions are detailed below. Some below are not necessarily exceptions but simply emphasize style guidelines you should be following from TensorFlow or PEP 8 anyways.\n\n\nUse four-space indents rather than two-space.\n\n\nTo organize imports in a script, use three blocks: 1. any \nfrom __future__ import [...]\n lines; 2. any \nimport [...]\n lines; and 3. any \nfrom [...] import [...]\n lines. Each block is separated by a blank line, and within each block the lines are sorted alphabetically.\n\n\nedward.stats\n uses SciPy standards. This includes, for example, the argument specification and the choice of how a distribution is parameterized. \nedward.models\n uses \ntf.contrib.distributions\n standards.\n\n\nFor arguments that are positive integers, use \nn_\n, e.g., \nn_minibatch\n, \nn_print\n, to represent \"number of [...]\".  For class attributes that are booleans, use \nis_\n, e.g., \nis_reparameterized\n, \nis_multivariate\n.\n\n\nAim for 70 characters per line, with some exceptions.\n\n\nPackage names are almost always plural, with the exception of\n \nutil.py\n.\n\n\nUse a blank line to separate the end of an indented procedure:\n\n\n\n\nfor i in range(5):\n    do_stuff()\n\nmore_code()\n\n\n\n\nSuggested workflow\n\n\n\n\nUpdate your Python path.\n As you make changes, it can be cumbersome to constantly reinstall the package to test these changes. We recommend adding the path to your local repo to your \nPYTHONPATH\n. That is, run the following on the command-line:\n\n\n\n\nexport PYTHONPATH=\n${PYTHONPATH}:/path/to/repo\n\n\n\n\n\nFor this to work permanently, add this line to your \n~/.bashrc\n if you use Bash or \n~/.zshenv\n if you use zsh. Any time you import the package, it will look for the package locally via this directory path.\n\n\n\n\nLocal installation.\n Sometimes it does make sense to check the installation. To install locally, run the following when at the parent directory of the repo:\n\n\n\n\npip install -e edward\n\n\n\n\n(We recommend not installing with \nsudo\n; rather \nuse virtualenv\n.)\n\n\n\n\nPackaging and submitting to PyPI.\n First, update the version number in \nsetup.py\n. Second, follow \nthese steps\n. For shorthand, the sequence of commands is\n\n\n\n\npython setup.py sdist\npython setup.py bdist_wheel\ntwine upload dist/*\n\n\n\n\nThird, tag the release on Github and note the new additions when tagging this release. You can do this by comparing commits from the previous tagged release to master. A link that compares tagged commits to master is available on the \nreleases page\n.\n\n\nSuggested private workflow\n\n\nTo develop work on a branch privately, we suggest using a private repo that maintains the master branch from the public repo. Development happens on the private repo's branch, and when it is finished, you can push it to the public repo's branch to submit as a pull request. We describe this in detail.\n\n\nClone the private repo so you can work on it (create a repo if it does not exist).\n\n\ngit clone https://github.com/blei-lab/edward-private.git\n\n\n\n\nPull changes from the public repo. This will let the private repo have the latest code from the public repo on its master branch.\n\n\ncd edward-private\ngit remote add public https://github.com/blei-lab/edward.git\ngit pull public master # Creates a merge commit\ngit push origin master\n\n\n\n\nNow create your branch on the private repo, develop stuff, and pull any latest changes from the public repo as you develop (\ngit pull public master\n). Make sure that as you're running Edward, you're using the Edward library pointing to the private repo so it reflects your developer changes and not pointed to the public repo where it won't see any changes.\n\n\nFinally, to create a pull request from a private repo's branch to the public repo, push the private branch to the public repo.\n\n\ngit clone https://github.com/blei-lab/edward.git\ncd edward\ngit remote add private https://github.com/blei-lab/edward-private.git\ngit checkout -b pull_request_yourname\ngit pull private master\ngit push origin pull_request_yourname\n\n\n\n\nNow simply create a pull request via the Github UI on the public repo. Once project owners review the pull request, they can merge it. \nSource", 
            "title": "Developer Process"
        }, 
        {
            "location": "/developer/#developer-process", 
            "text": "", 
            "title": "Developer Process"
        }, 
        {
            "location": "/developer/#standards", 
            "text": "Pull request and branches.  Contribute by developing on a clone of the repo and writing the code in a branch. Submit a pull request when ready.   For developers with push permission to the repo, see  Stan's process  for how to name branches.  Do not merge your own pull requests or ever push to master. Someone should always review your code.  After merging (or deciding to close the request without merging), always delete the branch from the repo.   Unit testing.  Unit testing is awesome. It's useful not only for checking code after having written it, but also in checking code as you are developing it. If you're informally writing short scripts that output various things anyways, I suggest saving the file in the  tests/  directory. This gets the momentum going as the test becomes formalized. For testing, simply run  nose2  in the repo; it will automatically find and run all tests in  tests/ . Most if not all pull requests should have unit tests.  Issue labeling system.  We use  Stan's labeling system . While several labels obviously don't apply to us, it's better than the default labels and it's not worth the effort to reinvent the wheel and maintain a custom system.   Coding   Style guidelines.  Follow  TensorFlow , including its  documentation guidelines .  The only exceptions are detailed below. Some below are not necessarily exceptions but simply emphasize style guidelines you should be following from TensorFlow or PEP 8 anyways.  Use four-space indents rather than two-space.  To organize imports in a script, use three blocks: 1. any  from __future__ import [...]  lines; 2. any  import [...]  lines; and 3. any  from [...] import [...]  lines. Each block is separated by a blank line, and within each block the lines are sorted alphabetically.  edward.stats  uses SciPy standards. This includes, for example, the argument specification and the choice of how a distribution is parameterized.  edward.models  uses  tf.contrib.distributions  standards.  For arguments that are positive integers, use  n_ , e.g.,  n_minibatch ,  n_print , to represent \"number of [...]\".  For class attributes that are booleans, use  is_ , e.g.,  is_reparameterized ,  is_multivariate .  Aim for 70 characters per line, with some exceptions.  Package names are almost always plural, with the exception of   util.py .  Use a blank line to separate the end of an indented procedure:   for i in range(5):\n    do_stuff()\n\nmore_code()", 
            "title": "Standards"
        }, 
        {
            "location": "/developer/#suggested-workflow", 
            "text": "Update your Python path.  As you make changes, it can be cumbersome to constantly reinstall the package to test these changes. We recommend adding the path to your local repo to your  PYTHONPATH . That is, run the following on the command-line:   export PYTHONPATH= ${PYTHONPATH}:/path/to/repo   For this to work permanently, add this line to your  ~/.bashrc  if you use Bash or  ~/.zshenv  if you use zsh. Any time you import the package, it will look for the package locally via this directory path.   Local installation.  Sometimes it does make sense to check the installation. To install locally, run the following when at the parent directory of the repo:   pip install -e edward  (We recommend not installing with  sudo ; rather  use virtualenv .)   Packaging and submitting to PyPI.  First, update the version number in  setup.py . Second, follow  these steps . For shorthand, the sequence of commands is   python setup.py sdist\npython setup.py bdist_wheel\ntwine upload dist/*  Third, tag the release on Github and note the new additions when tagging this release. You can do this by comparing commits from the previous tagged release to master. A link that compares tagged commits to master is available on the  releases page .", 
            "title": "Suggested workflow"
        }, 
        {
            "location": "/developer/#suggested-private-workflow", 
            "text": "To develop work on a branch privately, we suggest using a private repo that maintains the master branch from the public repo. Development happens on the private repo's branch, and when it is finished, you can push it to the public repo's branch to submit as a pull request. We describe this in detail.  Clone the private repo so you can work on it (create a repo if it does not exist).  git clone https://github.com/blei-lab/edward-private.git  Pull changes from the public repo. This will let the private repo have the latest code from the public repo on its master branch.  cd edward-private\ngit remote add public https://github.com/blei-lab/edward.git\ngit pull public master # Creates a merge commit\ngit push origin master  Now create your branch on the private repo, develop stuff, and pull any latest changes from the public repo as you develop ( git pull public master ). Make sure that as you're running Edward, you're using the Edward library pointing to the private repo so it reflects your developer changes and not pointed to the public repo where it won't see any changes.  Finally, to create a pull request from a private repo's branch to the public repo, push the private branch to the public repo.  git clone https://github.com/blei-lab/edward.git\ncd edward\ngit remote add private https://github.com/blei-lab/edward-private.git\ngit checkout -b pull_request_yourname\ngit pull private master\ngit push origin pull_request_yourname  Now simply create a pull request via the Github UI on the public repo. Once project owners review the pull request, they can merge it.  Source", 
            "title": "Suggested private workflow"
        }, 
        {
            "location": "/tensorflow/", 
            "text": "Getting Started with TensorFlow\n\n\nIf you'd like to use this library for research, you have to learn TensorFlow. Trust me. It's worth the investment. As a heuristic, it takes roughly a day to have a good grasp of the essential mechanics behind the library.\n\n\nHere's what I recommend for learning TensorFlow.\n\n\n\n\nRead TensorFlow's \nGetting Started\n. It tells you the essential objects that it works with.\n\n\nSkim through the simple examples in these \nTensorFlow tutorials\n. It gives you a big picture of the semantics and how the commands generally work with each other.\n\n\nSkim through the example code in this library! If you\u2019re familiar with the underlying math for variational inference, going through the code base here will also teach you the mapping from math to TensorFlow.", 
            "title": "TensorFlow"
        }, 
        {
            "location": "/tensorflow/#getting-started-with-tensorflow", 
            "text": "If you'd like to use this library for research, you have to learn TensorFlow. Trust me. It's worth the investment. As a heuristic, it takes roughly a day to have a good grasp of the essential mechanics behind the library.  Here's what I recommend for learning TensorFlow.   Read TensorFlow's  Getting Started . It tells you the essential objects that it works with.  Skim through the simple examples in these  TensorFlow tutorials . It gives you a big picture of the semantics and how the commands generally work with each other.  Skim through the example code in this library! If you\u2019re familiar with the underlying math for variational inference, going through the code base here will also teach you the mapping from math to TensorFlow.", 
            "title": "Getting Started with TensorFlow"
        }, 
        {
            "location": "/wishlist/", 
            "text": "Feature Wishlist\n\n\nModeling\n\n\n\n\nA graphical modeling language\n\n\n\n\nInference\n\n\n\n\nVariational inference\n\n\nCoordinate ascent variational inference\n\n\nExpectation propagation\n\n\nGenerative adversarial networks\n\n\n\n\n\n\nBayesian risk minimization\n\n\nMonte Carlo\n\n\nMarkov chain Monte Carlo\n\n\nImportance sampling\n\n\nSequential Monte Carlo\n\n\n\n\n\n\n\n\nCriticism\n\n\n\n\nGraphical checks\n\n\nSensitivity analysis\n\n\nConvergence diagnostics\n\n\n\n\nMiscellaneous\n\n\n\n\nVisualization tools\n\n\nA model zoo\n\n\n\n\nAdvanced features\n\n\n\n\nVariance reduction techniques\n\n\nControl variates\n\n\nMarkov blankets\n\n\nLocal expectation gradients\n\n\n\n\n\n\nMulticanonical variational inference\n\n\nVariational models\n\n\nHierarchical variational models\n\n\nMixture of mean-field\n\n\nStructured factorizations\n\n\nNormalizing flows\n\n\nVariational Gaussian process\n\n\nMarkov chains\n\n\n\n\n\n\nPopulation variational inference\n\n\nAccelerated variational inference", 
            "title": "Feature Wishlist"
        }, 
        {
            "location": "/wishlist/#feature-wishlist", 
            "text": "Modeling   A graphical modeling language   Inference   Variational inference  Coordinate ascent variational inference  Expectation propagation  Generative adversarial networks    Bayesian risk minimization  Monte Carlo  Markov chain Monte Carlo  Importance sampling  Sequential Monte Carlo     Criticism   Graphical checks  Sensitivity analysis  Convergence diagnostics   Miscellaneous   Visualization tools  A model zoo", 
            "title": "Feature Wishlist"
        }, 
        {
            "location": "/wishlist/#advanced-features", 
            "text": "Variance reduction techniques  Control variates  Markov blankets  Local expectation gradients    Multicanonical variational inference  Variational models  Hierarchical variational models  Mixture of mean-field  Structured factorizations  Normalizing flows  Variational Gaussian process  Markov chains    Population variational inference  Accelerated variational inference", 
            "title": "Advanced features"
        }, 
        {
            "location": "/misc/", 
            "text": "Advanced features\n\n\nHere is a list of advanced features currently supported.\n\n\n\n\nScore function gradient\n\n\nReparameterization gradient\n\n\nVariance reduction techniques\n\n\nAnalytic KL's and entropy decompositions\n\n\n\n\n\n\nVariational models\n\n\nMean-field\n\n\nGlobal parameterizations (inference networks, recognition networks, inverse mappings)\n\n\n\n\n\n\n\n\nReferences\n\n\nReferences for the process\n\n\n\n\nBox, G. E. P. (1976). Science and Statistics. Journal of the American Statistical Association, 71(356), 791\u2013799. [\nlink\n]\n\n\nBlei, D. M. (2014). Build, compute, critique, repeat: Data analysis with latent variable models. Annual Review of Statistics and Its Application. [\nlink\n]\n\n\nGelman, A., \n Shalizi, C. R. (2012). Philosophy and the practice of Bayesian statistics. British Journal of Mathematical and Statistical Psychology, 66(1), 8\u201338. [\nlink\n]\n\n\n\n\nReferences for modeling languages\n\n\n\n\nCarpenter, B., Gelman A., Hoffman, M., Lee, D., Goodrich, B., Betancourt, M., Brubaker, M. A., Guo, J., Li, P., \n Riddell, A. (2016). Stan: A probabilistic programming language. Journal of Statistical Software. [\nlink\n]\n\n\nAbadi, M., Agarwal, A., Barham, P., Brevdo, E., \n Chen, Z. (2015). TensorFlow: Large-scale machine learning on heterogeneous systems. Technical Report. [\nlink\n]\n\n\nvan der Walt, S., Colbert, S. C., \n Varoquaux, G. (2011). The NumPy Array: A Structure for Efficient Numerical Computation, Computing in Science \n Engineering, 13, 22-30. [\nlink\n]\n\n\n\n\nReferences for inference\n\n\n\n\nHoffman, M. D., Blei, D. M., Wang, C., \n Paisley, J. (2013). Stochastic Variational Inference. Journal of Machine Learning Research, 14, 1303\u20131347. [\nlink\n]\n\n\nKingma, D. P., \n Welling, M. (2014). Auto-Encoding Variational Bayes. In International Conference on Learning Representations. [\nlink\n]\n\n\nKucukelbir, A., Tran, D., Ranganath, R., Gelman, A., \n Blei, D. M. (2016). Automatic Differentiation Variational Inference. arXiv preprint arXiv:1603.00788. [\nlink\n]\n\n\nKurihara, K., Welling, M., \n Vlassis, N. (2006). Accelerated Variational Dirichlet Process Mixtures. In Neural Information Processing Systems. [\nlink\n]\n\n\nMandt, S., Mcinerney, J., Abrol, F., Ranganath, R., \n Blei, D. M. (2014). Multicanonical Stochastic Variational Inference. In Artificial Intelligence and Statistics. [\nlink\n]\n\n\nMcinerney, J., Ranganath, R., \n Blei, D. M. (2015). The Population Posterior and Bayesian Inference on Streams. In Neural Information Processing Systems. [\nlink\n]\n\n\nRanganath, R., Gerrish, S., \n Blei, D. M. (2014). Black Box Variational Inference. In Artificial Intelligence and Statistics. [\nlink\n]\n\n\nRanganath, R., Tran, D., \n Blei, D. M. (2015). Hierarchical Variational Models. arXiv preprint arXiv:1511.02386. [\nlink\n]\n\n\nRezende, D. J., \n Mohamed, S. (2015). Variational Inference with Normalizing Flows. In International Conference on Machine Learning. [\nlink\n]\n\n\nRezende, D. J., Mohamed, S., \n Wierstra, D. (2014). Stochastic Backpropagation and Approximate Inference in Deep Generative Models. In International Conference on Machine Learning. [\nlink\n]\n\n\nSalimans, T., Kingma, D. P., \n Welling, M. (2015). Markov Chain Monte Carlo and Variational Inference: Bridging the Gap. In International Conference on Machine Learning. [\nlink\n]\n\n\nTran, D., Ranganath, R., \n Blei, D. M. (2016). Variational Gaussian Process. In International Conference on Learning Representations. [\nlink\n]\n\n\n\n\nReferences for criticism\n\n\n\n\nBox, G. E. P. (1980). Sampling and Bayes' inference in scientific modelling and robustness. Journal of the Royal Statistical Society. Series a. General, 143(4), 383\u2013430.\n\n\nGelman, A., Meng, X.-L., \n Stern, H. (1996). Posterior predictive assessment of model fitness via realized discrepancies. Statistica Sinica.", 
            "title": "Miscellaneous"
        }, 
        {
            "location": "/misc/#advanced-features", 
            "text": "Here is a list of advanced features currently supported.   Score function gradient  Reparameterization gradient  Variance reduction techniques  Analytic KL's and entropy decompositions    Variational models  Mean-field  Global parameterizations (inference networks, recognition networks, inverse mappings)", 
            "title": "Advanced features"
        }, 
        {
            "location": "/misc/#references", 
            "text": "References for the process   Box, G. E. P. (1976). Science and Statistics. Journal of the American Statistical Association, 71(356), 791\u2013799. [ link ]  Blei, D. M. (2014). Build, compute, critique, repeat: Data analysis with latent variable models. Annual Review of Statistics and Its Application. [ link ]  Gelman, A.,   Shalizi, C. R. (2012). Philosophy and the practice of Bayesian statistics. British Journal of Mathematical and Statistical Psychology, 66(1), 8\u201338. [ link ]   References for modeling languages   Carpenter, B., Gelman A., Hoffman, M., Lee, D., Goodrich, B., Betancourt, M., Brubaker, M. A., Guo, J., Li, P.,   Riddell, A. (2016). Stan: A probabilistic programming language. Journal of Statistical Software. [ link ]  Abadi, M., Agarwal, A., Barham, P., Brevdo, E.,   Chen, Z. (2015). TensorFlow: Large-scale machine learning on heterogeneous systems. Technical Report. [ link ]  van der Walt, S., Colbert, S. C.,   Varoquaux, G. (2011). The NumPy Array: A Structure for Efficient Numerical Computation, Computing in Science   Engineering, 13, 22-30. [ link ]   References for inference   Hoffman, M. D., Blei, D. M., Wang, C.,   Paisley, J. (2013). Stochastic Variational Inference. Journal of Machine Learning Research, 14, 1303\u20131347. [ link ]  Kingma, D. P.,   Welling, M. (2014). Auto-Encoding Variational Bayes. In International Conference on Learning Representations. [ link ]  Kucukelbir, A., Tran, D., Ranganath, R., Gelman, A.,   Blei, D. M. (2016). Automatic Differentiation Variational Inference. arXiv preprint arXiv:1603.00788. [ link ]  Kurihara, K., Welling, M.,   Vlassis, N. (2006). Accelerated Variational Dirichlet Process Mixtures. In Neural Information Processing Systems. [ link ]  Mandt, S., Mcinerney, J., Abrol, F., Ranganath, R.,   Blei, D. M. (2014). Multicanonical Stochastic Variational Inference. In Artificial Intelligence and Statistics. [ link ]  Mcinerney, J., Ranganath, R.,   Blei, D. M. (2015). The Population Posterior and Bayesian Inference on Streams. In Neural Information Processing Systems. [ link ]  Ranganath, R., Gerrish, S.,   Blei, D. M. (2014). Black Box Variational Inference. In Artificial Intelligence and Statistics. [ link ]  Ranganath, R., Tran, D.,   Blei, D. M. (2015). Hierarchical Variational Models. arXiv preprint arXiv:1511.02386. [ link ]  Rezende, D. J.,   Mohamed, S. (2015). Variational Inference with Normalizing Flows. In International Conference on Machine Learning. [ link ]  Rezende, D. J., Mohamed, S.,   Wierstra, D. (2014). Stochastic Backpropagation and Approximate Inference in Deep Generative Models. In International Conference on Machine Learning. [ link ]  Salimans, T., Kingma, D. P.,   Welling, M. (2015). Markov Chain Monte Carlo and Variational Inference: Bridging the Gap. In International Conference on Machine Learning. [ link ]  Tran, D., Ranganath, R.,   Blei, D. M. (2016). Variational Gaussian Process. In International Conference on Learning Representations. [ link ]   References for criticism   Box, G. E. P. (1980). Sampling and Bayes' inference in scientific modelling and robustness. Journal of the Royal Statistical Society. Series a. General, 143(4), 383\u2013430.  Gelman, A., Meng, X.-L.,   Stern, H. (1996). Posterior predictive assessment of model fitness via realized discrepancies. Statistica Sinica.", 
            "title": "References"
        }
    ]
}