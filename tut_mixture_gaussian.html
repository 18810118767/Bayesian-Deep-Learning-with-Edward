<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta content="text/html; charset=utf-8" http-equiv="Content-Type"/>
<meta content="text/css" http-equiv="Content-Style-Type"/>
<meta content="pandoc" name="generator"/>
<title>Edward – Mixture of Gaussians</title>
<!-- Mobile Specific Metas -->
<meta content="width=device-width, initial-scale=1" name="viewport">
<!-- FONT -->
<link href="https://fonts.googleapis.com/css?family=Lora:400,400i,700" rel="stylesheet">
<!-- CSS -->
<link href="css/normalize.css" rel="stylesheet">
<link href="css/skeleton.css" rel="stylesheet">
<!-- Dynamically resize logo for mobile -->
<style type="text/css">
  .logo-width {
    width: 100%;
    box-sizing: border-box;
    margin-bottom: 15%;
  }
  /* Roughly the point when website is single column */
  @media (max-width: 850px) {
    .logo-width {
      width: 50%;
      box-sizing: border-box;
      margin-bottom: 5%;
    }
  }
  </style>
<!-- KaTeX -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.6.0/katex.min.js"></script>
<link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.6.0/katex.min.css" rel="stylesheet"/>
<script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.6.0/contrib/auto-render.min.js"></script>
<!-- highlight.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.4.0/highlight.min.js"></script>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.4.0/styles/github.min.css" rel="stylesheet">
<!-- Favicon -->
<link href="icons/apple-touch-icon-57x57.png" rel="apple-touch-icon" sizes="57x57">
<link href="icons/apple-touch-icon-60x60.png" rel="apple-touch-icon" sizes="60x60">
<link href="icons/apple-touch-icon-72x72.png" rel="apple-touch-icon" sizes="72x72">
<link href="icons/apple-touch-icon-76x76.png" rel="apple-touch-icon" sizes="76x76">
<link href="icons/apple-touch-icon-114x114.png" rel="apple-touch-icon" sizes="114x114">
<link href="icons/apple-touch-icon-120x120.png" rel="apple-touch-icon" sizes="120x120">
<link href="icons/apple-touch-icon-144x144.png" rel="apple-touch-icon" sizes="144x144">
<link href="icons/apple-touch-icon-152x152.png" rel="apple-touch-icon" sizes="152x152">
<link href="icons/apple-touch-icon-180x180.png" rel="apple-touch-icon" sizes="180x180">
<link href="icons/favicon-32x32.png" rel="icon" sizes="32x32" type="image/png">
<link href="icons/android-chrome-192x192.png" rel="icon" sizes="192x192" type="image/png">
<link href="icons/favicon-96x96.png" rel="icon" sizes="96x96" type="image/png">
<link href="icons/favicon-16x16.png" rel="icon" sizes="16x16" type="image/png">
<link href="icons/manifest.json" rel="manifest">
<link color="#5bbad5" href="icons/safari-pinned-tab.svg" rel="mask-icon">
<link href="icons/favicon.ico" rel="shortcut icon">
<meta content="#da532c" name="msapplication-TileColor">
<meta content="icons/mstile-144x144.png" name="msapplication-TileImage">
<meta content="icons/browserconfig.xml" name="msapplication-config">
<meta content="#ffffff" name="theme-color">
</meta></meta></meta></meta></link></link></link></link></link></link></link></link></link></link></link></link></link></link></link></link></link></link></link></link></meta></head>
<body>
<div class="container">
<div class="row" style="margin-top: 5%">
<div class="three columns">
<h1><a href="/">Edward</a></h1>
<a href="/">
<center>
<img alt="Edward" class="logo-width" src="images/edward.png"/>
</center>
</a>
<a class="button u-full-width" href="/">Home</a>
<a class="button u-full-width" href="getting-started">Getting Started</a>
<a class="button u-full-width" href="delving-in">Delving In</a>
<a class="button u-full-width" href="tutorials">Tutorials</a>
<a class="button u-full-width" href="api/">API</a>
<a class="button u-full-width" href="#">Advanced</a>
<a class="button2 u-full-width" href="design-philosophy">Design Philosophy</a>
<a class="button2 u-full-width" href="contributing">Contributing</a>
<a class="button2 u-full-width" href="troubleshooting">Troubleshooting</a>
<a class="button2 u-full-width" href="license">License</a>
<div class="row" style="padding-bottom: 5%"> </div>
<a href="https://github.com/blei-lab/edward">
<!-- <object data="images/github-mark.svg" type="image/svg+xml"> -->
<img alt="Edward on Github" class="u-pull-right" src="images/github-mark.svg" style="padding-right:10%"/>
<!-- </object> -->
</a>
<div class="row" style="padding-bottom: 5%"> </div>
</div>
<div class="nine columns">
<h2 id="mixture-of-gaussians">Mixture of Gaussians</h2>
<p>A mixture model is a model typically used for clustering. It assigns a mixture component to each data point, and this mixture component determines the distribution that the data point is generated from. A mixture of Gaussians uses Gaussian distributions to generate this data.</p>
<p>For a set of <span class="math inline">\(N\)</span> data points, the likelihood of each observation <span class="math inline">\(\mathbf{x}_n\)</span> is <span class="math display">\[\begin{aligned}
  p(\mathbf{x}_n \mid \pi, \mu, \sigma)
  &amp;=
  \sum_{k=1}^K \pi_k \, \mathcal{N}(\mathbf{x}_n ; \mu_k, \sigma_k).\end{aligned}\]</span> The latent variable <span class="math inline">\(\pi\)</span> is a <span class="math inline">\(K\)</span>-dimensional probability vector which mixes individual Gaussian distributions, each characterized by mean <span class="math inline">\(\mu_k\)</span> and variance <span class="math inline">\(\sigma_k\)</span>.</p>
<p>Define the prior on <span class="math inline">\(\pi\in[0,1]\)</span> such that <span class="math inline">\(\sum_{k=1}^K\pi_k=1\)</span> to be <span class="math display">\[\begin{aligned}
  p(\pi)
  &amp;=
  \text{Dirichlet}(\pi \;;\; \alpha \mathbf{1}_{K}).\end{aligned}\]</span></p>
<p>Define the prior on each component <span class="math inline">\(\mathbf{\mu}_k\in\mathbb{R}^D\)</span> to be <span class="math display">\[\begin{aligned}
  p(\mathbf{\mu}_k)
  &amp;=
  \mathcal{N}(\mathbf{\mu}_k \;;\; 0, \sigma^2\mathbf{I}).\end{aligned}\]</span></p>
<p>Define the prior on each component <span class="math inline">\(\mathbf{\sigma}_k\in\mathbb{R}^D\)</span> to be <span class="math display">\[\begin{aligned}
  p(\mathbf{\sigma}_k)
  &amp;=
  \text{InvGamma}(\mathbf{\sigma}_k \;;\; a, b).\end{aligned}\]</span></p>
<p>Let’s build the model in Edward using TensorFlow. This simply requires writing down the model’s log joint density, <span class="math display">\[\begin{aligned}
  \log p(\pi) +
  \Big[ \sum_{k=1}^K \log p(\mathbf{\mu}_k) + \log
  p(\mathbf{\sigma}_k) \Big] +
  \sum_{n=1}^N \log p(\mathbf{x}_n \mid \pi, \mu, \sigma).\end{aligned}\]</span> Writing the model’s log-likelihood can be tricky: <span class="math display">\[\begin{aligned}
  \sum_{n=1}^N \log p(\mathbf{x}_n \mid \pi, \mu, \sigma)
  &amp;=
  \sum_{n=1}^N \log \sum_{k=1}^K \pi_k \, \mathcal{N}(\mathbf{x}_n ;
  \mu_k, \sigma_k).\end{aligned}\]</span> To prevent numerical instability, we’d like to work on the log-scale when calculating densities, <span class="math display">\[\begin{aligned}
  \sum_{n=1}^N \log p(\mathbf{x}_n \mid \pi, \mu, \sigma)
  &amp;=
  \sum_{n=1}^N \log \sum_{k=1}^K \exp\Big(
  \log \pi_k + \log \mathcal{N}(\mathbf{x}_n ; \mu_k, \sigma_k)\Big).\end{aligned}\]</span> This expression involves a log sum exp operation, which is numerically unstable as exponentiation will often lead to one value dominating the rest. Therefore we use the log-sum-exp trick, which is based on the identity <span class="math display">\[\begin{aligned}
  \mathbf{x}_{\mathrm{max}}
  &amp;=
  \arg\max \mathbf{x},
  \\
  \log \sum_i \exp(\mathbf{x}_i)
  &amp;=
  \log \Big(\exp(\mathbf{x}_{\mathrm{max}}) \sum_i \exp(\mathbf{x}_i -
  \mathbf{x}_{\mathrm{max}})\Big)
  \\
  &amp;=
  \mathbf{x}_{\mathrm{max}} + \log \sum_i \exp(\mathbf{x}_i -
  \mathbf{x}_{\mathrm{max}}).\end{aligned}\]</span> Subtracting the maximum value before taking the log-sum-exp leads to more numerically stable output.</p>
<pre class="python" language="Python"><code>class MixtureGaussian:
  """
  Mixture of Gaussians

  p(x, z) = [ prod_{n=1}^N sum_{k=1}^K pi_k N(x_n; mu_k, sigma_k) ]
        [ prod_{k=1}^K N(mu_k; 0, cI) Inv-Gamma(sigma_k; a, b) ]
        Dirichlet(pi; alpha)

  where z = {pi, mu, sigma} and for known hyperparameters a, b, c, alpha.

  Parameters
  ----------
  K : int
    Number of mixture components.
  D : float, optional
    Dimension of the Gaussians.
  """
  def __init__(self, K, D):
    self.K = K
    self.D = D
    self.n_vars = (2 * D + 1) * K

    self.a = 1
    self.b = 1
    self.c = 10
    self.alpha = tf.ones([K])

  def log_prob(self, xs, zs):
    """Return a vector [log p(xs, zs[1,:]), ..., log p(xs, zs[S,:])]."""
    x = xs['x']
    pi, mus, sigmas = zs['pi'], zs['mu'], zs['sigma']
    log_prior = dirichlet.logpdf(pi, self.alpha)
    log_prior += tf.reduce_sum(norm.logpdf(mus, 0, np.sqrt(self.c)), 1)
    log_prior += tf.reduce_sum(invgamma.logpdf(sigmas, self.a, self.b), 1)

    # Loop over each sample zs[s, :].
    log_lik = []
    N = get_dims(x)[0]
    n_samples = get_dims(pi)[0]
    for s in range(n_samples):
      # log-likelihood is
      # sum_{n=1}^N log sum_{k=1}^K exp( log pi_k + log N(x_n; mu_k, sigma_k) )
      # Create a K x N matrix, whose entry (k, n) is
      # log pi_k + log N(x_n; mu_k, sigma_k).
      matrix = []
      for k in range(self.K):
        matrix += [tf.ones(N) * tf.log(pi[s, k]) +
                   multivariate_normal.logpdf(x,
                   mus[s, (k * self.D):((k + 1) * self.D)],
                   sigmas[s, (k * self.D):((k + 1) * self.D)])]

      matrix = tf.pack(matrix)
      # log_sum_exp() along the rows is a vector, whose nth
      # element is the log-likelihood of data point x_n.
      vector = log_sum_exp(matrix, 0)
      # Sum over data points to get the full log-likelihood.
      log_lik_z = tf.reduce_sum(vector)
      log_lik += [log_lik_z]

    return log_prior + tf.pack(log_lik)


model = MixtureGaussian(K=2, D=2)</code></pre>
<p>We experiment with this model using variational inference in the <a href="tut_unsupervised">unsupervised learning</a> tutorial. Example scripts using this model can found <a href="https://github.com/blei-lab/edward/blob/master/examples/mixture_gaussian_map.py">here with MAP estimation</a> and <a href="https://github.com/blei-lab/edward/blob/master/examples/mixture_gaussian_laplace.py">here with the Laplace approximation</a>.</p>
<h3 id="references">References</h3>
<ul>
<li>Bishop, C. (2007). Pattern Recognition and Machine Learning. Springer.</li>
</ul>
</div>
</div>
<div class="row" style="padding-bottom: 25%"> </div>
</div>
<script>
  hljs.initHighlightingOnLoad();
  renderMathInElement(document.body);
</script>
</body>
</html>
