<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta content="text/html; charset=utf-8" http-equiv="Content-Type"/>
<meta content="text/css" http-equiv="Content-Style-Type"/>
<meta content="pandoc" name="generator"/>
<title>Edward – Design Philosophy</title>
<!-- Mobile Specific Metas -->
<meta content="width=device-width, initial-scale=1" name="viewport">
<!-- FONT -->
<link href="https://fonts.googleapis.com/css?family=Lora:400,400i,700" rel="stylesheet">
<!-- CSS -->
<link href="/css/normalize.css" rel="stylesheet">
<link href="/css/skeleton.css" rel="stylesheet">
<!-- Dynamically resize logo for mobile -->
<style type="text/css">
  .logo-width {
    width: 100%;
    box-sizing: border-box;
    margin-bottom: 15%;
  }
  /* Roughly the point when website is single column */
  @media (max-width: 850px) {
    .logo-width {
      width: 50%;
      box-sizing: border-box;
      margin-bottom: 5%;
    }
  }
  </style>
<!-- KaTeX -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.6.0/katex.min.js"></script>
<link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.6.0/katex.min.css" rel="stylesheet"/>
<script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.6.0/contrib/auto-render.min.js"></script>
<!-- highlight.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.4.0/highlight.min.js"></script>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.4.0/styles/github.min.css" rel="stylesheet">
<!-- Favicon -->
<link href="/icons/apple-touch-icon-57x57.png" rel="apple-touch-icon" sizes="57x57">
<link href="/icons/apple-touch-icon-60x60.png" rel="apple-touch-icon" sizes="60x60">
<link href="/icons/apple-touch-icon-72x72.png" rel="apple-touch-icon" sizes="72x72">
<link href="/icons/apple-touch-icon-76x76.png" rel="apple-touch-icon" sizes="76x76">
<link href="/icons/apple-touch-icon-114x114.png" rel="apple-touch-icon" sizes="114x114">
<link href="/icons/apple-touch-icon-120x120.png" rel="apple-touch-icon" sizes="120x120">
<link href="/icons/apple-touch-icon-144x144.png" rel="apple-touch-icon" sizes="144x144">
<link href="/icons/apple-touch-icon-152x152.png" rel="apple-touch-icon" sizes="152x152">
<link href="/icons/apple-touch-icon-180x180.png" rel="apple-touch-icon" sizes="180x180">
<link href="/icons/favicon-32x32.png" rel="icon" sizes="32x32" type="image/png">
<link href="/icons/android-chrome-192x192.png" rel="icon" sizes="192x192" type="image/png">
<link href="/icons/favicon-96x96.png" rel="icon" sizes="96x96" type="image/png">
<link href="/icons/favicon-16x16.png" rel="icon" sizes="16x16" type="image/png">
<link href="/icons/manifest.json" rel="manifest">
<link color="#5bbad5" href="/icons/safari-pinned-tab.svg" rel="mask-icon">
<link href="/icons/favicon.ico" rel="shortcut icon">
<meta content="#da532c" name="msapplication-TileColor">
<meta content="/icons/mstile-144x144.png" name="msapplication-TileImage">
<meta content="/icons/browserconfig.xml" name="msapplication-config">
<meta content="#ffffff" name="theme-color">
</meta></meta></meta></meta></link></link></link></link></link></link></link></link></link></link></link></link></link></link></link></link></link></link></link></link></meta></head>
<body>
<div class="container">
<div class="row" style="margin-top: 5%">
<div class="three columns">
<h1><a href="/">Edward</a></h1>
<a href="/">
<center>
<img alt="Edward" class="logo-width" src="/images/edward.png"/>
</center>
</a>
<a class="button u-full-width" href="/">Home</a>
<a class="button u-full-width" href="/getting-started">Getting Started</a>
<a class="button u-full-width" href="/tutorials/">Tutorials</a>
<a class="button u-full-width" href="/api/">API</a>
<a class="button u-full-width" href="#">Advanced</a>
<a class="button2 u-full-width" href="/design-philosophy">Design Philosophy</a>
<a class="button2 u-full-width" href="/contributing">Contributing</a>
<a class="button2 u-full-width" href="/troubleshooting">Troubleshooting</a>
<a class="button2 u-full-width" href="/license">License</a>
<div class="row" style="padding-bottom: 5%"> </div>
<a href="https://github.com/blei-lab/edward">
<!-- <object data="images/github-mark.svg" type="image/svg+xml"> -->
<img alt="Edward on Github" class="u-pull-right" src="/images/github-mark.svg" style="padding-right:10%"/>
<!-- </object> -->
</a>
<div class="row" style="padding-bottom: 5%"> </div>
</div>
<div class="nine columns">
<h2 id="design-philosophy">Design Philosophy</h2>
<p><strong>Edward</strong> serves two purposes:</p>
<ol>
<li>to serve as a foundation for research;</li>
<li>to serve as a unified library for modeling, inference, and criticism.</li>
</ol>
<p>As a research tool, the code base provides a testbed for fast experimentation. For example, to evaluate new inference algorithms, the experiments only need to be written once and we can simply swap the inference with the newly proposed algorithm. This idea applies to all components of probabilistic modeling: we can leverage the built-in inference algorithms to develop new complex models, or use the built-in models and inference to develop new criticism techniques.</p>
<p>As an applied tool, Edward supports a wide variety of settings, ranging from classical hierarchical models on small data sets to complex deep probabilistic models on large data sets. With <a href="https://www.tensorflow.org">TensorFlow</a> as a backend, Edward can leverage features such as computational graphs, distributed training, and CPU/GPU integration to deploy probabilistic modeling at scale.</p>
<h2 id="related-software">Related Software</h2>
<p>There are several notable themes in Edward.</p>
<p><strong>Probabilistic programming.</strong> There has been much work on programming languages which specify broad classes of probabilistic models, or probabilistic programs. Recent works include <a href="http://projects.csail.mit.edu/church/wiki/Church">Church</a> <span class="citation">(Goodman, Mansinghka, Roy, Bonawitz, &amp; Tenenbaum, 2012)</span>, <a href="http://probcomp.csail.mit.edu/venture/">Venture</a> <span class="citation">(Mansinghka, Selsam, &amp; Perov, 2014)</span>, <a href="http://www.robots.ox.ac.uk/~fwood/anglican/literature/index.html">Anglican</a> <span class="citation">(Wood, Meent, &amp; Mansinghka, 2014)</span>, <a href="http://mc-stan.org">Stan</a> <span class="citation">(Carpenter et al., 2016)</span>, and <a href="http://webppl.org">WebPPL</a> <span class="citation">(Goodman &amp; Stuhlmüller, 2014)</span>. The most important distinction in Edward comes from our motivation. We are interested in deploying probabilistic models to a myriad of real world applications, ranging from the size of data and data structure, such as large text corpora or many brief audio signals, to the size of model and class of models, such as small nonparametric models or deep generative models. Thus Edward is built with efficient (and possibly distributed) training in mind, beyond the setting where all computing is on CPUs or where data must fit in memory.</p>
<p><strong>Black box inference.</strong> Black box algorithms are typically based on Monte Carlo methods, and by design make very few assumptions about the model <span class="citation">(Hastings, 1970; Metropolis &amp; Ulam, 1949)</span>. Our motivation as outlined above presents a new set of challenges in both inference research and their software design. As one consequence, we focus on variational inference <span class="citation">(Hinton &amp; Van Camp, 1993; Jordan, Ghahramani, Jaakkola, &amp; Saul, 1999; Waterhouse, MacKay, &amp; Robinson, 1996)</span>. As a second consequence, we encourage active research on inference by providing a class hierarchy of inference algorithms. As a third consequence, our inference algorithms aim to take advantage of as much structure as possible from the model. Edward supports all types of inference, whether they be black box or model specific <span class="citation">(Dempster, Laird, &amp; Rubin, 1977; Hoffman, Blei, Wang, &amp; Paisley, 2013)</span>.</p>
<p><strong>Computational frameworks.</strong> There are many computational frameworks, primarily built for deep learning: as of this date, this includes <a href="https://www.tensorflow.org">TensorFlow</a>, <a href="http://deeplearning.net/software/theano/">Theano</a>, <a href="http://torch.ch">Torch</a>, <a href="https://github.com/NervanaSystems/neon">neon</a>, <a href="http://rll.berkeley.edu/cgt/">Computational Graph Toolkit</a>, and <a href="https://github.com/stan-dev/math">Stan Math Library</a>. These are incredible tools which Edward employs as a backend. In terms of abstraction, Edward sits one level higher.</p>
<p><strong>High-level deep learning libraries.</strong> Neural network libraries such as <a href="https://github.com/fchollet/keras">Keras</a> and <a href="https://github.com/Lasagne/Lasagne">Lasagne</a> are at a similar abstraction level as us, but they are primarily interested in parameterizing complicated functions for supervised learning on large datasets. We are interested in probabilistic models which apply to a wide array of learning tasks, and which can have both complicated likelihood and complicated priors (neural networks are an option but not a necessity). Therefore our goals are orthogonal and in fact mutually benefit each other. For example, we use Keras’ abstraction as a way to easily specify models parameterized by deep neural networks.</p>
<h3 class="unnumbered" id="references">References</h3>
<div class="references" id="refs">
<div id="ref-carpenter2016stan">
<p>Carpenter, B., Gelman, A., Hoffman, M. D., Lee, D., Goodrich, B., Betancourt, M., … Riddell, A. (2016). Stan: A probabilistic programming language. <em>Journal of Statistical Software</em>.</p>
</div>
<div id="ref-dempster1977maximum">
<p>Dempster, A. P., Laird, N. M., &amp; Rubin, D. B. (1977). Maximum likelihood from incomplete data via the em algorithm. <em>Journal of the Royal Statistical Society. Series B (Methodological)</em>, 1–38.</p>
</div>
<div id="ref-goodman2014design">
<p>Goodman, N., &amp; Stuhlmüller, A. (2014). The design and implementation of probabilistic programming languages. <a class="uri" href="http://dippl.org">http://dippl.org</a>.</p>
</div>
<div id="ref-goodman2012church">
<p>Goodman, N., Mansinghka, V., Roy, D. M., Bonawitz, K., &amp; Tenenbaum, J. B. (2012). Church: a language for generative models. In <em>Uncertainty in artificial intelligence</em>.</p>
</div>
<div id="ref-hastings1970monte">
<p>Hastings, W. K. (1970). Monte carlo sampling methods using markov chains and their applications. <em>Biometrika</em>, <em>57</em>(1), 97–109.</p>
</div>
<div id="ref-hinton1993keeping">
<p>Hinton, G. E., &amp; Van Camp, D. (1993). Keeping the neural networks simple by minimizing the description length of the weights. In <em>Proceedings of the sixth annual conference on computational learning theory</em> (pp. 5–13). ACM.</p>
</div>
<div id="ref-hoffman2013stochastic">
<p>Hoffman, M. D., Blei, D. M., Wang, C., &amp; Paisley, J. (2013). Stochastic variational inference. <em>The Journal of Machine Learning Research</em>, <em>14</em>(1), 1303–1347.</p>
</div>
<div id="ref-jordan1999introduction">
<p>Jordan, M. I., Ghahramani, Z., Jaakkola, T. S., &amp; Saul, L. K. (1999). An introduction to variational methods for graphical models. <em>Machine Learning</em>, <em>37</em>(2), 183–233.</p>
</div>
<div id="ref-mansinghka2014venture">
<p>Mansinghka, V., Selsam, D., &amp; Perov, Y. (2014). Venture: A higher-order probabilistic programming platform with programmable inference. <em>ArXiv.org</em>.</p>
</div>
<div id="ref-metropolis1949monte">
<p>Metropolis, N., &amp; Ulam, S. (1949). The Monte Carlo method. <em>Journal of the American Statistical Association</em>, <em>44</em>(247), 335–341.</p>
</div>
<div id="ref-waterhouse1996bayesian">
<p>Waterhouse, S., MacKay, D., &amp; Robinson, T. (1996). Bayesian methods for mixtures of experts. <em>Advances in Neural Information Processing Systems</em>, 351–357.</p>
</div>
<div id="ref-wood2014new">
<p>Wood, F., Meent, J. W. van de, &amp; Mansinghka, V. (2014). A new approach to probabilistic programming inference. In <em>Artificial intelligence and statistics</em>.</p>
</div>
</div>
</div>
</div>
<div class="row" style="padding-bottom: 25%"> </div>
</div>
<script>
  hljs.initHighlightingOnLoad();
  renderMathInElement(document.body);
</script>
</body>
</html>
