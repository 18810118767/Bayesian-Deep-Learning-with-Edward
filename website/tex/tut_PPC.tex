% Define the subtitle of the page
\title{Posterior predictive checks}

% Begin the content of the page
\subsection{Posterior predictive checks}

Posterior predictive checks (PPCs; Rubin, 1984; Gelman et al., 1996)
analyze the degree to which data generated from the model deviate from
data generated from the true distribution. They can be used either
numerically to quantify this degree, or graphically to analyze this
degree qualitatively.
PPCs can be thought of as a probabilistic version of point-based
evaluations.

PPCs focus on the posterior predictive distribution
\begin{align*}
  p(x_\text{new} \mid x)
  &=
  \int
  p(x_\text{new} \mid z)
  p(z \mid x)
  \text{d} z.
\end{align*}
The model's posterior predictive can be used to generate new data
given past observations and can also make predictions on new data
given past observations.
It is formed by calculating the likelihood of the new data, averaged
over every possible set of latent variables according to the posterior
distribution.

The simplest PPC works by applying a test statistic on new data
generated from the posterior predictive, such as
$T(x_\text{new}) = \max(x_\text{new})$.  Applying $T(x_\text{new})$ to
new data over many data replications induces a distribution. We compare
this distribution to the test statistic on the real data $T(x)$.

\includegraphics{images/ppc.png}

In the figure, $T(x)$ falls in a low probability region of this
reference distribution. This indicates that the model fits the data
poorly according to this check; this suggests an area of improvement
for the model.

More generally, the test statistic can also be a function of the
model's latent variables $T(x, z)$, known as a discrepancy function.

\subsubsection{Implementation}

Edward implements PPCs through the \texttt{sample_likelihood()}
function in the probability model. This method samples a dataset from the
model likelihood
\begin{lstlisting}[language=Python]
class BetaBernoulli:
    def __init__(self):
        self.num_vars = 1

    def log_prob(self, xs, zs):
        log_prior = beta.logpdf(zs, a=1.0, b=1.0)
        log_lik = tf.pack([tf.reduce_sum(bernoulli.logpmf(xs['x'], z))
                           for z in tf.unpack(zs)])
        return log_lik + log_prior

    def sample_likelihood(self, zs, size):
    """x | z ~ p(x | z)"""
        out = []
        for s in range(zs.shape[0]):
            out += [{'x': bernoulli.rvs(zs[s, :], size=size).reshape((size,))}]
        return out
\end{lstlisting}

The \texttt{ed.ppc()} method then provides a scaffold for studying
various discrepancy functions by repeatedly simulating datasets from the
posterior predictive distribution
\begin{lstlisting}[language=Python]
T = lambda y, z=None: tf.reduce_mean(y['x'])
print(ed.ppc(model, variational, data, T))
\end{lstlisting}

See the \href{api/index.html}{API} for further implementation details.

PPCs are an excellent tool for revising models, simplifying or
expanding the current model as one examines how well it fits the data.
They are inspired by classical hypothesis testing (Meng, 1994),
under the philosophy that models should be criticized under the
frequentist perspective of large samples.

PPCs can also be applied for other tasks such as hypothesis testing,
model comparison, model selection, and model averaging.  It's
important to note that while they can be applied as a form of Bayesian
hypothesis testing, hypothesis testing is generally not recommended,
as binary decision making from a single test is not as common a use
case as one might believe.

\subsubsection{References}\label{references}

\begin{itemize}
\item
  Box, G.E.P. (1980). Sampling and Bayes' inference in scientific modelling and
  robustness. Journal of the Royal Statistical Society. Series A. 143(4), 383–430.
\item
  Gelman, A., Meng, X.-L., \& Stern, H. (1996). Posterior predictive assessment
  of model fitness via realized discrepancies. Statistica Sinica.
\item
  Meng, X.-L. (1994). Posterior predictive $p$-values. The Annals of
  Statistics, 1–19.
\item
  Rubin, D. B. (1984). Bayesianly justifiable and relevant frequency
  calculations for the applied statistician. The Annals of Statistics,
  12(4), 1151–1172.
\end{itemize}
