<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <title>Edward – Latent space models for neural data</title>
  <!-- Mobile Specific Metas -->
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- FONT -->
  <link href="https://fonts.googleapis.com/css?family=Lora:400,400i,700" rel="stylesheet">
    
  <!-- CSS -->
  <link rel="stylesheet" href="css/normalize.css">
  <link rel="stylesheet" href="css/skeleton.css">

  <!-- KaTeX -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.6.0/katex.min.js"></script>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.6.0/katex.min.css" />
  <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.6.0/contrib/auto-render.min.js"></script>

  <!-- highlight.js -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.4.0/highlight.min.js"></script>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.4.0/styles/github.min.css">

  <!-- Favicon -->
  <link rel="apple-touch-icon" sizes="57x57" href="icons/apple-touch-icon-57x57.png">
  <link rel="apple-touch-icon" sizes="60x60" href="icons/apple-touch-icon-60x60.png">
  <link rel="apple-touch-icon" sizes="72x72" href="icons/apple-touch-icon-72x72.png">
  <link rel="apple-touch-icon" sizes="76x76" href="icons/apple-touch-icon-76x76.png">
  <link rel="apple-touch-icon" sizes="114x114" href="icons/apple-touch-icon-114x114.png">
  <link rel="apple-touch-icon" sizes="120x120" href="icons/apple-touch-icon-120x120.png">
  <link rel="apple-touch-icon" sizes="144x144" href="icons/apple-touch-icon-144x144.png">
  <link rel="apple-touch-icon" sizes="152x152" href="icons/apple-touch-icon-152x152.png">
  <link rel="apple-touch-icon" sizes="180x180" href="icons/apple-touch-icon-180x180.png">
  <link rel="icon" type="image/png" href="icons/favicon-32x32.png" sizes="32x32">
  <link rel="icon" type="image/png" href="icons/android-chrome-192x192.png" sizes="192x192">
  <link rel="icon" type="image/png" href="icons/favicon-96x96.png" sizes="96x96">
  <link rel="icon" type="image/png" href="icons/favicon-16x16.png" sizes="16x16">
  <link rel="manifest" href="icons/manifest.json">
  <link rel="mask-icon" href="icons/safari-pinned-tab.svg" color="#5bbad5">
  <link rel="shortcut icon" href="icons/favicon.ico">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="msapplication-TileImage" content="icons/mstile-144x144.png">
  <meta name="msapplication-config" content="icons/browserconfig.xml">
  <meta name="theme-color" content="#ffffff">
</head>
<body>
<div class="container">
  <div class="row" style="margin-top: 5%">
    <div class="three columns">
    <h1><a href="index.html">Edward</a></h1> 
    <a href="index.html">
    <img src="images/edward.png" class="u-full-width" style="margin-bottom:15%" alt="Edward" />
    </a>
    <a class="button u-full-width" href="index.html">Home</a>
    <a class="button u-full-width" href="getting-started.html">Getting Started</a> 
    <a class="button u-full-width" href="delving-in.html">Delving In</a> 
    <a class="button u-full-width" href="tutorials.html">Tutorials</a> 
    <a class="button u-full-width" href="api/index.html">API</a> 
    <a class="button u-full-width" href="#">Advanced</a> 
    <a class="button2 u-full-width" href="design-philosophy.html">Design Philosophy</a> 
    <a class="button2 u-full-width" href="developer-process.html">Developer Process</a> 
    <a class="button2 u-full-width" href="troubleshooting.html">Troubleshooting</a> 
    <a class="button2 u-full-width" href="license.html">License</a> 
    <div class="row" style="padding-bottom: 5%"> </div>
    <a href="https://github.com/blei-lab/edward">
    <!-- <object data="images/github-mark.svg" type="image/svg+xml"> -->
      <img src="images/github-mark.svg" class="u-pull-right" style="padding-right:10%"
    alt="Edward on Github" />
    <!-- </object> -->
    </a>
    <div class="row" style="padding-bottom: 5%"> </div>
    </div>
    <div class="nine columns">
<h2 id="latent-space-models-for-neural-data">Latent space models for neural data</h2>
<p>Many interesting data sets are networks. For example, social networks or biological neural networks.</p>
<p>Often the question arises what we can learn about the nodes of the network from the connectivity patterns. This question can be addressed by fitting a latent space model (Hoff et al., 2002). Latent space models are latent variable models which embed the nodes of the network in a latent space which captures attributes of the nodes. The likelihood to form an edge between two nodes depends on their distance in the latent space.</p>
<p>We demonstrate how to do this in Edward with an example from neuroscience. The script can be found <a href="https://github.com/blei-lab/edward/blob/master/examples/latent_space_model.py">here</a>.</p>
<h3 id="data">Data</h3>
<p>The data comes from <a href="http://www-personal.umich.edu/~mejn/netdata/">Mark Newman’s repository</a>. It is a weighted, directed network representing the neural network of the nematode <a href="https://en.wikipedia.org/wiki/Caenorhabditis_elegans">C. Elegans</a> compiled by Watts and Strogatz (1998) from original experimental data by White et al. (1986).</p>
<p>The neural network consists of around <span class="math inline">\(300\)</span> neurons. Each connection is associated with a weight (positive integer) capturing the strength of the connection.</p>
<p>In the example we load the data with</p>
<pre class="python" language="Python"><code>data, N = load_celegans_brain()</code></pre>
<h3 id="model">Model</h3>
<p>Here we will fit a latent space model to the C.Elegans neural network. What can we learn about the neurons from how they are connected? We will learn a latent embedding for each neuron to capture the similarities between them.</p>
<p>Each neuron <span class="math inline">\(n\)</span> is a node in the network and is associated with a latent <span class="math inline">\(K\)</span>-dimensional vector <span class="math inline">\(z_n\)</span>.</p>
<p>We place a Gaussian prior on each of the latent vectors. In Hoff et al. (2002), the log-odds of an edge between node <span class="math inline">\(i\)</span> and <span class="math inline">\(j\)</span> is proportional to the Euclidean distance between the latent representations of the nodes <span class="math inline">\(|z_i- z_j|\)</span>. Here, we model the weights (<span class="math inline">\(Y_{ij}\)</span>) of the edges with a Poisson likelihood. The rate is the reciprocal of the distance in latent space. This is the generative process:</p>
<p>For each node <span class="math inline">\(n\)</span>: <span class="math display">\[\begin{aligned}
z_n \sim N(0,I).\end{aligned}\]</span> For each edge <span class="math inline">\((i,j)\)</span>: <span class="math display">\[\begin{aligned}
Y_{ij} \sim \text{Poisson}\Bigg(\frac{1}{|z_i - z_j|}\Bigg).\end{aligned}\]</span></p>
<p>Here we build the model in Edward using TensorFlow.</p>
<pre class="python" language="Python"><code>class LatentSpaceModel:
    def __init__(self, N, K):
        self.n_vars = N * K
        self.N = N
        self.K = K

    def log_prob(self, xs, zs):
        &quot;&quot;&quot;Return a vector [log p(xs, zs[1,:]), ..., log p(xs, zs[S,:])].&quot;&quot;&quot;
        log_prior = - tf.reduce_sum(zs*zs)
        z = tf.reshape(zs, [self.N,self.K])
        # compute reciprocal of euclidean distance
        xp = tf.matmul(tf.ones([1,self.N]), tf.reduce_sum(z*z,1,keep_dims=True))
        xp = xp + tf.transpose(xp) - 2*tf.matmul(z, z, transpose_b = True)
        xp = 1.0/xp
        log_lik = tf.reduce_sum(poisson.logpmf(xs,xp))
        return log_lik + log_prior

K = 3
model = LatentSpaceModel(N, K)</code></pre>
<h3 id="inference">Inference</h3>
<p>Maximum a posteriori (MAP) estimation is simple in Edward. Two lines are required: Instantiating inference and running it.</p>
<pre class="python" language="Python"><code>inference = ed.MAP(model, data)
inference.run(n_iter=5000, n_print=500)</code></pre>
<p>See this extended tutorial about <a href="tut_MAP.html">MAP estimation in Edward</a>.</p>
<p>One could instead run variational inference. This requires specifying a variational model and instantiating <code>MFVI</code>.</p>
<pre class="python" language="Python"><code>variational = Variational()
variational.add(Normal(model.n_vars))
inference = ed.MFVI(model, variational, data)</code></pre>
<p>Finally, the following line runs the inference procedure:</p>
<pre class="python" language="Python"><code>inference.run(n_iter=5000, n_print=500)</code></pre>
<p>See this extended tutorial about <a href="tut_variational_inference.html">variational inference in Edward</a>.</p>
<h3 id="references">References</h3>
<p>Hoff, P. D., Raftery, A. E., and Handcock, M. S. (2002). Latent space approaches to social network analysis. , 97(460):1090–1098.</p>
<p>Watts, D. J. and Strogatz, S. H. (1998). Collective dynamics of ‘</p>
<p>White, J. G., Southgate, E., Thomson, J. N., and Brenner, S. (1986). The structure of the nervous system of the nematode caenorhabditis elegans. , 314(1165):1–340.</p>
    </div>
  </div>
  <div class="row" style="padding-bottom: 25%"> </div>
</div>
<script>
  hljs.initHighlightingOnLoad();
  renderMathInElement(document.body);
</script> 
</body>
</html>
