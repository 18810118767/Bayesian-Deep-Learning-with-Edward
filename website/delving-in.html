<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta content="text/html; charset=utf-8" http-equiv="Content-Type"/>
<meta content="text/css" http-equiv="Content-Style-Type"/>
<meta content="pandoc" name="generator"/>
<title>Edward – Delving In</title>
<!-- Mobile Specific Metas -->
<meta content="width=device-width, initial-scale=1" name="viewport">
<!-- FONT -->
<link href="https://fonts.googleapis.com/css?family=Lora:400,400i,700" rel="stylesheet">
<!-- CSS -->
<link href="css/normalize.css" rel="stylesheet">
<link href="css/skeleton.css" rel="stylesheet">
<!-- KaTeX -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.6.0/katex.min.js"></script>
<link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.6.0/katex.min.css" rel="stylesheet"/>
<script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.6.0/contrib/auto-render.min.js"></script>
<!-- highlight.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.4.0/highlight.min.js"></script>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.4.0/styles/github.min.css" rel="stylesheet">
<!-- Favicon -->
<link href="icons/apple-touch-icon-57x57.png" rel="apple-touch-icon" sizes="57x57">
<link href="icons/apple-touch-icon-60x60.png" rel="apple-touch-icon" sizes="60x60">
<link href="icons/apple-touch-icon-72x72.png" rel="apple-touch-icon" sizes="72x72">
<link href="icons/apple-touch-icon-76x76.png" rel="apple-touch-icon" sizes="76x76">
<link href="icons/apple-touch-icon-114x114.png" rel="apple-touch-icon" sizes="114x114">
<link href="icons/apple-touch-icon-120x120.png" rel="apple-touch-icon" sizes="120x120">
<link href="icons/apple-touch-icon-144x144.png" rel="apple-touch-icon" sizes="144x144">
<link href="icons/apple-touch-icon-152x152.png" rel="apple-touch-icon" sizes="152x152">
<link href="icons/apple-touch-icon-180x180.png" rel="apple-touch-icon" sizes="180x180">
<link href="icons/favicon-32x32.png" rel="icon" sizes="32x32" type="image/png">
<link href="icons/android-chrome-192x192.png" rel="icon" sizes="192x192" type="image/png">
<link href="icons/favicon-96x96.png" rel="icon" sizes="96x96" type="image/png">
<link href="icons/favicon-16x16.png" rel="icon" sizes="16x16" type="image/png">
<link href="icons/manifest.json" rel="manifest">
<link color="#5bbad5" href="icons/safari-pinned-tab.svg" rel="mask-icon">
<link href="icons/favicon.ico" rel="shortcut icon">
<meta content="#da532c" name="msapplication-TileColor">
<meta content="icons/mstile-144x144.png" name="msapplication-TileImage">
<meta content="icons/browserconfig.xml" name="msapplication-config">
<meta content="#ffffff" name="theme-color">
</meta></meta></meta></meta></link></link></link></link></link></link></link></link></link></link></link></link></link></link></link></link></link></link></link></link></meta></head>
<body>
<div class="container">
<div class="row" style="margin-top: 5%">
<div class="three columns">
<h1><a href="index.html">Edward</a></h1>
<a href="index.html">
<img alt="Edward" class="u-full-width" src="images/edward.png" style="margin-bottom:15%"/>
</a>
<a class="button u-full-width" href="index.html">Home</a>
<a class="button u-full-width" href="getting-started.html">Getting Started</a>
<a class="button u-full-width" href="delving-in.html">Delving In</a>
<a class="button u-full-width" href="tutorials.html">Tutorials</a>
<a class="button u-full-width" href="api/index.html">API</a>
<a class="button u-full-width" href="#">Advanced</a>
<a class="button2 u-full-width" href="design-philosophy.html">Design Philosophy</a>
<a class="button2 u-full-width" href="developer-process.html">Developer Process</a>
<a class="button2 u-full-width" href="troubleshooting.html">Troubleshooting</a>
<a class="button2 u-full-width" href="license.html">License</a>
<div class="row" style="padding-bottom: 5%"> </div>
<a href="https://github.com/blei-lab/edward">
<!-- <object data="images/github-mark.svg" type="image/svg+xml"> -->
<img alt="Edward on Github" class="u-pull-right" src="images/github-mark.svg" style="padding-right:10%"/>
<!-- </object> -->
</a>
<div class="row" style="padding-bottom: 5%"> </div>
</div>
<div class="nine columns">
<h2 id="delving-in">Delving In</h2>
<p>Edward’s design reflects the building blocks for probabilistic modeling. It defines interchangeable components, enabling fast experimentation and research with probabilistic models. Here we describe the design and provide an overview of its internal workings.</p>
<p>Edward is named after the innovative statistician <a href="https://en.wikipedia.org/wiki/George_E._P._Box">George Edward Pelham Box</a>. Edward follows Box’s philosophy of statistics and machine learning.</p>
<p>First gather data from a real-world phenomena. Then cycle through Box’s loop:</p>
<ol>
<li>Build a probabilistic model of the phenomena.</li>
<li>Reason about the phenomena given model and data.</li>
<li>Criticize the model, revise and repeat.</li>
</ol>
<p><img alt="image" src="images/model_infer_criticize.png"/></p>
<p>Here’s a toy example. A child flips a coin ten times, with the set of outcomes being <code>[0, 1, 0, 0, 0, 0, 0, 0, 0, 1]</code>, where <code>0</code> denotes tails and <code>1</code> denotes heads. We are interested in the probability that the coin lands heads. First, build a model: assume the coin flips are independent and land heads with the same probability. Second, reason about the phenomena: use an algorithm to infer the model given data. Third, criticize the model: analyze whether the model captures the real-world phenomena of coin flips. If it doesn’t, then revise the model and repeat.</p>
<p>This process defines the design of Edward. Four objects organize the above analysis.</p>
<h3 id="data">Data</h3>
<p>Data defines a set of observations. Edward represents data as a Python dictionary, typically comprised of strings naming a data object and NumPy arrays representing its values. For example,</p>
<pre class="python" language="Python"><code>data = {'x': np.array([0, 1, 0, 0, 0, 0, 0, 0, 0, 1])}</code></pre>
<p>Data can also have its values be TensorFlow tensors in order to deal with settings such as when the data does not fit in memory.</p>
<h3 id="models">Models</h3>
<p>A probabilistic model is a joint distribution <span class="math inline">\(p(x, z)\)</span> of data <span class="math inline">\(x\)</span> and latent variables <span class="math inline">\(z\)</span>. Edward supports several languages for specifying probability models: TensorFlow, Python, PyMC3, and Stan. In general, a probability model has the following structure.</p>
<pre class="python" language="Python"><code>class ProbabilityModel:
    def __init__(...):
        ...
        self.n_vars = ...

    def log_prob(self, xs, zs):
        log_prior = ...
        log_likelihood = ...
        return log_prior + log_likelihood

model = ProbabilityModel(...)</code></pre>
<p>The field <code>n_vars</code> denotes the number of latent variables in the probability model. For example, a model with a Gaussian likelihood with latent mean and variance would have <code>n_vars=2*N</code> latent variables for <code>N</code> observations.</p>
<p>The method <code>log_prob(xs, zs)</code> calculates the log probability of the joint density <span class="math inline">\(\log p(x,z)\)</span>. Here <code>xs</code> can be a single data point or a batch of data points, and analogously, <code>zs</code> can be a single set or multiple sets of latent variables. The method returns a vector of log density evaluations, one for each set of latent variables.</p>
<h3 id="inference">Inference</h3>
<p>Given a model and data, we aim to reason about <span class="math inline">\(z\)</span>: the model’s hidden structure conditioned on the data. The posterior distribution <span class="math inline">\(p(z \mid x)\)</span> captures our reasoning: its mean describes our best guess of the hidden structure, and its variance describes the uncertainty around our best guess.</p>
<p>Edward has a variety of built-in inference methods and makes it easy to develop new ones.</p>
<p><img alt="image" src="images/inference_structure.png"/> <span><em>Dependency graph of inference methods. Nodes are classes in Edward and arrows represent class inheritance.</em></span></p>
<p>Edward focuses on variational inference. It views posterior inference as positing a model of the latent variables <span class="math inline">\(q(z \;;\; \lambda)\)</span> and optimizing it to approximate the posterior <span class="math inline">\(p(z \mid x)\)</span>.</p>
<p>Edward provides a <code>Variational</code> class and a library of <code>Distribution</code> objects. Variational models combine these using the <code>add()</code> syntax. For example, to specify this variational model (e.g. for a Gaussian mixture) <span class="math display">\[\begin{aligned}
  q(z \;;\; \lambda)
  &amp;=
  \text{Dirichlet}(z_\pi)
  \times
  \mathcal{N}(z_\mu)
  \times
  \text{InvGamma}(z_\sigma)\end{aligned}\]</span> we would write</p>
<pre class="python" language="Python"><code>from edward.models import Variational, Dirichlet, Normal, InvGamma

variational = Variational()
variational.add(Dirichlet(K))
variational.add(Normal(K*D))
variational.add(InvGamma(K*D))</code></pre>
<p>Each algorithm derived from <code>VariationalInference</code> minimizes a different loss function between the variational model and the posterior. For example, to minimize the Kullback-Leibler divergence <span class="math display">\[\begin{aligned}
  \text{KL}(p(z \mid x) \;\|\; q(z \;;\; \lambda))\end{aligned}\]</span> we first instantiate the inference class and then run it.</p>
<pre class="python" language="Python"><code>inference = ed.KLpq(model, variational, data)
inference.run(n_iter=500, n_minibatch=5)</code></pre>
<p>This runs the <code>KLpq</code> minimization algorithm for <code>500</code> iterations, using a batch of <code>5</code> data points per iteration.</p>
<h3 id="criticism">Criticism</h3>
<p>Criticizing models and their inference is a crucial step in analysis. Following falsificationists such as Popper and Box, we can never validate whether a model is true—no model will be true in practice—but we can seek to uncover where the model goes wrong.</p>
<p>Edward provides a <code>criticisms</code> module, which supports</p>
<ul>
<li>point-based evaluations such as mean squared error or classification accuracy</li>
</ul>
<pre class="python" language="Python"><code>ed.evaluate('mean_squared_error', model, variational, data)</code></pre>
<ul>
<li>posterior predictive checks for making probabilistic assessments of the model fit using discrepancy functions</li>
</ul>
<pre class="python" language="Python"><code>T = lambda data, z=None: tf.reduce_mean(data['x'])
print(ed.ppc(model, variational, data, T))</code></pre>
<p>See the <a href="tutorials.html">tutorials</a> for examples of models, inference, and criticism in Edward.</p>
<p>See the <a href="api/index.html">API</a> for details of how Edward designs these objects.</p>
<h3 id="references">References</h3>
<ul>
<li>Box, G.E.P. (1976). Science and Statistics. Journal of the American Statistical Association, 71(356), 791–799</li>
<li>David M Blei. (2014). Build, compute, critique, repeat: Data analysis with latent variable models. Annual Review of Statistics, 1:203-232</li>
</ul>
</div>
</div>
<div class="row" style="padding-bottom: 25%"> </div>
</div>
<script>
  hljs.initHighlightingOnLoad();
  renderMathInElement(document.body);
</script>
</body>
</html>
