

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>edward package &mdash; Edward 1.0 documentation</title>
  

  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  

  

  
    <link rel="top" title="Edward 1.0 documentation" href="index.html"/>
        <link rel="next" title="edward.models package" href="edward.models.html"/>
        <link rel="prev" title="Edward" href="index.html"/> 

  
  <script src="_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="index.html" class="icon icon-home"> Edward
          

          
          </a>

          
            
            
              <div class="version">
                1.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
                <ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">edward package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#subpackages">Subpackages</a><ul>
<li class="toctree-l3"><a class="reference internal" href="edward.models.html">edward.models package</a></li>
<li class="toctree-l3"><a class="reference internal" href="edward.stats.html">edward.stats package</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-edward.criticisms">edward.criticisms module</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-edward.data">edward.data module</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-edward.inferences">edward.inferences module</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-edward.util">edward.util module</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-edward">Module contents</a></li>
</ul>
</li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="index.html">Edward</a>
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          

 



<div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="index.html">Docs</a> &raquo;</li>
      
    <li>edward package</li>
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="_sources/edward.txt" rel="nofollow"> View page source</a>
          
        
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="edward-package">
<h1>edward package<a class="headerlink" href="#edward-package" title="Permalink to this headline">¶</a></h1>
<div class="section" id="subpackages">
<h2>Subpackages<a class="headerlink" href="#subpackages" title="Permalink to this headline">¶</a></h2>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="edward.models.html">edward.models package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="edward.models.html#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="edward.models.html#module-edward.models.distributions">edward.models.distributions module</a></li>
<li class="toctree-l2"><a class="reference internal" href="edward.models.html#module-edward.models.models">edward.models.models module</a></li>
<li class="toctree-l2"><a class="reference internal" href="edward.models.html#module-edward.models">Module contents</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="edward.stats.html">edward.stats package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="edward.stats.html#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="edward.stats.html#module-edward.stats.distributions">edward.stats.distributions module</a></li>
<li class="toctree-l2"><a class="reference internal" href="edward.stats.html#module-edward.stats">Module contents</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div class="section" id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="module-edward.criticisms">
<span id="edward-criticisms-module"></span><h2>edward.criticisms module<a class="headerlink" href="#module-edward.criticisms" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="edward.criticisms.binary_accuracy">
<code class="descclassname">edward.criticisms.</code><code class="descname">binary_accuracy</code><span class="sig-paren">(</span><em>y_true</em>, <em>y_pred</em><span class="sig-paren">)</span><a class="headerlink" href="#edward.criticisms.binary_accuracy" title="Permalink to this definition">¶</a></dt>
<dd><p>Binary prediction accuracy, also known as 0/1-loss.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>y_true</strong> (<em>tf.Tensor</em>) &#8211; Tensor of 0s and 1s.</li>
<li><strong>y_pred</strong> (<em>tf.Tensor</em>) &#8211; Tensor of probabilities.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="edward.criticisms.binary_crossentropy">
<code class="descclassname">edward.criticisms.</code><code class="descname">binary_crossentropy</code><span class="sig-paren">(</span><em>y_true</em>, <em>y_pred</em><span class="sig-paren">)</span><a class="headerlink" href="#edward.criticisms.binary_crossentropy" title="Permalink to this definition">¶</a></dt>
<dd><p>Binary cross-entropy.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>y_true</strong> (<em>tf.Tensor</em>) &#8211; Tensor of 0s and 1s.</li>
<li><strong>y_pred</strong> (<em>tf.Tensor</em>) &#8211; Tensor of probabilities.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="edward.criticisms.categorical_accuracy">
<code class="descclassname">edward.criticisms.</code><code class="descname">categorical_accuracy</code><span class="sig-paren">(</span><em>y_true</em>, <em>y_pred</em><span class="sig-paren">)</span><a class="headerlink" href="#edward.criticisms.categorical_accuracy" title="Permalink to this definition">¶</a></dt>
<dd><p>Multi-class prediction accuracy. One-hot representation for <code class="docutils literal"><span class="pre">y_true</span></code>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>y_true</strong> (<em>tf.Tensor</em>) &#8211; Tensor of 0s and 1s, where the outermost dimension of size <code class="docutils literal"><span class="pre">K</span></code>
has only one 1 per row.</li>
<li><strong>y_pred</strong> (<em>tf.Tensor</em>) &#8211; Tensor of probabilities, with same shape as <code class="docutils literal"><span class="pre">y_true</span></code>.
The outermost dimension denote the categorical probabilities for
that data point per row.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="edward.criticisms.categorical_crossentropy">
<code class="descclassname">edward.criticisms.</code><code class="descname">categorical_crossentropy</code><span class="sig-paren">(</span><em>y_true</em>, <em>y_pred</em><span class="sig-paren">)</span><a class="headerlink" href="#edward.criticisms.categorical_crossentropy" title="Permalink to this definition">¶</a></dt>
<dd><p>Multi-class cross entropy. One-hot representation for <code class="docutils literal"><span class="pre">y_true</span></code>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>y_true</strong> (<em>tf.Tensor</em>) &#8211; Tensor of 0s and 1s, where the outermost dimension of size K
has only one 1 per row.</li>
<li><strong>y_pred</strong> (<em>tf.Tensor</em>) &#8211; Tensor of probabilities, with same shape as y_true.
The outermost dimension denote the categorical probabilities for
that data point per row.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="edward.criticisms.cosine_proximity">
<code class="descclassname">edward.criticisms.</code><code class="descname">cosine_proximity</code><span class="sig-paren">(</span><em>y_true</em>, <em>y_pred</em><span class="sig-paren">)</span><a class="headerlink" href="#edward.criticisms.cosine_proximity" title="Permalink to this definition">¶</a></dt>
<dd><p>Cosine similarity of two vectors.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>y_true</strong> (<em>tf.Tensor</em>) &#8211; </li>
<li><strong>y_pred</strong> (<em>tf.Tensor</em>) &#8211; Tensors of same shape and type.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="edward.criticisms.evaluate">
<code class="descclassname">edward.criticisms.</code><code class="descname">evaluate</code><span class="sig-paren">(</span><em>metrics</em>, <em>model</em>, <em>variational</em>, <em>data</em><span class="sig-paren">)</span><a class="headerlink" href="#edward.criticisms.evaluate" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluate fitted model using a set of metrics.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>metrics</strong> (<em>list or str</em>) &#8211; List of metrics or a single metric.</li>
<li><strong>model</strong> (<em>ed.Model</em>) &#8211; Probability model p(x, z)</li>
<li><strong>variational</strong> (<em>ed.Variational</em>) &#8211; Variational approximation to the posterior p(z | x)</li>
<li><strong>data</strong> (<em>ed.Data</em>) &#8211; Data to evaluate the model at</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">A list of evaluations or a single evaluation.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first">list or float</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Raises:</th><td class="field-body"><p class="first last"><code class="xref py py-exc docutils literal"><span class="pre">NotImplementedError</span></code> &#8211; If an input metric does not match an implemented metric in Edward.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="edward.criticisms.hinge">
<code class="descclassname">edward.criticisms.</code><code class="descname">hinge</code><span class="sig-paren">(</span><em>y_true</em>, <em>y_pred</em><span class="sig-paren">)</span><a class="headerlink" href="#edward.criticisms.hinge" title="Permalink to this definition">¶</a></dt>
<dd><p>Hinge loss.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>y_true</strong> (<em>tf.Tensor</em>) &#8211; Tensor of 0s and 1s.</li>
<li><strong>y_pred</strong> (<em>tf.Tensor</em>) &#8211; Tensor of real value.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="edward.criticisms.mean_absolute_error">
<code class="descclassname">edward.criticisms.</code><code class="descname">mean_absolute_error</code><span class="sig-paren">(</span><em>y_true</em>, <em>y_pred</em><span class="sig-paren">)</span><a class="headerlink" href="#edward.criticisms.mean_absolute_error" title="Permalink to this definition">¶</a></dt>
<dd><p>Mean absolute error loss.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>y_true</strong> (<em>tf.Tensor</em>) &#8211; </li>
<li><strong>y_pred</strong> (<em>tf.Tensor</em>) &#8211; Tensors of same shape and type.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="edward.criticisms.mean_absolute_percentage_error">
<code class="descclassname">edward.criticisms.</code><code class="descname">mean_absolute_percentage_error</code><span class="sig-paren">(</span><em>y_true</em>, <em>y_pred</em><span class="sig-paren">)</span><a class="headerlink" href="#edward.criticisms.mean_absolute_percentage_error" title="Permalink to this definition">¶</a></dt>
<dd><p>Mean absolute percentage error loss.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>y_true</strong> (<em>tf.Tensor</em>) &#8211; </li>
<li><strong>y_pred</strong> (<em>tf.Tensor</em>) &#8211; Tensors of same shape and type.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="edward.criticisms.mean_squared_error">
<code class="descclassname">edward.criticisms.</code><code class="descname">mean_squared_error</code><span class="sig-paren">(</span><em>y_true</em>, <em>y_pred</em><span class="sig-paren">)</span><a class="headerlink" href="#edward.criticisms.mean_squared_error" title="Permalink to this definition">¶</a></dt>
<dd><p>Mean squared error loss.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>y_true</strong> (<em>tf.Tensor</em>) &#8211; </li>
<li><strong>y_pred</strong> (<em>tf.Tensor</em>) &#8211; Tensors of same shape and type.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="edward.criticisms.mean_squared_logarithmic_error">
<code class="descclassname">edward.criticisms.</code><code class="descname">mean_squared_logarithmic_error</code><span class="sig-paren">(</span><em>y_true</em>, <em>y_pred</em><span class="sig-paren">)</span><a class="headerlink" href="#edward.criticisms.mean_squared_logarithmic_error" title="Permalink to this definition">¶</a></dt>
<dd><p>Mean squared logarithmic error loss.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>y_true</strong> (<em>tf.Tensor</em>) &#8211; </li>
<li><strong>y_pred</strong> (<em>tf.Tensor</em>) &#8211; Tensors of same shape and type.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="edward.criticisms.poisson">
<code class="descclassname">edward.criticisms.</code><code class="descname">poisson</code><span class="sig-paren">(</span><em>y_true</em>, <em>y_pred</em><span class="sig-paren">)</span><a class="headerlink" href="#edward.criticisms.poisson" title="Permalink to this definition">¶</a></dt>
<dd><p>Negative Poisson log-likelihood of data <code class="docutils literal"><span class="pre">y_true</span></code> given predictions
<code class="docutils literal"><span class="pre">y_pred</span></code> (up to proportion).</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>y_true</strong> (<em>tf.Tensor</em>) &#8211; </li>
<li><strong>y_pred</strong> (<em>tf.Tensor</em>) &#8211; Tensors of same shape and type.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="edward.criticisms.ppc">
<code class="descclassname">edward.criticisms.</code><code class="descname">ppc</code><span class="sig-paren">(</span><em>model</em>, <em>variational=None</em>, <em>data=&lt;edward.data.Data object&gt;</em>, <em>T=None</em>, <em>size=100</em><span class="sig-paren">)</span><a class="headerlink" href="#edward.criticisms.ppc" title="Permalink to this definition">¶</a></dt>
<dd><p>Posterior predictive check.
(Rubin, 1984; Meng, 1994; Gelman, Meng, and Stern, 1996)
If no posterior approximation is provided through <code class="docutils literal"><span class="pre">variational</span></code>,
then we default to a prior predictive check (Box, 1980).</p>
<p>PPC&#8217;s form an empirical distribution for the predictive discrepancy,</p>
<div class="math">
\[p(T) = \int p(T(yrep) | z) p(z | y) dz\]</div>
<p>by drawing replicated data sets yrep and calculating
<span class="math">\(T(yrep)\)</span> for each data set. Then it compares it to
<span class="math">\(T(y)\)</span>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>model</strong> (<em>ed.Model</em>) &#8211; class object that implements the <code class="docutils literal"><span class="pre">sample_likelihood</span></code> method</li>
<li><strong>variational</strong> (<em>ed.Variational, optional</em>) &#8211; latent variable distribution q(z) to sample from. It is an
approximation to the posterior, e.g., a variational
approximation or an empirical distribution from MCMC samples.
If not specified, samples will be obtained from the model
through the <code class="docutils literal"><span class="pre">sample_prior</span></code> method.</li>
<li><strong>data</strong> (<em>ed.Data, optional</em>) &#8211; Observed data to compare to. If not specified, will return
only the reference distribution with an assumed replicated
data set size of 1.</li>
<li><strong>T</strong> (<em>function, optional</em>) &#8211; Discrepancy function taking tf.Tensor inputs and returning
a tf.Tensor output. Default is the identity function.
In general this is a function taking in a data set <code class="docutils literal"><span class="pre">y</span></code>
and optionally a set of latent variables <code class="docutils literal"><span class="pre">z</span></code> as input.</li>
<li><strong>size</strong> (<em>int, optional</em>) &#8211; number of replicated data sets</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><p>List containing the reference distribution, which is a Numpy
vector of size elements,</p>
<div class="math">
\[(T(yrep^{1}, z^{1}), ..., T(yrep^{size}, z^{size}))\]</div>
<p>and the realized discrepancy, which is a NumPy vector of size
elements,</p>
<div class="math">
\[(T(y, z^{1}), ..., T(y, z^{size})).\]</div>
</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">list</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="edward.criticisms.sparse_categorical_accuracy">
<code class="descclassname">edward.criticisms.</code><code class="descname">sparse_categorical_accuracy</code><span class="sig-paren">(</span><em>y_true</em>, <em>y_pred</em><span class="sig-paren">)</span><a class="headerlink" href="#edward.criticisms.sparse_categorical_accuracy" title="Permalink to this definition">¶</a></dt>
<dd><p>Multi-class prediction accuracy. Label {0, 1, .., K-1}
representation for <code class="docutils literal"><span class="pre">y_true</span></code>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>y_true</strong> (<em>tf.Tensor</em>) &#8211; Tensor of integers {0, 1, ..., K-1}.</li>
<li><strong>y_pred</strong> (<em>tf.Tensor</em>) &#8211; Tensor of probabilities, with shape <code class="docutils literal"><span class="pre">(y_true.get_shape(),</span> <span class="pre">K)</span></code>.
The outermost dimension are the categorical probabilities for
that data point.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="edward.criticisms.sparse_categorical_crossentropy">
<code class="descclassname">edward.criticisms.</code><code class="descname">sparse_categorical_crossentropy</code><span class="sig-paren">(</span><em>y_true</em>, <em>y_pred</em><span class="sig-paren">)</span><a class="headerlink" href="#edward.criticisms.sparse_categorical_crossentropy" title="Permalink to this definition">¶</a></dt>
<dd><p>Multi-class cross entropy. Label {0, 1, .., K-1} representation
for <code class="docutils literal"><span class="pre">y_true.</span></code></p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>y_true</strong> (<em>tf.Tensor</em>) &#8211; Tensor of integers {0, 1, ..., K-1}.</li>
<li><strong>y_pred</strong> (<em>tf.Tensor</em>) &#8211; Tensor of probabilities, with shape <code class="docutils literal"><span class="pre">(y_true.get_shape(),</span> <span class="pre">K)</span></code>.
The outermost dimension are the categorical probabilities for
that data point.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="edward.criticisms.squared_hinge">
<code class="descclassname">edward.criticisms.</code><code class="descname">squared_hinge</code><span class="sig-paren">(</span><em>y_true</em>, <em>y_pred</em><span class="sig-paren">)</span><a class="headerlink" href="#edward.criticisms.squared_hinge" title="Permalink to this definition">¶</a></dt>
<dd><p>Squared hinge loss.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>y_true</strong> (<em>tf.Tensor</em>) &#8211; Tensor of 0s and 1s.</li>
<li><strong>y_pred</strong> (<em>tf.Tensor</em>) &#8211; Tensor of real value.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="module-edward.data">
<span id="edward-data-module"></span><h2>edward.data module<a class="headerlink" href="#module-edward.data" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="edward.data.Data">
<em class="property">class </em><code class="descclassname">edward.data.</code><code class="descname">Data</code><span class="sig-paren">(</span><em>data=None</em>, <em>shuffled=True</em><span class="sig-paren">)</span><a class="headerlink" href="#edward.data.Data" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">object</span></code></p>
<p>Base class for Edward data objects.</p>
<p>By default, it assumes the data is an array (or list of arrays).
If requested will perform data subsampling according to slices of
the first index (e.g., elements in a vector, rows in a matrix,
y-by-z matrices in a x-by-y-by-z tensor). Use one of the derived
classes for subsampling more complex data structures.</p>
<p>For TensorFlow models, data argument can be list of placeholders
or list of np.ndarrays. If np.ndarrays, it will use mini-batches
of the np.arrays during computation. If placeholders, user must
manually control mini-batches and feed in the placeholders.</p>
<p>Data subsampling is not currently available for Stan models.</p>
<p>Internally, <code class="docutils literal"><span class="pre">self.counter</span></code> stores the last accessed data index. It
is used to obtain the next batch of data starting from
<code class="docutils literal"><span class="pre">self.counter</span></code> to the size of the data set.</p>
<p>Initialization.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>data</strong> (<em>tf.tensor, np.ndarray, list, dict, optional</em>) &#8211; <p>Data whose type depends on the type of model it is fed into.</p>
<p>If TensorFlow, must be <code class="docutils literal"><span class="pre">tf.tensor</span></code> or <code class="docutils literal"><span class="pre">list</span></code>.</p>
<p>If Stan, must be <code class="docutils literal"><span class="pre">dict</span></code>.</p>
<p>If PyMC3, must be <code class="docutils literal"><span class="pre">np.ndarray</span></code>.</p>
<p>If NumPy/SciPy, must be <code class="docutils literal"><span class="pre">np.ndarray</span></code> or <code class="docutils literal"><span class="pre">list</span></code> of <code class="docutils literal"><span class="pre">np.ndarrays</span></code>.</p>
</li>
<li><strong>shuffled</strong> (<em>bool, optional</em>) &#8211; Whether the data is shuffled when sampling.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="edward.data.Data.sample">
<code class="descname">sample</code><span class="sig-paren">(</span><em>n_data=None</em><span class="sig-paren">)</span><a class="headerlink" href="#edward.data.Data.sample" title="Permalink to this definition">¶</a></dt>
<dd><p>Data sampling method.</p>
<p>At any given point, the internal counter <code class="docutils literal"><span class="pre">self.counter</span></code> tracks the
last datapoint returned by <code class="docutils literal"><span class="pre">sample</span></code>.</p>
<p>If the requested number of datapoints <code class="docutils literal"><span class="pre">n_data</span></code> goes beyond the size
of the dataset, the internal counter wraps around the size of the
dataset. The returned minibatch, thus, may include datapoints from the
beginning of the dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>n_data</strong> (<em>int, optional</em>) &#8211; <p>Number of datapoints to sample</p>
<p>Defaults to total number of datapoints in <code class="docutils literal"><span class="pre">Data</span></code> object.</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><strong>minibatch</strong> &#8211; a tensor with first dimension size = <code class="docutils literal"><span class="pre">n_data</span></code></td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">tf.Tensor</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-edward.inferences">
<span id="edward-inferences-module"></span><h2>edward.inferences module<a class="headerlink" href="#module-edward.inferences" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="edward.inferences.Inference">
<em class="property">class </em><code class="descclassname">edward.inferences.</code><code class="descname">Inference</code><span class="sig-paren">(</span><em>model</em>, <em>data=&lt;edward.data.Data object&gt;</em><span class="sig-paren">)</span><a class="headerlink" href="#edward.inferences.Inference" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">object</span></code></p>
<p>Base class for Edward inference methods.</p>
<p>Initialization.</p>
<p>Calls <code class="docutils literal"><span class="pre">util.get_session()</span></code></p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>model</strong> (<em>ed.Model</em>) &#8211; probability model</li>
<li><strong>data</strong> (<em>ed.Data, optional</em>) &#8211; observed data</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="class">
<dt id="edward.inferences.KLpq">
<em class="property">class </em><code class="descclassname">edward.inferences.</code><code class="descname">KLpq</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#edward.inferences.KLpq" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#edward.inferences.VariationalInference" title="edward.inferences.VariationalInference"><code class="xref py py-class docutils literal"><span class="pre">edward.inferences.VariationalInference</span></code></a></p>
<p>A variational inference method that minimizes the Kullback-Leibler
divergence from the posterior to the variational model (Cappe et al., 2008)</p>
<div class="math">
\[KL( p(z |x) || q(z) ).\]</div>
<dl class="method">
<dt id="edward.inferences.KLpq.build_loss">
<code class="descname">build_loss</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#edward.inferences.KLpq.build_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Loss function to minimize.</p>
<p>Defines a stochastic gradient of</p>
<div class="math">
\[KL( p(z |x) || q(z) )
=
E_{p(z | x)} [ \log p(z | x) - \log q(z; \lambda) ]\]</div>
<p>based on importance sampling.</p>
<p>Computed as</p>
<div class="math">
\[1/B \sum_{b=1}^B [ w_{norm}(z^b; \lambda) *
                    (\log p(x, z^b) - \log q(z^b; \lambda) ]\]</div>
<p>where</p>
<div class="math">
\[ \begin{align}\begin{aligned}z^b \sim q(z^b; \lambda)\\w_{norm}(z^b; \lambda) = w(z^b; \lambda) / \sum_{b=1}^B ( w(z^b; \lambda) )\\w(z^b; \lambda) = p(x, z^b) / q(z^b; \lambda)\end{aligned}\end{align} \]</div>
<p>which gives a gradient</p>
<div class="math">
\[- 1/B \sum_{b=1}^B
w_{norm}(z^b; \lambda) \partial_{\lambda} \log q(z^b; \lambda)\]</div>
</dd></dl>

<dl class="method">
<dt id="edward.inferences.KLpq.initialize">
<code class="descname">initialize</code><span class="sig-paren">(</span><em>n_minibatch=1</em>, <em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#edward.inferences.KLpq.initialize" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialization.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>n_minibatch</strong> (<em>int, optional</em>) &#8211; Number of samples from variational model for calculating
stochastic gradients.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="edward.inferences.KLpq.update">
<code class="descname">update</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#edward.inferences.KLpq.update" title="Permalink to this definition">¶</a></dt>
<dd><p>Runs one iteration of KLpq minimization.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><strong>loss</strong> &#8211; KLpq loss function value after one iteration.</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">double</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="edward.inferences.Laplace">
<em class="property">class </em><code class="descclassname">edward.inferences.</code><code class="descname">Laplace</code><span class="sig-paren">(</span><em>model</em>, <em>data=&lt;edward.data.Data object&gt;</em>, <em>params=None</em><span class="sig-paren">)</span><a class="headerlink" href="#edward.inferences.Laplace" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#edward.inferences.MAP" title="edward.inferences.MAP"><code class="xref py py-class docutils literal"><span class="pre">edward.inferences.MAP</span></code></a></p>
<p>Laplace approximation.</p>
<p>It approximates the posterior distribution using a normal
distribution centered at the mode of the posterior.</p>
<p>We implement this by running <code class="docutils literal"><span class="pre">MAP</span></code> to find the posterior mode.
This forms the mean of the normal approximation. We then compute
the Hessian at the mode of the posterior. This forms the
covariance of the normal approximation.</p>
<dl class="method">
<dt id="edward.inferences.Laplace.finalize">
<code class="descname">finalize</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#edward.inferences.Laplace.finalize" title="Permalink to this definition">¶</a></dt>
<dd><p>Function to call after convergence.</p>
<p>Computes the Hessian at the mode.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="edward.inferences.MAP">
<em class="property">class </em><code class="descclassname">edward.inferences.</code><code class="descname">MAP</code><span class="sig-paren">(</span><em>model</em>, <em>data=&lt;edward.data.Data object&gt;</em>, <em>params=None</em><span class="sig-paren">)</span><a class="headerlink" href="#edward.inferences.MAP" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#edward.inferences.VariationalInference" title="edward.inferences.VariationalInference"><code class="xref py py-class docutils literal"><span class="pre">edward.inferences.VariationalInference</span></code></a></p>
<p>Maximum a posteriori inference.</p>
<p>We implement this using a <code class="docutils literal"><span class="pre">PointMass</span></code> variational distribution to
solve the following optimization problem</p>
<div class="math">
\[\min_{z} - \log p(x,z)\]</div>
<dl class="method">
<dt id="edward.inferences.MAP.build_loss">
<code class="descname">build_loss</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#edward.inferences.MAP.build_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Loss function to minimize.</p>
<p>Defines the gradient of</p>
<div class="math">
\[- \log p(x,z)\]</div>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="edward.inferences.MFVI">
<em class="property">class </em><code class="descclassname">edward.inferences.</code><code class="descname">MFVI</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#edward.inferences.MFVI" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#edward.inferences.VariationalInference" title="edward.inferences.VariationalInference"><code class="xref py py-class docutils literal"><span class="pre">edward.inferences.VariationalInference</span></code></a></p>
<p>Mean-field variational inference.</p>
<p>This class implements a variety of &#8220;black-box&#8221; variational inference
techniques (Ranganath et al., 2014) that minimize</p>
<div class="math">
\[KL( q(z; \lambda) || p(z | x) ).\]</div>
<p>This is equivalent to maximizing the objective function (Jordan et al., 1999)</p>
<div class="math">
\[ELBO =  E_{q(z; \lambda)} [ \log p(x, z) - \log q(z; \lambda) ].\]</div>
<dl class="method">
<dt id="edward.inferences.MFVI.build_loss">
<code class="descname">build_loss</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#edward.inferences.MFVI.build_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Wrapper for the MFVI loss function.</p>
<div class="math">
\[-ELBO =  -E_{q(z; \lambda)} [ \log p(x, z) - \log q(z; \lambda) ]\]</div>
<p>MFVI supports</p>
<ol class="arabic simple">
<li>score function gradients</li>
<li>reparameterization gradients</li>
</ol>
<p>of the loss function.</p>
<p>If the variational model is a Gaussian distribution, then part of the
loss function can be computed analytically.</p>
<p>If the variational model is a normal distribution and the prior is
standard normal, then part of the loss function can be computed
analytically following Kingma and Welling (2014),</p>
<div class="math">
\[E[\log p(x | z) + KL],\]</div>
<p>where the KL term is computed analytically.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">an appropriately selected loss function form</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">result</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="edward.inferences.MFVI.build_reparam_loss">
<code class="descname">build_reparam_loss</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#edward.inferences.MFVI.build_reparam_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines a loss function whose automatic differentiation
is the stochastic gradient of</p>
<div class="math">
\[-ELBO =  -E_{q(z; \lambda)} [ \log p(x, z) - \log q(z; \lambda) ]\]</div>
<p>based on the reparameterization trick. (Kingma and Welling, 2014)</p>
<p>Computed by sampling from <span class="math">\(q(z;\lambda)\)</span> and evaluating the
expectation using Monte Carlo sampling.</p>
</dd></dl>

<dl class="method">
<dt id="edward.inferences.MFVI.build_reparam_loss_entropy">
<code class="descname">build_reparam_loss_entropy</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#edward.inferences.MFVI.build_reparam_loss_entropy" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines a loss function whose automatic differentiation
is the stochastic gradient of</p>
<div class="math">
\[-ELBO =  -( E_{q(z; \lambda)} [ \log p(x , z) ]
            + H(q(z; \lambda)) )\]</div>
<p>based on the reparameterization trick. (Kingma and Welling, 2014)</p>
<p>It assumes the entropy is analytic.</p>
<p>Computed by sampling from <span class="math">\(q(z;\lambda)\)</span> and evaluating the
expectation using Monte Carlo sampling.</p>
</dd></dl>

<dl class="method">
<dt id="edward.inferences.MFVI.build_reparam_loss_kl">
<code class="descname">build_reparam_loss_kl</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#edward.inferences.MFVI.build_reparam_loss_kl" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines a loss function whose automatic differentiation
is the stochastic gradient of</p>
<div class="math">
\[-ELBO =  - ( E_{q(z; \lambda)} [ \log p(x | z) ]
            + KL(q(z; \lambda) || p(z)) )\]</div>
<p>based on the reparameterization trick. (Kingma and Welling, 2014)</p>
<p>It assumes the KL is analytic.</p>
<p>It assumes the prior is <span class="math">\(p(z) = \mathcal{N}(z; 0, 1)\)</span></p>
<p>Computed by sampling from <span class="math">\(q(z;\lambda)\)</span> and evaluating the
expectation using Monte Carlo sampling.</p>
</dd></dl>

<dl class="method">
<dt id="edward.inferences.MFVI.build_score_loss">
<code class="descname">build_score_loss</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#edward.inferences.MFVI.build_score_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines a loss function whose automatic differentiation
is the stochastic gradient of</p>
<div class="math">
\[-ELBO =  -E_{q(z; \lambda)} [ \log p(x, z) - \log q(z; \lambda) ]\]</div>
<p>based on the score function estimator. (Paisley et al., 2012)</p>
<p>Computed by sampling from <span class="math">\(q(z;\lambda)\)</span> and evaluating the
expectation using Monte Carlo sampling.</p>
</dd></dl>

<dl class="method">
<dt id="edward.inferences.MFVI.build_score_loss_entropy">
<code class="descname">build_score_loss_entropy</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#edward.inferences.MFVI.build_score_loss_entropy" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines a loss function whose automatic differentiation
is the stochastic gradient of</p>
<div class="math">
\[-ELBO =  - ( E_{q(z; \lambda)} [ \log p(x, z) ]
            + H(q(z; \lambda)) )\]</div>
<p>based on the score function estimator. (Paisley et al., 2012)</p>
<p>It assumes the entropy is analytic.</p>
<p>Computed by sampling from <span class="math">\(q(z;\lambda)\)</span> and evaluating the
expectation using Monte Carlo sampling.</p>
</dd></dl>

<dl class="method">
<dt id="edward.inferences.MFVI.build_score_loss_kl">
<code class="descname">build_score_loss_kl</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#edward.inferences.MFVI.build_score_loss_kl" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines a loss function whose automatic differentiation
is the stochastic gradient of</p>
<div class="math">
\[-ELBO =  - ( E_{q(z; \lambda)} [ \log p(x | z) ]
             + KL(q(z; \lambda) || p(z)) )\]</div>
<p>based on the score function estimator. (Paisley et al., 2012)</p>
<p>It assumes the KL is analytic.</p>
<p>It assumes the prior is <span class="math">\(p(z) = \mathcal{N}(z; 0, 1)\)</span>.</p>
<p>Computed by sampling from <span class="math">\(q(z;\lambda)\)</span> and evaluating the
expectation using Monte Carlo sampling.</p>
</dd></dl>

<dl class="method">
<dt id="edward.inferences.MFVI.initialize">
<code class="descname">initialize</code><span class="sig-paren">(</span><em>n_minibatch=1</em>, <em>score=None</em>, <em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#edward.inferences.MFVI.initialize" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialization.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>n_minibatch</strong> (<em>int, optional</em>) &#8211; Number of samples from variational model for calculating
stochastic gradients.</li>
<li><strong>score</strong> (<em>bool, optional</em>) &#8211; Whether to force inference to use the score function
gradient estimator. Otherwise default is to use the
reparameterization gradient if available.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="edward.inferences.MFVI.update">
<code class="descname">update</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#edward.inferences.MFVI.update" title="Permalink to this definition">¶</a></dt>
<dd><p>Runs one iteration of MFVI.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><strong>loss</strong> &#8211; MFVI loss function value after one iteration.</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">double</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="edward.inferences.MonteCarlo">
<em class="property">class </em><code class="descclassname">edward.inferences.</code><code class="descname">MonteCarlo</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#edward.inferences.MonteCarlo" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#edward.inferences.Inference" title="edward.inferences.Inference"><code class="xref py py-class docutils literal"><span class="pre">edward.inferences.Inference</span></code></a></p>
<p>Base class for Monte Carlo inference methods.</p>
<p>Initialization.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>model</strong> (<em>ed.Model</em>) &#8211; probability model</li>
<li><strong>data</strong> (<em>ed.Data, optional</em>) &#8211; observed data</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="class">
<dt id="edward.inferences.VariationalInference">
<em class="property">class </em><code class="descclassname">edward.inferences.</code><code class="descname">VariationalInference</code><span class="sig-paren">(</span><em>model</em>, <em>variational</em>, <em>data=&lt;edward.data.Data object&gt;</em><span class="sig-paren">)</span><a class="headerlink" href="#edward.inferences.VariationalInference" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#edward.inferences.Inference" title="edward.inferences.Inference"><code class="xref py py-class docutils literal"><span class="pre">edward.inferences.Inference</span></code></a></p>
<p>Base class for variational inference methods.</p>
<p>Initialization.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>model</strong> (<em>ed.Model</em>) &#8211; probability model</li>
<li><strong>variational</strong> (<em>ed.Variational</em>) &#8211; variational model or distribution</li>
<li><strong>data</strong> (<em>ed.Data, optional</em>) &#8211; observed data</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="edward.inferences.VariationalInference.build_loss">
<code class="descname">build_loss</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#edward.inferences.VariationalInference.build_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Build loss function.</p>
<p>Empty method.</p>
<p>Any class based on <code class="docutils literal"><span class="pre">VariationalInference</span></code> <strong>must</strong>
implement this method.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Raises:</th><td class="field-body"><code class="xref py py-exc docutils literal"><span class="pre">NotImplementedError</span></code></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="edward.inferences.VariationalInference.finalize">
<code class="descname">finalize</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#edward.inferences.VariationalInference.finalize" title="Permalink to this definition">¶</a></dt>
<dd><p>Finalize.</p>
<p>Empty method. (Optional.)</p>
<p>Any class based on <code class="docutils literal"><span class="pre">VariationalInference</span></code> <strong>may</strong>
implement this method.</p>
</dd></dl>

<dl class="method">
<dt id="edward.inferences.VariationalInference.initialize">
<code class="descname">initialize</code><span class="sig-paren">(</span><em>n_iter=1000</em>, <em>n_data=None</em>, <em>n_print=100</em>, <em>optimizer=None</em>, <em>scope=None</em><span class="sig-paren">)</span><a class="headerlink" href="#edward.inferences.VariationalInference.initialize" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize variational inference algorithm.</p>
<p>Set up <code class="docutils literal"><span class="pre">tf.train.AdamOptimizer</span></code> with a decaying scale factor.</p>
<p>Initialize all variables</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>n_iter</strong> (<em>int, optional</em>) &#8211; Number of iterations for optimization.</li>
<li><strong>n_data</strong> (<em>int, optional</em>) &#8211; Number of samples for data subsampling. Default is to use all
the data.</li>
<li><strong>n_print</strong> (<em>int, optional</em>) &#8211; Number of iterations for each print progress. To suppress print
progress, then specify None.</li>
<li><strong>optimizer</strong> (<em>str, optional</em>) &#8211; Whether to use TensorFlow optimizer or PrettyTensor
optimizer when using PrettyTensor. Defaults to TensorFlow.</li>
<li><strong>scope</strong> (<em>str, optional</em>) &#8211; Scope of TensorFlow variable objects to optimize over.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="edward.inferences.VariationalInference.print_progress">
<code class="descname">print_progress</code><span class="sig-paren">(</span><em>t</em>, <em>loss</em><span class="sig-paren">)</span><a class="headerlink" href="#edward.inferences.VariationalInference.print_progress" title="Permalink to this definition">¶</a></dt>
<dd><p>Print progress to output.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>t</strong> (<em>int</em>) &#8211; Iteration counter</li>
<li><strong>loss</strong> (<em>double</em>) &#8211; Loss function value at iteration <code class="docutils literal"><span class="pre">t</span></code></li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="edward.inferences.VariationalInference.run">
<code class="descname">run</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#edward.inferences.VariationalInference.run" title="Permalink to this definition">¶</a></dt>
<dd><p>A simple wrapper to run variational inference.</p>
<ol class="arabic simple">
<li>Initialize via <code class="docutils literal"><span class="pre">initialize</span></code></li>
<li>Run <code class="docutils literal"><span class="pre">update</span></code> for <code class="docutils literal"><span class="pre">self.n_iter</span></code> iterations</li>
<li>While running, <code class="docutils literal"><span class="pre">print_progress</span></code></li>
<li>Finalize via <code class="docutils literal"><span class="pre">finalize</span></code></li>
</ol>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>*args</strong> &#8211; passed into <code class="docutils literal"><span class="pre">initialize</span></code></li>
<li><strong>**kwargs</strong> &#8211; passed into <code class="docutils literal"><span class="pre">initialize</span></code></li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="edward.inferences.VariationalInference.update">
<code class="descname">update</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#edward.inferences.VariationalInference.update" title="Permalink to this definition">¶</a></dt>
<dd><p>Run one iteration of optimizer for variational inference.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><strong>loss</strong> &#8211; Loss function values after one iteration</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">double</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-edward.util">
<span id="edward-util-module"></span><h2>edward.util module<a class="headerlink" href="#module-edward.util" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="edward.util.cumprod">
<code class="descclassname">edward.util.</code><code class="descname">cumprod</code><span class="sig-paren">(</span><em>xs</em><span class="sig-paren">)</span><a class="headerlink" href="#edward.util.cumprod" title="Permalink to this definition">¶</a></dt>
<dd><p>Cumulative product of a tensor along first dimension.</p>
<p><a class="reference external" href="https://github.com/tensorflow/tensorflow/issues/813">https://github.com/tensorflow/tensorflow/issues/813</a></p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>x</strong> (<em>tf.Tensor</em>) &#8211; vector, matrix, or n-Tensor</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">A Tensor with <cite>cumprod</cite> applied along its first dimension.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">tf.Tensor</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="edward.util.dot">
<code class="descclassname">edward.util.</code><code class="descname">dot</code><span class="sig-paren">(</span><em>x</em>, <em>y</em><span class="sig-paren">)</span><a class="headerlink" href="#edward.util.dot" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute dot product between a Tensor matrix and a Tensor vector.</p>
<p>If x is a <code class="docutils literal"><span class="pre">[M</span> <span class="pre">x</span> <span class="pre">N]</span></code> matrix, then y is a <code class="docutils literal"><span class="pre">M</span></code>-vector.</p>
<p>If x is a <code class="docutils literal"><span class="pre">M</span></code>-vector, then y is a <code class="docutils literal"><span class="pre">[M</span> <span class="pre">x</span> <span class="pre">N]</span></code> matrix.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>x</strong> (<em>tf.Tensor</em>) &#8211; <code class="docutils literal"><span class="pre">M</span> <span class="pre">x</span> <span class="pre">N</span></code> matrix or <code class="docutils literal"><span class="pre">M</span></code> vector (see above)</li>
<li><strong>y</strong> (<em>tf.Tensor</em>) &#8211; <code class="docutils literal"><span class="pre">M</span></code> vector or <code class="docutils literal"><span class="pre">M</span> <span class="pre">x</span> <span class="pre">N</span></code> matrix (see above)</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><code class="docutils literal"><span class="pre">N</span></code>-vector</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">tf.Tensor</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="edward.util.get_dims">
<code class="descclassname">edward.util.</code><code class="descname">get_dims</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="headerlink" href="#edward.util.get_dims" title="Permalink to this definition">¶</a></dt>
<dd><p>Get values of each dimension.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>x</strong> (<em>tf.Tensor</em>) &#8211; scalar, vector, matrix, or n-Tensor</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">Python list containing dimensions of <cite>x</cite></td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">list</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="edward.util.get_session">
<code class="descclassname">edward.util.</code><code class="descname">get_session</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#edward.util.get_session" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the globally defined TensorFlow session.</p>
<p>If the session is not already defined, then the function will create
a global session.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><strong>_ED_SESSION</strong></td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">tf.InteractiveSession</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="edward.util.hessian">
<code class="descclassname">edward.util.</code><code class="descname">hessian</code><span class="sig-paren">(</span><em>y</em>, <em>xs</em><span class="sig-paren">)</span><a class="headerlink" href="#edward.util.hessian" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate Hessian of y with respect to each x in xs.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>y</strong> (<em>tf.Tensor</em>) &#8211; Tensor to calculate Hessian of.</li>
<li><strong>xs</strong> (<em>list</em>) &#8211; List of TensorFlow variables to calculate with respect to.
The variables can have different shapes.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">A matrix where each row is
.. math:: partial_{xs} ( [ partial_{xs} y ]_j ).</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">tf.Tensor</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="edward.util.kl_multivariate_normal">
<code class="descclassname">edward.util.</code><code class="descname">kl_multivariate_normal</code><span class="sig-paren">(</span><em>loc_one</em>, <em>scale_one</em>, <em>loc_two=0</em>, <em>scale_two=1</em><span class="sig-paren">)</span><a class="headerlink" href="#edward.util.kl_multivariate_normal" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate the KL of multivariate normal distributions with
diagonal covariances.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>loc_one</strong> (<em>tf.Tensor</em>) &#8211; n-dimensional vector, or M x n-dimensional matrix where each
row represents the mean of a n-dimensional Gaussian</li>
<li><strong>scale_one</strong> (<em>tf.Tensor</em>) &#8211; n-dimensional vector, or M x n-dimensional matrix where each
row represents the standard deviation of a n-dimensional Gaussian</li>
<li><strong>loc_two</strong> (<em>tf.Tensor, optional</em>) &#8211; n-dimensional vector, or M x n-dimensional matrix where each
row represents the mean of a n-dimensional Gaussian</li>
<li><strong>scale_two</strong> (<em>tf.Tensor, optional</em>) &#8211; n-dimensional vector, or M x n-dimensional matrix where each
row represents the standard deviation of a n-dimensional Gaussian</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">for scalar or vector inputs, outputs the scalar
<code class="docutils literal"><span class="pre">KL(</span> <span class="pre">N(z;</span> <span class="pre">loc_one,</span> <span class="pre">scale_one)</span> <span class="pre">||</span> <span class="pre">N(z;</span> <span class="pre">loc_two,</span> <span class="pre">scale_two)</span> <span class="pre">)</span></code>
for matrix inputs, outputs the vector
<code class="docutils literal"><span class="pre">[KL(</span> <span class="pre">N(z;</span> <span class="pre">loc_one[m,:],</span> <span class="pre">scale_one[m,:])</span> <span class="pre">||</span> <span class="pre">N(z;</span> <span class="pre">loc_two[m,:],</span> <span class="pre">scale_two[m,:])</span> <span class="pre">)]_{m=1}^M</span></code></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">tf.Tensor</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="edward.util.log_sum_exp">
<code class="descclassname">edward.util.</code><code class="descname">log_sum_exp</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="headerlink" href="#edward.util.log_sum_exp" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the <code class="docutils literal"><span class="pre">log_sum_exp</span></code> of the elements in x.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>x</strong> (<em>tf.Tensor</em>) &#8211; vector or matrix with second dimension 1
shape=TensorShape([Dimension(N)])
shape=TensorShape([Dimension(N), Dimension(1)])</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">scalar if vector input, vector if matrix tensor input</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">tf.Tensor</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="edward.util.logit">
<code class="descclassname">edward.util.</code><code class="descname">logit</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="headerlink" href="#edward.util.logit" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluate <span class="math">\(\log(x / (1 - x))\)</span> elementwise.</p>
<p>Clips all elements to be between <span class="math">\((0,1)\)</span>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>x</strong> (<em>tf.Tensor</em>) &#8211; scalar, vector, matrix, or n-Tensor</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">size corresponding to size of input</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">tf.Tensor</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="edward.util.multivariate_rbf">
<code class="descclassname">edward.util.</code><code class="descname">multivariate_rbf</code><span class="sig-paren">(</span><em>x</em>, <em>y=0.0</em>, <em>sigma=1.0</em>, <em>l=1.0</em><span class="sig-paren">)</span><a class="headerlink" href="#edward.util.multivariate_rbf" title="Permalink to this definition">¶</a></dt>
<dd><p>Squared-exponential kernel</p>
<div class="math">
\[k(x, y) = \sigma^2 \exp{ -1/(2l^2) \sum_i (x_i - y_i)^2 }\]</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>x</strong> (<em>tf.Tensor</em>) &#8211; scalar, vector, matrix, or n-Tensor</li>
<li><strong>y</strong> (<em>Optional[tf.Tensor], default 0.0</em>) &#8211; scalar, vector, matrix, or n-Tensor</li>
<li><strong>sigma</strong> (<em>Optional[double], default 1.0</em>) &#8211; standard deviation of radial basis function</li>
<li><strong>l</strong> (<em>Optional[double], default 1.0</em>) &#8211; lengthscale of radial basis function</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">scalar if vector input, rank-(n-1) if n-Tensor input</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">tf.Tensor</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="edward.util.rbf">
<code class="descclassname">edward.util.</code><code class="descname">rbf</code><span class="sig-paren">(</span><em>x</em>, <em>y=0.0</em>, <em>sigma=1.0</em>, <em>l=1.0</em><span class="sig-paren">)</span><a class="headerlink" href="#edward.util.rbf" title="Permalink to this definition">¶</a></dt>
<dd><p>Squared-exponential kernel element-wise</p>
<div class="math">
\[k(x, y) = \sigma^2 \exp{ -1/(2l^2) (x_i - y_i)^2 }\]</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>x</strong> (<em>tf.Tensor</em>) &#8211; scalar, vector, matrix, or n-Tensor</li>
<li><strong>y</strong> (<em>Optional[tf.Tensor], default 0.0</em>) &#8211; scalar, vector, matrix, or n-Tensor</li>
<li><strong>sigma</strong> (<em>Optional[double], default 1.0</em>) &#8211; standard deviation of radial basis function</li>
<li><strong>l</strong> (<em>Optional[double], default 1.0</em>) &#8211; lengthscale of radial basis function</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">size corresponding to size of input</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">tf.Tensor</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="edward.util.set_seed">
<code class="descclassname">edward.util.</code><code class="descname">set_seed</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="headerlink" href="#edward.util.set_seed" title="Permalink to this definition">¶</a></dt>
<dd><p>Set seed for both NumPy and TensorFlow.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>x</strong> (<em>int, float</em>) &#8211; seed</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="edward.util.softplus">
<code class="descclassname">edward.util.</code><code class="descname">softplus</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="headerlink" href="#edward.util.softplus" title="Permalink to this definition">¶</a></dt>
<dd><p>Elementwise Softplus function</p>
<div class="math">
\[\log(1 + \exp(x))\]</div>
<p>TensorFlow can&#8217;t currently autodiff through <code class="docutils literal"><span class="pre">tf.nn.softplus()</span></code>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>x</strong> (<em>tf.Tensor</em>) &#8211; scalar, vector, matrix, or n-Tensor</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">size corresponding to size of input</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">tf.Tensor</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="edward.util.stop_gradient">
<code class="descclassname">edward.util.</code><code class="descname">stop_gradient</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="headerlink" href="#edward.util.stop_gradient" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply <code class="docutils literal"><span class="pre">tf.stop_gradient()</span></code> element-wise.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>x</strong> (<em>tf.Tensor or list</em>) &#8211; scalar, vector, matrix, or n-Tensor or list thereof</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">size corresponding to size of input</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">tf.Tensor or list</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="edward.util.to_simplex">
<code class="descclassname">edward.util.</code><code class="descname">to_simplex</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="headerlink" href="#edward.util.to_simplex" title="Permalink to this definition">¶</a></dt>
<dd><p>Transform real vector of length <code class="docutils literal"><span class="pre">(K-1)</span></code> to a simplex of dimension <code class="docutils literal"><span class="pre">K</span></code>
using a backward stick breaking construction.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>x</strong> (<em>tf.tensor or np.array</em>) &#8211; scalar, vector, or matrix</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">Same shape as input but with last dimension of size <code class="docutils literal"><span class="pre">K</span></code>.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">tf.Tensor</td>
</tr>
</tbody>
</table>
<p class="rubric">Notes</p>
<p>x as a 3d or higher tensor is not guaranteed to be supported.</p>
</dd></dl>

</div>
<div class="section" id="module-edward">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-edward" title="Permalink to this headline">¶</a></h2>
</div>
</div>


           </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="edward.models.html" class="btn btn-neutral float-right" title="edward.models package" accesskey="n">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="index.html" class="btn btn-neutral" title="Edward" accesskey="p"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2016, Edward Development Team.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'./',
            VERSION:'1.0',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true
        };
    </script>
      <script type="text/javascript" src="_static/jquery.js"></script>
      <script type="text/javascript" src="_static/underscore.js"></script>
      <script type="text/javascript" src="_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>