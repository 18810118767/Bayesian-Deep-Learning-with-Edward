<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta content="text/html; charset=utf-8" http-equiv="Content-Type"/>
<meta content="text/css" http-equiv="Content-Style-Type"/>
<meta content="pandoc" name="generator"/>
<title>Edward – Linear Mixed Effects Models</title>
<!-- Mobile Specific Metas -->
<meta content="width=device-width, initial-scale=1" name="viewport">
<!-- FONT -->
<link href="https://fonts.googleapis.com/css?family=Lora:400,400i,700" rel="stylesheet">
<!-- CSS -->
<link href="/css/normalize.css" rel="stylesheet">
<link href="/css/skeleton.css" rel="stylesheet">
<!-- Dynamically resize logo for mobile -->
<style type="text/css">
  .logo-width {
    width: 100%;
    box-sizing: border-box;
    margin-bottom: 15%;
  }
  /* Roughly the point when website is single column */
  @media (max-width: 850px) {
    .logo-width {
      width: 50%;
      box-sizing: border-box;
      margin-bottom: 5%;
    }
  }
  /* Docstrings. */
  dl.class + dl.class, dl.function + dl.function {
    /* Add border inbetween docstrings. */
    border-top: 1px solid #E1E1E1;
  }
  dt { /* Add spacing for top border. */
    margin-top: 1.0rem;
  }
  dd { /* Remove overall indenting in an entry. */
    margin-left: 0.0rem;
  }
  dl th, dl td { /* Remove extraneous padding and decorations. */
    padding: 0 15px 0 0;
    border: none;
  }
  dt em, dt span.sig-paren { /* Keep style of declarations consistent. */
    font-family: monospace, monospace;
    font-style: normal;
    font-size: 14px !important;
  }
  /* Attribute contents within a docstring. */
  dd blockquote, dl blockquote, dt blockquote { /* Reduce margins. */
    margin-left: 0.0rem;
    margin-top: 0.0rem;
    margin-bottom: 0.0rem;
  }
  dl td p { /* Reduce spacing. */
    margin-bottom: 0.75rem;
  }
  dl td.field-body { /* Add indenting. */
    padding-top: 0.75rem;
    padding-left: 2.0rem;
    display: block;
  }
  dl code { /* Keep code font size consistent with rest of contents. */
    font-size: 90%;
  }
  </style>
<!-- KaTeX -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.6.0/katex.min.js"></script>
<link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.6.0/katex.min.css" rel="stylesheet"/>
<script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.6.0/contrib/auto-render.min.js"></script>
<!-- highlight.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.4.0/highlight.min.js"></script>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.4.0/styles/github.min.css" rel="stylesheet">
<!-- Favicon -->
<link href="/icons/apple-touch-icon-57x57.png" rel="apple-touch-icon" sizes="57x57">
<link href="/icons/apple-touch-icon-60x60.png" rel="apple-touch-icon" sizes="60x60">
<link href="/icons/apple-touch-icon-72x72.png" rel="apple-touch-icon" sizes="72x72">
<link href="/icons/apple-touch-icon-76x76.png" rel="apple-touch-icon" sizes="76x76">
<link href="/icons/apple-touch-icon-114x114.png" rel="apple-touch-icon" sizes="114x114">
<link href="/icons/apple-touch-icon-120x120.png" rel="apple-touch-icon" sizes="120x120">
<link href="/icons/apple-touch-icon-144x144.png" rel="apple-touch-icon" sizes="144x144">
<link href="/icons/apple-touch-icon-152x152.png" rel="apple-touch-icon" sizes="152x152">
<link href="/icons/apple-touch-icon-180x180.png" rel="apple-touch-icon" sizes="180x180">
<link href="/icons/favicon-32x32.png" rel="icon" sizes="32x32" type="image/png">
<link href="/icons/android-chrome-192x192.png" rel="icon" sizes="192x192" type="image/png">
<link href="/icons/favicon-96x96.png" rel="icon" sizes="96x96" type="image/png">
<link href="/icons/favicon-16x16.png" rel="icon" sizes="16x16" type="image/png">
<link href="/icons/manifest.json" rel="manifest">
<link color="#5bbad5" href="/icons/safari-pinned-tab.svg" rel="mask-icon">
<link href="/icons/favicon.ico" rel="shortcut icon">
<meta content="#da532c" name="msapplication-TileColor">
<meta content="/icons/mstile-144x144.png" name="msapplication-TileImage">
<meta content="/icons/browserconfig.xml" name="msapplication-config">
<meta content="#ffffff" name="theme-color">
</meta></meta></meta></meta></link></link></link></link></link></link></link></link></link></link></link></link></link></link></link></link></link></link></link></link></meta></head>
<body>
<div class="container">
<div class="row" style="margin-top: 5%">
<div class="three columns">
<h1><a href="/">Edward</a></h1>
<a href="/">
<center>
<img alt="Edward" class="logo-width" src="/images/edward.png"/>
</center>
</a>
<a class="button u-full-width" href="/getting-started">Getting Started</a>
<a class="button u-full-width" href="/tutorials/">Tutorials</a>
<a class="button u-full-width" href="/api/">API</a>
<a class="button u-full-width" href="/community">Community</a>
<a class="button u-full-width" href="/contributing">Contributing</a>
<div class="row" style="padding-bottom: 5%"> </div>
<a class="button2 u-pull-right" href="https://github.com/blei-lab/edward" style="padding-right:10%">
<span style="vertical-align:middle;">Github</span> 
      <img alt="Edward on Github" src="/images/github-mark.svg" style="vertical-align:middle;"/>
</a>
<div class="row" style="padding-bottom: 5%"> </div>
</div>
<div class="nine columns">
<h2 id="linear-mixed-effects-models">Linear Mixed Effects Models</h2>
<p>With linear mixed effects models, we wish to model a linear relationship for data points with inputs of varying type, categorized into subgroups, and associated to a real-valued output.</p>
<p>We demonstrate with an example in Edward. An interactive version with Jupyter notebook is available <a href="http://nbviewer.jupyter.org/github/blei-lab/edward/blob/master/notebooks/linear_mixed_effects_models.ipynb">here</a>.</p>
<h3 id="data">Data</h3>
<p>We use the <code>InstEval</code> data set from the popular <a href="http://lme4.r-forge.r-project.org">lme4 R package</a> <span class="citation">(Bates, Mächler, Bolker, &amp; Walker, 2015)</span>, located <a href="https://github.com/blei-lab/edward/blob/master/examples/data/insteval.csv">here</a>. It is a data set of instructor evaluation ratings, where the inputs (covariates) include categories such as <code>students</code> and <code>departments</code>, and our response variable of interest is the instructor evaluation rating.</p>
<pre class="python" language="Python"><code>data = pd.read_csv('../../examples/data/insteval.csv')
data['dcodes'] = data['d'].astype('category').cat.codes
data['deptcodes'] = data['dept'].astype('category').cat.codes
data['s'] = data['s'] - 1

train = data.sample(frac=0.8)
test = data.drop(train.index)</code></pre>
<p>In the code, we denote:</p>
<ul>
<li><code>students</code> as <code>s</code></li>
<li><code>instructors</code> as <code>d</code></li>
<li><code>departments</code> as <code>dept</code></li>
<li><code>service</code> as <code>service</code></li>
</ul>
<pre class="python" language="Python"><code>n_s = 2972  # number of students
n_d = 1128  # number of instructors
n_dept = 14  # number of departments
n_obs = train.shape[0]  # number of observations</code></pre>
<h3 id="model">Model</h3>
<p>With linear regression, one makes an independence assumption where each data point regresses with a constant slope among each other. In our setting, the observations come from sets of groups which may have varying slopes and intercepts. Thus we’d like to build a model that can capture this behavior <span class="citation">(Gelman &amp; Hill, 2006)</span>.</p>
<p>For examples of this phenomena:</p>
<ul>
<li>The observations from a single student are not independent of each other. Rather, some students may systematically give low (or high) lecture ratings.</li>
<li>The observations from a single teacher are not independent of each other. We expect good teachers to get generally good ratings and bad teachers to get generally bad ratings.</li>
<li>The observations from a single department are not independent of each other. One department may generally have dry material and thus be rated lower than others.</li>
</ul>
<p>Typical linear regression takes the form <span class="math display">\[\mathbf{y} = \mathbf{X}\beta + \epsilon,\]</span> where <span class="math inline">\(\mathbf{X}\)</span> corresponds to fixed effects with coefficients <span class="math inline">\(\beta\)</span> and <span class="math inline">\(\epsilon\)</span> corresponds to random noise, <span class="math inline">\(\epsilon\sim\mathcal{N}(\mathbf{0}, \mathbf{I})\)</span>.</p>
<p>In a linear mixed effects model, we add an additional term <span class="math inline">\(\mathbf{Z}\eta\)</span>, where <span class="math inline">\(\mathbf{Z}\)</span> corresponds to random effects with coefficients <span class="math inline">\(\eta\)</span>. The model takes the form <span class="math display">\[\begin{aligned}
\eta &amp;\sim \mathcal{N}(\mathbf{0}, \sigma^2 \mathbf{I}), \\
\mathbf{y} &amp;= \mathbf{X}\beta + \mathbf{Z}\eta + \epsilon.\end{aligned}\]</span> Given data, the goal is to infer <span class="math inline">\(\beta\)</span>, <span class="math inline">\(\eta\)</span>, and <span class="math inline">\(\sigma^2\)</span>, where <span class="math inline">\(\beta\)</span> are model parameters (“fixed effects”), <span class="math inline">\(\eta\)</span> are latent variables (“random effects”), and <span class="math inline">\(\sigma^2\)</span> is a variance component parameter.</p>
<p>Because the random effects have mean 0, the data’s mean is captured by <span class="math inline">\(\mathbf{X}\beta\)</span>. The random effects component <span class="math inline">\(\mathbf{Z}\eta\)</span> captures variations in the data (e.g. Instructor #54 is rated 1.4 points higher than the mean).</p>
<p>A natural question is the difference between fixed and random effects. A fixed effect is an effect that is constant for a given population. A random effect is an effect that varies for a given population (i.e., it may be constant within subpopulations but varies within the overall population). We illustrate below in our example:</p>
<ul>
<li>Select <code>service</code> as the fixed effect. It is a binary covariate corresponding to whether the lecture belongs to the lecturer’s main department or not. No matter how much additional data we collect, it can only take on the values in <span class="math inline">\(0\)</span> and <span class="math inline">\(1\)</span>.</li>
<li>Selct the categorical values of <code>students</code>, <code>teachers</code>, and <code>departments</code> as the random effects. Given more observations from the population of instructor evaluation ratings, we may be looking at new students, teachers, or departments.</li>
</ul>
<p>In the syntax of R’s lme4 package <span class="citation">(Bates et al., 2015)</span>, the model can be summarized as</p>
<pre language="JSON"><code>y ~ 1 + (1|students) + (1|instructor) + (1|dept) + service</code></pre>
<p>where <code>1</code> denotes an intercept term, <code>(1|x)</code> denotes a random effect for <code>x</code>, and <code>x</code> denotes a fixed effect.</p>
<pre class="python" language="Python"><code># Set up placeholders for the data inputs.
s_ph = tf.placeholder(tf.int32, [None])
d_ph = tf.placeholder(tf.int32, [None])
dept_ph = tf.placeholder(tf.int32, [None])
service_ph = tf.placeholder(tf.float32, [None])

# Set up fixed effects.
mu = tf.Variable(tf.random_normal([]))
service = tf.Variable(tf.random_normal([]))

sigma_s = tf.sqrt(tf.exp(tf.Variable(tf.random_normal([]))))
sigma_d = tf.sqrt(tf.exp(tf.Variable(tf.random_normal([]))))
sigma_dept = tf.sqrt(tf.exp(tf.Variable(tf.random_normal([]))))

# Set up random effects.
eta_s = Normal(mu=tf.zeros(n_s), sigma=sigma_s * tf.ones(n_s))
eta_d = Normal(mu=tf.zeros(n_d), sigma=sigma_d * tf.ones(n_d))
eta_dept = Normal(mu=tf.zeros(n_dept), sigma=sigma_dept * tf.ones(n_dept))

yhat = tf.gather(eta_s, s_ph) + \
    tf.gather(eta_d, d_ph) + \
    tf.gather(eta_dept, dept_ph) + \
    mu + service * service_ph
y = Normal(mu=yhat, sigma=tf.ones(n_obs))</code></pre>
<h3 id="inference">Inference</h3>
<p>Given data, we aim to infer the model’s fixed and random effects. In this analysis, we use variational inference with the <span class="math inline">\(\text{KL}(q\|p)\)</span> divergence measure. We specify fully factorized normal approximations for the random effects and pass in all training data for inference. Under the algorithm, the fixed effects will be estimated under a variational EM scheme.</p>
<pre class="python" language="Python"><code>q_eta_s = Normal(
    mu=tf.Variable(tf.random_normal([n_s])),
    sigma=tf.nn.softplus(tf.Variable(tf.random_normal([n_s]))))
q_eta_d = Normal(
    mu=tf.Variable(tf.random_normal([n_d])),
    sigma=tf.nn.softplus(tf.Variable(tf.random_normal([n_d]))))
q_eta_dept = Normal(
    mu=tf.Variable(tf.random_normal([n_dept])),
    sigma=tf.nn.softplus(tf.Variable(tf.random_normal([n_dept]))))

latent_vars = {
    eta_s: q_eta_s,
    eta_d: q_eta_d,
    eta_dept: q_eta_dept}
data = {
    y: y_train,
    s_ph: s_train,
    d_ph: d_train,
    dept_ph: dept_train,
    service_ph: service_train}
inference = ed.KLqp(latent_vars, data)</code></pre>
<p>One way to critique the fitted model is a residual plot, i.e., a plot of the difference between the predicted value and the observed value for each data point. Below we manually run inference, initializing the algorithm and performing individual updates within a loop. We form residual plots as the algorithm progresses. This helps us examine how the algorithm proceeds to infer the random and fixed effects from data.</p>
<p>To form residuals, we first make predictions on test data. We do this by copying <code>yhat</code> defined in the model and replacing its dependence on random effects with their inferred means. During the algorithm, we evaluate the predictions, feeding in test inputs.</p>
<pre class="python" language="Python"><code>yhat_test = ed.copy(yhat, {
    eta_s: q_eta_s.mean(),
    eta_d: q_eta_d.mean(),
    eta_dept: q_eta_dept.mean()})</code></pre>
<p>We now write the main loop.</p>
<pre class="python" language="Python"><code>inference.initialize(n_print=20, n_iter=100)
tf.global_variables_initializer().run()

for _ in range(inference.n_iter):
  # Update and print progress of algorithm.
  info_dict = inference.update()
  inference.print_progress(info_dict)

  t = info_dict['t']
  if t == 1 or t % inference.n_print == 0:
    # Make predictions on test data.
    yhat_vals = yhat_test.eval(feed_dict={
        s_ph: s_test,
        d_ph: d_test,
        dept_ph: dept_test,
        service_ph: service_test})

    # Form residual plot.
    plt.title("Residuals for Predicted Ratings on Test Set")
    plt.xlim(-4, 4)
    plt.ylim(0, 800)
    plt.hist(yhat_vals - y_test, 75)
    plt.show()</code></pre>
<h3 id="criticism">Criticism</h3>
<p>Above, we described a method for diagnosing the fit of the model via residual plots. Below we show the residuals for the model post-convergence. (For intermediate residual plots, check the Jupyter notebook.)</p>
<p><img alt="image" src="/images/linear-mixed-effects-models.png" width="450"/></p>
<p>The residuals appear normally distributed with mean 0. This provides evidence that the model correctly fits the data.</p>
<h3 id="acknowledgments">Acknowledgments</h3>
<p>We thank Mayank Agrawal for writing the initial version of this tutorial.</p>
<h3 class="unnumbered" id="references">References</h3>
<div class="references" id="refs">
<div id="ref-bates2015fitting">
<p>Bates, D., Mächler, M., Bolker, B., &amp; Walker, S. (2015). Fitting Linear Mixed-Effects Models Using lme4. <em>Journal of Statistical Software</em>, <em>67</em>(1), 1–48.</p>
</div>
<div id="ref-gelman2006data">
<p>Gelman, A., &amp; Hill, J. L. (2006). <em>Data analysis using regression and multilevel/hierarchical models</em>. Cambridge University Press.</p>
</div>
</div>
</div>
</div>
<div class="row" style="padding-bottom: 25%"> </div>
</div>
<script>
  hljs.initHighlightingOnLoad();
  renderMathInElement(document.body);
</script>
</body>
</html>
