<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <title>Edward – Mixture of Gaussians</title>
  <!-- Mobile Specific Metas -->
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- FONT -->
  <link href="https://fonts.googleapis.com/css?family=Lora:400,400i,700" rel="stylesheet">

  <!-- CSS -->
  <link rel="stylesheet" href="/css/normalize.css">
  <link rel="stylesheet" href="/css/skeleton.css">
  <!-- Dynamically resize logo for mobile -->
  <style type="text/css">
  .logo-width {
    width: 100%;
    box-sizing: border-box;
    margin-bottom: 15%;
  }
  /* Roughly the point when website is single column */
  @media (max-width: 850px) {
    .logo-width {
      width: 50%;
      box-sizing: border-box;
      margin-bottom: 5%;
    }
  }
  </style>

  <!-- KaTeX -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.6.0/katex.min.js"></script>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.6.0/katex.min.css" />
  <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.6.0/contrib/auto-render.min.js"></script>

  <!-- highlight.js -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.4.0/highlight.min.js"></script>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.4.0/styles/github.min.css">

  <!-- Favicon -->
  <link rel="apple-touch-icon" sizes="57x57" href="/icons/apple-touch-icon-57x57.png">
  <link rel="apple-touch-icon" sizes="60x60" href="/icons/apple-touch-icon-60x60.png">
  <link rel="apple-touch-icon" sizes="72x72" href="/icons/apple-touch-icon-72x72.png">
  <link rel="apple-touch-icon" sizes="76x76" href="/icons/apple-touch-icon-76x76.png">
  <link rel="apple-touch-icon" sizes="114x114" href="/icons/apple-touch-icon-114x114.png">
  <link rel="apple-touch-icon" sizes="120x120" href="/icons/apple-touch-icon-120x120.png">
  <link rel="apple-touch-icon" sizes="144x144" href="/icons/apple-touch-icon-144x144.png">
  <link rel="apple-touch-icon" sizes="152x152" href="/icons/apple-touch-icon-152x152.png">
  <link rel="apple-touch-icon" sizes="180x180" href="/icons/apple-touch-icon-180x180.png">
  <link rel="icon" type="image/png" href="/icons/favicon-32x32.png" sizes="32x32">
  <link rel="icon" type="image/png" href="/icons/android-chrome-192x192.png" sizes="192x192">
  <link rel="icon" type="image/png" href="/icons/favicon-96x96.png" sizes="96x96">
  <link rel="icon" type="image/png" href="/icons/favicon-16x16.png" sizes="16x16">
  <link rel="manifest" href="/icons/manifest.json">
  <link rel="mask-icon" href="/icons/safari-pinned-tab.svg" color="#5bbad5">
  <link rel="shortcut icon" href="/icons/favicon.ico">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="msapplication-TileImage" content="/icons/mstile-144x144.png">
  <meta name="msapplication-config" content="/icons/browserconfig.xml">
  <meta name="theme-color" content="#ffffff">
</head>
<body>
<div class="container">
  <div class="row" style="margin-top: 5%">
    <div class="three columns">
    <h1><a href="/">Edward</a></h1>
    <a href="/">
    <center>
      <img src="/images/edward.png" class="logo-width" alt="Edward" />
    </center>
    </a>
    <a class="button u-full-width" href="/">Home</a>
    <a class="button u-full-width" href="/getting-started">Getting Started</a>
    <a class="button u-full-width" href="/tutorials/">Tutorials</a>
    <a class="button u-full-width" href="/api/">API</a>
    <a class="button u-full-width" href="#">Advanced</a>
    <a class="button2 u-full-width" href="/design-philosophy">Design Philosophy</a>
    <a class="button2 u-full-width" href="/contributing">Contributing</a>
    <a class="button2 u-full-width" href="/troubleshooting">Troubleshooting</a>
    <a class="button2 u-full-width" href="/license">License</a>
    <div class="row" style="padding-bottom: 5%"> </div>
    <a href="https://github.com/blei-lab/edward">
    <!-- <object data="images/github-mark.svg" type="image/svg+xml"> -->
      <img src="/images/github-mark.svg" class="u-pull-right" style="padding-right:10%"
    alt="Edward on Github" />
    <!-- </object> -->
    </a>
    <div class="row" style="padding-bottom: 5%"> </div>
    </div>
    <div class="nine columns">

<h2 id="mixture-of-gaussians">Mixture of Gaussians</h2>
<p>A mixture model is a model typically used for clustering. It assigns a mixture component to each data point, and this mixture component determines the distribution that the data point is generated from. A mixture of Gaussians uses Gaussian distributions to generate this data <span class="citation">(Bishop, 2006)</span>.</p>
<p>For a set of <span class="math inline">\(N\)</span> data points, the likelihood of each observation <span class="math inline">\(\mathbf{x}_n\)</span> is <span class="math display">\[\begin{aligned}
  p(\mathbf{x}_n \mid \pi, \mu, \sigma)
  &amp;=
  \sum_{k=1}^K \pi_k \, \text{Normal}(\mathbf{x}_n \mid \mu_k, \sigma_k).\end{aligned}\]</span> The latent variable <span class="math inline">\(\pi\)</span> is a <span class="math inline">\(K\)</span>-dimensional probability vector which mixes individual Gaussian distributions, each characterized by a mean <span class="math inline">\(\mu_k\)</span> and standard deviation <span class="math inline">\(\sigma_k\)</span>.</p>
<p>Define the prior on <span class="math inline">\(\pi\in[0,1]\)</span> such that <span class="math inline">\(\sum_{k=1}^K\pi_k=1\)</span> to be <span class="math display">\[\begin{aligned}
  p(\pi)
  &amp;=
  \text{Dirichlet}(\pi \mid \alpha \mathbf{1}_{K}).\end{aligned}\]</span></p>
<p>Define the prior on each component <span class="math inline">\(\mathbf{\mu}_k\in\mathbb{R}^D\)</span> to be <span class="math display">\[\begin{aligned}
  p(\mathbf{\mu}_k)
  &amp;=
  \text{Normal}(\mathbf{\mu}_k \mid 0, \sigma^2\mathbf{I}).\end{aligned}\]</span></p>
<p>Define the prior on each component <span class="math inline">\(\mathbf{\sigma}_k\in\mathbb{R}^D\)</span> to be <span class="math display">\[\begin{aligned}
  p(\mathbf{\sigma}_k)
  &amp;=
  \text{InverseGamma}(\mathbf{\sigma}_k \mid a, b).\end{aligned}\]</span></p>
<p>We build two versions of the model in Edward: one explicitly with the mixture assignments as latent variables, and another with them summed out.</p>
<p>The full version is as follows:</p>
<pre class="python" language="Python"><code>from edward.models import Categorical, Dirichlet, InverseGamma, Normal

N = 500  # number of data points
K = 2  # number of components
D = 2  # dimensionality of data

pi = Dirichlet(alpha=tf.constant([1.0]*K))
mu = Normal(mu=tf.zeros([K, D]), sigma=tf.ones([K, D]))
sigma = InverseGamma(alpha=tf.ones([K, D]), beta=tf.ones([K, D]))
c = Categorical(logits=ed.tile(ed.logit(pi), [N, 1]))
x = Normal(mu=tf.gather(mu, c), sigma=tf.gather(sigma, c))</code></pre>
<p>The collapsed mixture of Gaussians marginalizes out the mixture assignments. We implement this by leveraging the <code>Mixture</code> random variable.</p>
<pre class="python" language="Python"><code>from edward.models import Categorical, InverseGamma, Mixture, \
    MultivariateNormalDiag, Normal

N = 500  # number of data points
K = 2  # number of components
D = 2  # dimensionality of data

mu = Normal(mu=tf.zeros([K, D]), sigma=tf.ones([K, D]))
sigma = InverseGamma(alpha=tf.ones([K, D]), beta=tf.ones([K, D]))
cat = Categorical(logits=tf.zeros([N, K]))
components = [
    MultivariateNormalDiag(mu=tf.ones([N, 1]) * tf.gather(mu, k),
                           diag_stdev=tf.ones([N, 1]) * tf.gather(sigma, k))
    for k in range(K)]

x = Mixture(cat=cat, components=components)</code></pre>
<p>We experiment with this model using variational inference in the <a href="/tutorials/unsupervised">unsupervised learning</a> tutorial. Example scripts using this model can found <a href="https://github.com/blei-lab/edward/blob/master/examples/mixture_gaussian_collapsed.py">.</a></p>
<h3 id="remarks-the-log-sum-exp-trick">Remarks: The log-sum-exp trick</h3>
<p>In general, the model’s log joint density is <span class="math display">\[\begin{aligned}
  \log p(\pi) +
  \Big[ \sum_{k=1}^K \log p(\mathbf{\mu}_k) + \log
  p(\mathbf{\sigma}_k) \Big] +
  \sum_{n=1}^N \log p(\mathbf{x}_n \mid \pi, \mu, \sigma).\end{aligned}\]</span> For a collapsed mixture of Gaussians, implementing the model’s log-likelihood can be tricky: <span class="math display">\[\begin{aligned}
  \sum_{n=1}^N \log p(\mathbf{x}_n \mid \pi, \mu, \sigma)
  &amp;=
  \sum_{n=1}^N \log \sum_{k=1}^K \pi_k \, \text{Normal}(\mathbf{x}_n \mid
  \mu_k, \sigma_k).\end{aligned}\]</span> To prevent numerical instability, we’d like to work on the log-scale when calculating densities, <span class="math display">\[\begin{aligned}
  \sum_{n=1}^N \log p(\mathbf{x}_n \mid \pi, \mu, \sigma)
  &amp;=
  \sum_{n=1}^N \log \sum_{k=1}^K \exp\Big(
  \log \pi_k + \log \text{Normal}(\mathbf{x}_n \mid \mu_k, \sigma_k)\Big).\end{aligned}\]</span> This expression involves a log sum exp operation, which is numerically unstable as exponentiation will often lead to one value dominating the rest. Therefore we use the log-sum-exp trick, which is based on the identity <span class="math display">\[\begin{aligned}
  \mathbf{x}_{\mathrm{max}}
  &amp;=
  \arg\max \mathbf{x},
  \\
  \log \sum_i \exp(\mathbf{x}_i)
  &amp;=
  \log \Big(\exp(\mathbf{x}_{\mathrm{max}}) \sum_i \exp(\mathbf{x}_i -
  \mathbf{x}_{\mathrm{max}})\Big)
  \\
  &amp;=
  \mathbf{x}_{\mathrm{max}} + \log \sum_i \exp(\mathbf{x}_i -
  \mathbf{x}_{\mathrm{max}}).\end{aligned}\]</span> Subtracting the maximum value before taking the log-sum-exp leads to more numerically stable output. The <code>Mixture</code> random variable uses this trick for its log-density calculation.</p>
<h3 id="references" class="unnumbered">References</h3>
<div id="refs" class="references">
<div id="ref-bishop2006pattern">
<p>Bishop, C. M. (2006). <em>Pattern recognition and machine learning</em>. Springer New York.</p>
</div>
</div>
    </div>
  </div>
  <div class="row" style="padding-bottom: 25%"> </div>
</div>
<script>
  hljs.initHighlightingOnLoad();
  renderMathInElement(document.body);
</script>
</body>
</html>
