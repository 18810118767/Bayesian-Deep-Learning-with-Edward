<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <title>Edward – Supervised learning (Regression)</title>
  <!-- Mobile Specific Metas -->
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- FONT -->
  <link href="https://fonts.googleapis.com/css?family=Lora:400,400i,700" rel="stylesheet">
    
  <!-- CSS -->
  <link rel="stylesheet" href="css/normalize.css">
  <link rel="stylesheet" href="css/skeleton.css">

  <!-- KaTeX -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.6.0/katex.min.js"></script>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.6.0/katex.min.css" />
  <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.6.0/contrib/auto-render.min.js"></script>

  <!-- highlight.js -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.4.0/highlight.min.js"></script>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.4.0/styles/github.min.css">

  <!-- Favicon -->
  <link rel="apple-touch-icon" sizes="57x57" href="icons/apple-touch-icon-57x57.png">
  <link rel="apple-touch-icon" sizes="60x60" href="icons/apple-touch-icon-60x60.png">
  <link rel="apple-touch-icon" sizes="72x72" href="icons/apple-touch-icon-72x72.png">
  <link rel="apple-touch-icon" sizes="76x76" href="icons/apple-touch-icon-76x76.png">
  <link rel="apple-touch-icon" sizes="114x114" href="icons/apple-touch-icon-114x114.png">
  <link rel="apple-touch-icon" sizes="120x120" href="icons/apple-touch-icon-120x120.png">
  <link rel="apple-touch-icon" sizes="144x144" href="icons/apple-touch-icon-144x144.png">
  <link rel="apple-touch-icon" sizes="152x152" href="icons/apple-touch-icon-152x152.png">
  <link rel="apple-touch-icon" sizes="180x180" href="icons/apple-touch-icon-180x180.png">
  <link rel="icon" type="image/png" href="icons/favicon-32x32.png" sizes="32x32">
  <link rel="icon" type="image/png" href="icons/android-chrome-192x192.png" sizes="192x192">
  <link rel="icon" type="image/png" href="icons/favicon-96x96.png" sizes="96x96">
  <link rel="icon" type="image/png" href="icons/favicon-16x16.png" sizes="16x16">
  <link rel="manifest" href="icons/manifest.json">
  <link rel="mask-icon" href="icons/safari-pinned-tab.svg" color="#5bbad5">
  <link rel="shortcut icon" href="icons/favicon.ico">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="msapplication-TileImage" content="icons/mstile-144x144.png">
  <meta name="msapplication-config" content="icons/browserconfig.xml">
  <meta name="theme-color" content="#ffffff">
</head>
<body>
<div class="container">
  <div class="row" style="margin-top: 5%">
    <div class="three columns">
    <h1><a href="index.html">Edward</a></h1> 
    <a href="index.html">
    <img src="images/edward.png" class="u-full-width" style="margin-bottom:15%" alt="Edward" />
    </a>
    <a class="button u-full-width" href="index.html">Home</a>
    <a class="button u-full-width" href="getting-started.html">Getting Started</a> 
    <a class="button u-full-width" href="delving-in.html">Delving In</a> 
    <a class="button u-full-width" href="tutorials.html">Tutorials</a> 
    <a class="button u-full-width" href="api/index.html">API</a> 
    <a class="button u-full-width" href="#">Advanced</a> 
    <a class="button2 u-full-width" href="design-philosophy.html">Design Philosophy</a> 
    <a class="button2 u-full-width" href="developer-process.html">Developer Process</a> 
    <a class="button2 u-full-width" href="troubleshooting.html">Troubleshooting</a> 
    <a class="button2 u-full-width" href="license.html">License</a> 
    <div class="row" style="padding-bottom: 5%"> </div>
    <a href="https://github.com/blei-lab/edward">
    <!-- <object data="images/github-mark.svg" type="image/svg+xml"> -->
      <img src="images/github-mark.svg" class="u-pull-right" style="padding-right:10%"
    alt="Edward on Github" />
    <!-- </object> -->
    </a>
    <div class="row" style="padding-bottom: 5%"> </div>
    </div>
    <div class="nine columns">
<h2 id="supervised-learning-regression">Supervised learning (Regression)</h2>
<p>In supervised learning, the task is to infer hidden structure from labeled data, comprised of training examples <span class="math inline">\(\{(x_n, y_n)\}\)</span>. Regression (typically) means the output <span class="math inline">\(y\)</span> takes continuous values.</p>
<p>We demonstrate how to do this in Edward with an example. The script is available <a href="https://github.com/blei-lab/edward/blob/master/examples/bayesian_linear_regression_test.py">here</a>.</p>
<h3 id="data">Data</h3>
<p>Simulate a data set of <span class="math inline">\(40\)</span> data points, which comprises of pairs of inputs <span class="math inline">\(\mathbf{x}_n\in\mathbb{R}^{10}\)</span> and outputs <span class="math inline">\(y_n\in\mathbb{R}\)</span>. They have a linear dependence with normally distributed noise.</p>
<pre class="python" language="Python"><code>def build_toy_dataset(N=40, coeff=np.random.randn(10), noise_std=0.1):
    n_dim = len(coeff)
    x = np.random.randn(N, n_dim).astype(np.float32)
    y = np.dot(x, coeff) + norm.rvs(0, noise_std, size=N)
    return {&#39;x&#39;: x, &#39;y&#39;: y}

coeff = np.random.randn(10)
data = build_toy_dataset(coeff=coeff)</code></pre>
<h3 id="model">Model</h3>
<p>Posit the model as Bayesian linear regression. For more details on the model, see the <a href="tut_bayesian_linear_regression.html">Bayesian linear regression tutorial</a>.</p>
<p>Here we build the model in Edward using TensorFlow.</p>
<pre class="python" language="Python"><code>class LinearModel:
    &quot;&quot;&quot;
    Bayesian linear regression for outputs y on inputs x.

    p((x,y), z) = Normal(y | x*z, lik_variance) *
                  Normal(z | 0, prior_variance),

    where z are weights, and with known lik_variance and
    prior_variance.

    Parameters
    ----------
    lik_variance : float, optional
        Variance of the normal likelihood; aka noise parameter,
        homoscedastic variance, scale parameter.
    prior_variance : float, optional
        Variance of the normal prior on weights; aka L2
        regularization parameter, ridge penalty, scale parameter.
    &quot;&quot;&quot;
    def __init__(self, lik_variance=0.01, prior_variance=0.01):
        self.lik_variance = lik_variance
        self.prior_variance = prior_variance
        self.n_vars = 11

    def log_prob(self, xs, zs):
        &quot;&quot;&quot;Return a vector [log p(xs, zs[1,:]), ..., log p(xs, zs[S,:])].&quot;&quot;&quot;
        x, y = xs[&#39;x&#39;], xs[&#39;y&#39;]
        log_prior = -tf.reduce_sum(zs*zs, 1) / self.prior_variance
        # broadcasting to do (x*W) + b (n_minibatch x n_samples - n_samples)
        b = zs[:, 0]
        W = tf.transpose(zs[:, 1:])
        mus = tf.matmul(x, W) + b
        # broadcasting to do mus - y (n_minibatch x n_samples - n_minibatch x 1)
        y = tf.expand_dims(y, 1)
        log_lik = -tf.reduce_sum(tf.pow(mus - y, 2), 0) / self.lik_variance
        return log_lik + log_prior

    def predict(self, xs, zs):
        &quot;&quot;&quot;Return a prediction for each data point, averaging over
        each set of latent variables z in zs; and also return the true
        value.&quot;&quot;&quot;
        x_test = xs[&#39;x&#39;]
        b = zs[:, 0]
        W = tf.transpose(zs[:, 1:])
        y_pred = tf.reduce_mean(tf.matmul(x_test, W) + b, 1)
        return y_pred

model = LinearModel()</code></pre>
<h3 id="inference">Inference</h3>
<p>Perform variational inference. Define the variational model to be a fully factorized normal</p>
<pre class="python" language="Python"><code>variational = Variational()
variational.add(Normal(model.n_vars))</code></pre>
<p>Run mean-field variational inference for 250 iterations and print every 10 iterations.</p>
<pre class="python" language="Python"><code>inference = ed.MFVI(model, variational, data)
inference.run(n_iter=250, n_print=10)</code></pre>
<p>In this case <code>MFVI</code> defaults to minimizing the <span class="math inline">\(\text{KL}(q\|p)\)</span> divergence measure using the reparameterization gradient. For more details on inference, see the <a href="tut_KLqp.html"><span class="math inline">\(\text{KL}(q\|p)\)</span> tutorial</a>.</p>
<h3 id="criticism">Criticism</h3>
<p>Use point-based evaluation, and calculate the mean squared error for predictions on test data. Here the test data is simulated from the same process.</p>
<pre class="python" language="Python"><code>data_test = build_toy_dataset(coeff=coeff)
x_test, y_test = data_test[&#39;x&#39;], data_test[&#39;y&#39;]
print(ed.evaluate(&#39;mse&#39;, model, variational, {&#39;x&#39;: x_test}, y_test))
## 0.0262413</code></pre>
<p>The trained model makes predictions with low mean squared error (relative to the magnitude of the output).</p>
<p>In addition to the model’s <code>log_prob()</code> method typically required for inference, it has a <code>predict()</code> method which makes predictions. This method is required for point-based evaluation. For more details on criticism, see the <a href="tut_point_eval.html">point-based evaluation tutorial</a>.</p>
    </div>
  </div>
  <div class="row" style="padding-bottom: 25%"> </div>
</div>
<script>
  hljs.initHighlightingOnLoad();
  renderMathInElement(document.body);
</script> 
</body>
</html>
